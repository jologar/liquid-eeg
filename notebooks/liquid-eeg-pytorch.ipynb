{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fp1</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>...</th>\n",
       "      <th>F8</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "      <th>Pz</th>\n",
       "      <th>X5</th>\n",
       "      <th>Marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.96</td>\n",
       "      <td>9.27</td>\n",
       "      <td>-2.47</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>5.36</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.56</td>\n",
       "      <td>10.45</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.37</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.51</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>1.91</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>4.41</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.98</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.60</td>\n",
       "      <td>9.30</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>5.98</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>2.29</td>\n",
       "      <td>-5.11</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-6.07</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>6.84</td>\n",
       "      <td>-5.01</td>\n",
       "      <td>2.26</td>\n",
       "      <td>-5.23</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.21</td>\n",
       "      <td>6.74</td>\n",
       "      <td>-3.58</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>2.36</td>\n",
       "      <td>-3.13</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.05</td>\n",
       "      <td>12.03</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-3.85</td>\n",
       "      <td>2.16</td>\n",
       "      <td>-3.58</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.53</td>\n",
       "      <td>-3.02</td>\n",
       "      <td>1.89</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fp1    Fp2    F3    F4    C3    C4    P3    P4    O1    O2  ...    F8  \\\n",
       "0  5.96   9.27 -2.47  1.62  0.37 -0.31 -1.97 -0.18 -1.64 -0.18  ...  5.36   \n",
       "1 -0.56  10.45  1.10  1.87  1.37 -1.32  0.79  1.26  0.60  1.51  ... -0.59   \n",
       "2 -3.60   9.30 -1.98  5.98 -1.81  2.29 -5.11 -0.82 -6.07 -0.80  ...  6.84   \n",
       "3 -8.21   6.74 -3.58  0.48 -0.41  0.09 -0.43 -0.95 -1.10 -0.58  ...  2.36   \n",
       "4 -2.05  12.03  0.54 -3.85  2.16 -3.58  0.93 -0.71  1.06 -0.66  ...  0.28   \n",
       "\n",
       "     T3    T4    T5    T6    Fz    Cz    Pz    X5  Marker  \n",
       "0  2.56  3.60  2.33  0.46  0.05 -0.90  0.60  0.10       0  \n",
       "1  0.25 -1.22  1.91 -0.54  4.41  4.49  2.98 -0.03       0  \n",
       "2 -5.01  2.26 -5.23 -1.18  2.42  1.40 -0.97 -0.00       0  \n",
       "3 -3.13  0.71 -0.90 -1.48 -0.77  0.27 -0.30 -0.39       0  \n",
       "4  2.53 -3.02  1.89 -1.27 -1.71 -0.82 -1.59 -0.31       0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/csv/HaLT-SubjectA-160223-6St-LRHandLegTongue_experiment_0.csv')\n",
    "df2 = pd.read_csv('../datasets/csv/HaLT-SubjectA-160223-6St-LRHandLegTongue_experiment_1.csv')\n",
    "df3 = pd.read_csv('../datasets/csv/HaLT-SubjectA-160223-6St-LRHandLegTongue_experiment_2.csv')\n",
    "df4 = pd.read_csv('../datasets/csv/HaLT-SubjectA-160308-6St-LRHandLegTongue_experiment_0.csv')\n",
    "df5 = pd.read_csv('../datasets/csv/HaLT-SubjectA-160308-6St-LRHandLegTongue_experiment_1.csv')\n",
    "\n",
    "df = df.sort_values(by=df.columns[0])\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "df2 = df2.sort_values(by=df2.columns[0])\n",
    "df2 = df2.drop(df2.columns[0], axis=1)\n",
    "df3 = df3.sort_values(by=df3.columns[0])\n",
    "df3 = df3.drop(df3.columns[0], axis=1)\n",
    "df4 = df4.sort_values(by=df4.columns[0])\n",
    "df4 = df4.drop(df4.columns[0], axis=1)\n",
    "df5 = df5.sort_values(by=df5.columns[0])\n",
    "df5 = df5.drop(df5.columns[0], axis=1)\n",
    "\n",
    "df = pd.concat([df, df2, df3, df4, df5])\n",
    "\n",
    "valid_df = pd.read_csv('../datasets/csv/HaLT-SubjectA-160310-6St-LRHandLegTongue_experiment_0.csv')\n",
    "valid_df = valid_df.sort_values(by=valid_df.columns[0])\n",
    "valid_df = valid_df.drop(valid_df.columns[0], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.utils.data as data\n",
    "# import numpy as np\n",
    "\n",
    "# # Define dataloaders\n",
    "# BATCH_SIZE = 64\n",
    "# classes = np.unique(df['Marker'])\n",
    "# # features = df[['Cz', 'C3', 'A1', 'F3', 'P3']]\n",
    "# features = df.drop(['Marker'], axis=1)\n",
    "\n",
    "# # use 20% of training data for validation\n",
    "# train_set_size = int(len(df) * 0.8)\n",
    "# valid_set_size = len(df) - train_set_size\n",
    "\n",
    "# train_set = features[:][:train_set_size]\n",
    "# valid_set = features[:][train_set_size:]\n",
    "\n",
    "# train_data_y = torch.tensor(df['Marker'][:train_set_size].values).type(torch.LongTensor) \n",
    "# validation_data_y = torch.tensor(df['Marker'][train_set_size:].values).type(torch.LongTensor) \n",
    "\n",
    "# train_data_x = torch.tensor(train_set.values).type(torch.LongTensor) \n",
    "# validation_data_x = torch.tensor(valid_set.values).type(torch.LongTensor) \n",
    "\n",
    "# train_tensor = data.TensorDataset(train_data_x, train_data_y)\n",
    "# validation_tensor = data.TensorDataset(validation_data_x, validation_data_y)\n",
    "\n",
    "# train_loader = data.DataLoader(train_tensor, batch_size=BATCH_SIZE, num_workers=8)\n",
    "# validation_loader = data.DataLoader(validation_tensor, batch_size=BATCH_SIZE, num_workers=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "\n",
    "# Define dataloaders\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "classes = np.unique(df['Marker'])\n",
    "# features = df[['Cz', 'C3', 'A1', 'F3', 'P3']]\n",
    "features = df.drop(['Marker'], axis=1)\n",
    "valid_features = valid_df.drop(['Marker'], axis=1)\n",
    "\n",
    "train_data_y = torch.tensor(df['Marker'].values).type(torch.LongTensor)\n",
    "validation_data_y = torch.tensor(valid_df['Marker'].values).type(torch.LongTensor)\n",
    "\n",
    "train_data_x = torch.tensor(features.values).type(torch.LongTensor) \n",
    "validation_data_x = torch.tensor(valid_features.values).type(torch.LongTensor)\n",
    "\n",
    "train_tensor = data.TensorDataset(train_data_x, train_data_y)\n",
    "validation_tensor = data.TensorDataset(validation_data_x, validation_data_y)\n",
    "\n",
    "train_loader = data.DataLoader(train_tensor, batch_size=BATCH_SIZE, num_workers=8)\n",
    "validation_loader = data.DataLoader(validation_tensor, batch_size=BATCH_SIZE, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train NN\n",
    "import datetime\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    total_start = datetime.datetime.now()\n",
    "    correct, train_loss = 0, 0\n",
    "     \n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred, _ = model.liquid.forward(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model.softmax(pred)\n",
    "        correct += torch.eq(torch.argmax(pred, dim=1), y).type(torch.float).sum().item()\n",
    "        train_loss += loss.item()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    print(f'Training time: {(datetime.datetime.now() - total_start).total_seconds()}')\n",
    "    correct /= size\n",
    "    return train_loss / batch, correct\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred, _ = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += torch.eq(torch.argmax(pred, dim=1), y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
    "\n",
    "    return test_loss, correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.torch import CfC\n",
    "\n",
    "class LiquidBlock(nn.Module):\n",
    "    def __init__(self, units=20, out_features=10, in_features=5):\n",
    "        super().__init__()\n",
    "        wiring = AutoNCP(units, out_features)\n",
    "        self.units = units\n",
    "        self.liquid = CfC(in_features, wiring, return_sequences=True, batch_first=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        x, hx = self.liquid.forward(input=x, hx=state)\n",
    "        return self.softmax(x), hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "MODEL PARAMETERS: 50608\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "model_units = 125\n",
    "decay_rate = 0.95\n",
    "\n",
    "model = LiquidBlock(units=model_units, out_features=len(classes), in_features=len(features.columns)).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate, verbose=True)\n",
    "\n",
    "epochs = 40\n",
    "history = []\n",
    "\n",
    "print(f'MODEL PARAMETERS: {count_parameters(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.979363  [   64/467150]\n",
      "loss: 1.852247  [ 6464/467150]\n",
      "loss: 1.895211  [12864/467150]\n",
      "loss: 1.596456  [19264/467150]\n",
      "loss: 1.713772  [25664/467150]\n",
      "loss: 2.166567  [32064/467150]\n",
      "loss: 1.419109  [38464/467150]\n",
      "loss: 1.882632  [44864/467150]\n",
      "loss: 1.161677  [51264/467150]\n",
      "loss: 2.336313  [57664/467150]\n",
      "loss: 1.422207  [64064/467150]\n",
      "loss: 1.292799  [70464/467150]\n",
      "loss: 2.004046  [76864/467150]\n",
      "loss: 1.370682  [83264/467150]\n",
      "loss: 1.443240  [89664/467150]\n",
      "loss: 1.595247  [96064/467150]\n",
      "loss: 1.832795  [102464/467150]\n",
      "loss: 1.250398  [108864/467150]\n",
      "loss: 1.563128  [115264/467150]\n",
      "loss: 2.411667  [121664/467150]\n",
      "loss: 1.613313  [128064/467150]\n",
      "loss: 1.770128  [134464/467150]\n",
      "loss: 2.166254  [140864/467150]\n",
      "loss: 1.727403  [147264/467150]\n",
      "loss: 1.852602  [153664/467150]\n",
      "loss: 1.555224  [160064/467150]\n",
      "loss: 1.812465  [166464/467150]\n",
      "loss: 1.545978  [172864/467150]\n",
      "loss: 1.154088  [179264/467150]\n",
      "loss: 1.480724  [185664/467150]\n",
      "loss: 1.134314  [192064/467150]\n",
      "loss: 1.331851  [198464/467150]\n",
      "loss: 0.977056  [204864/467150]\n",
      "loss: 1.338253  [211264/467150]\n",
      "loss: 1.231984  [217664/467150]\n",
      "loss: 2.335692  [224064/467150]\n",
      "loss: 1.643162  [230464/467150]\n",
      "loss: 1.936505  [236864/467150]\n",
      "loss: 1.405943  [243264/467150]\n",
      "loss: 2.102197  [249664/467150]\n",
      "loss: 1.636924  [256064/467150]\n",
      "loss: 2.261468  [262464/467150]\n",
      "loss: 2.345065  [268864/467150]\n",
      "loss: 1.644170  [275264/467150]\n",
      "loss: 1.992181  [281664/467150]\n",
      "loss: 1.755838  [288064/467150]\n",
      "loss: 1.684829  [294464/467150]\n",
      "loss: 1.762073  [300864/467150]\n",
      "loss: 2.044277  [307264/467150]\n",
      "loss: 1.706743  [313664/467150]\n",
      "loss: 1.303160  [320064/467150]\n",
      "loss: 1.443992  [326464/467150]\n",
      "loss: 2.179126  [332864/467150]\n",
      "loss: 1.962767  [339264/467150]\n",
      "loss: 1.227845  [345664/467150]\n",
      "loss: 1.261115  [352064/467150]\n",
      "loss: 1.358717  [358464/467150]\n",
      "loss: 1.747515  [364864/467150]\n",
      "loss: 2.438964  [371264/467150]\n",
      "loss: 1.358652  [377664/467150]\n",
      "loss: 1.554624  [384064/467150]\n",
      "loss: 1.306086  [390464/467150]\n",
      "loss: 2.047355  [396864/467150]\n",
      "loss: 1.489330  [403264/467150]\n",
      "loss: 1.667837  [409664/467150]\n",
      "loss: 1.413536  [416064/467150]\n",
      "loss: 1.828281  [422464/467150]\n",
      "loss: 2.072927  [428864/467150]\n",
      "loss: 1.970785  [435264/467150]\n",
      "loss: 1.264814  [441664/467150]\n",
      "loss: 1.063298  [448064/467150]\n",
      "loss: 1.711460  [454464/467150]\n",
      "loss: 1.622183  [460864/467150]\n",
      "Training time: 663.354407\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 1.870762\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.5000e-04.\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.072086  [   64/467150]\n",
      "loss: 1.294713  [ 6464/467150]\n",
      "loss: 1.772995  [12864/467150]\n",
      "loss: 1.065412  [19264/467150]\n",
      "loss: 1.255174  [25664/467150]\n",
      "loss: 1.841941  [32064/467150]\n",
      "loss: 1.119676  [38464/467150]\n",
      "loss: 1.686361  [44864/467150]\n",
      "loss: 1.118647  [51264/467150]\n",
      "loss: 1.946102  [57664/467150]\n",
      "loss: 1.291748  [64064/467150]\n",
      "loss: 1.335182  [70464/467150]\n",
      "loss: 1.870877  [76864/467150]\n",
      "loss: 1.263647  [83264/467150]\n",
      "loss: 1.177441  [89664/467150]\n",
      "loss: 1.265183  [96064/467150]\n",
      "loss: 1.802148  [102464/467150]\n",
      "loss: 1.137076  [108864/467150]\n",
      "loss: 1.616209  [115264/467150]\n",
      "loss: 2.434283  [121664/467150]\n",
      "loss: 1.347921  [128064/467150]\n",
      "loss: 2.080364  [134464/467150]\n",
      "loss: 2.054041  [140864/467150]\n",
      "loss: 1.719731  [147264/467150]\n",
      "loss: 1.767594  [153664/467150]\n",
      "loss: 1.556926  [160064/467150]\n",
      "loss: 1.792070  [166464/467150]\n",
      "loss: 1.269838  [172864/467150]\n",
      "loss: 1.020499  [179264/467150]\n",
      "loss: 1.380748  [185664/467150]\n",
      "loss: 1.104305  [192064/467150]\n",
      "loss: 1.149762  [198464/467150]\n",
      "loss: 0.986815  [204864/467150]\n",
      "loss: 1.279387  [211264/467150]\n",
      "loss: 1.121648  [217664/467150]\n",
      "loss: 2.127914  [224064/467150]\n",
      "loss: 1.909101  [230464/467150]\n",
      "loss: 1.935198  [236864/467150]\n",
      "loss: 1.401137  [243264/467150]\n",
      "loss: 2.240498  [249664/467150]\n",
      "loss: 1.498451  [256064/467150]\n",
      "loss: 2.010032  [262464/467150]\n",
      "loss: 2.293521  [268864/467150]\n",
      "loss: 1.636513  [275264/467150]\n",
      "loss: 1.859568  [281664/467150]\n",
      "loss: 1.632778  [288064/467150]\n",
      "loss: 1.737993  [294464/467150]\n",
      "loss: 1.685912  [300864/467150]\n",
      "loss: 1.905486  [307264/467150]\n",
      "loss: 1.638451  [313664/467150]\n",
      "loss: 1.270890  [320064/467150]\n",
      "loss: 1.429892  [326464/467150]\n",
      "loss: 2.341779  [332864/467150]\n",
      "loss: 1.337578  [339264/467150]\n",
      "loss: 1.224311  [345664/467150]\n",
      "loss: 1.298432  [352064/467150]\n",
      "loss: 1.315288  [358464/467150]\n",
      "loss: 1.764227  [364864/467150]\n",
      "loss: 2.243787  [371264/467150]\n",
      "loss: 1.972819  [377664/467150]\n",
      "loss: 1.413143  [384064/467150]\n",
      "loss: 1.250426  [390464/467150]\n",
      "loss: 1.637993  [396864/467150]\n",
      "loss: 1.393550  [403264/467150]\n",
      "loss: 1.612533  [409664/467150]\n",
      "loss: 1.191430  [416064/467150]\n",
      "loss: 1.903489  [422464/467150]\n",
      "loss: 1.969500  [428864/467150]\n",
      "loss: 1.832904  [435264/467150]\n",
      "loss: 1.352153  [441664/467150]\n",
      "loss: 0.909734  [448064/467150]\n",
      "loss: 1.581576  [454464/467150]\n",
      "loss: 1.678387  [460864/467150]\n",
      "Training time: 657.542832\n",
      "Test Error: \n",
      " Accuracy: 37.8%, Avg loss: 1.855779\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.0250e-04.\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.030511  [   64/467150]\n",
      "loss: 1.320346  [ 6464/467150]\n",
      "loss: 1.789919  [12864/467150]\n",
      "loss: 1.106102  [19264/467150]\n",
      "loss: 1.068673  [25664/467150]\n",
      "loss: 1.716660  [32064/467150]\n",
      "loss: 1.086313  [38464/467150]\n",
      "loss: 1.689543  [44864/467150]\n",
      "loss: 1.011812  [51264/467150]\n",
      "loss: 1.787807  [57664/467150]\n",
      "loss: 1.005639  [64064/467150]\n",
      "loss: 1.258504  [70464/467150]\n",
      "loss: 1.785802  [76864/467150]\n",
      "loss: 1.256537  [83264/467150]\n",
      "loss: 1.280180  [89664/467150]\n",
      "loss: 1.229714  [96064/467150]\n",
      "loss: 1.795442  [102464/467150]\n",
      "loss: 1.130959  [108864/467150]\n",
      "loss: 1.574104  [115264/467150]\n",
      "loss: 2.442560  [121664/467150]\n",
      "loss: 1.351642  [128064/467150]\n",
      "loss: 1.958028  [134464/467150]\n",
      "loss: 1.881204  [140864/467150]\n",
      "loss: 1.517881  [147264/467150]\n",
      "loss: 1.543786  [153664/467150]\n",
      "loss: 1.457920  [160064/467150]\n",
      "loss: 1.801333  [166464/467150]\n",
      "loss: 1.198627  [172864/467150]\n",
      "loss: 1.070726  [179264/467150]\n",
      "loss: 1.493742  [185664/467150]\n",
      "loss: 1.020767  [192064/467150]\n",
      "loss: 0.951566  [198464/467150]\n",
      "loss: 0.951612  [204864/467150]\n",
      "loss: 1.222818  [211264/467150]\n",
      "loss: 1.103361  [217664/467150]\n",
      "loss: 1.915618  [224064/467150]\n",
      "loss: 1.655204  [230464/467150]\n",
      "loss: 2.004184  [236864/467150]\n",
      "loss: 1.414684  [243264/467150]\n",
      "loss: 2.100296  [249664/467150]\n",
      "loss: 1.435134  [256064/467150]\n",
      "loss: 2.090328  [262464/467150]\n",
      "loss: 2.272196  [268864/467150]\n",
      "loss: 1.573799  [275264/467150]\n",
      "loss: 1.829442  [281664/467150]\n",
      "loss: 1.600987  [288064/467150]\n",
      "loss: 1.694772  [294464/467150]\n",
      "loss: 1.649100  [300864/467150]\n",
      "loss: 1.966549  [307264/467150]\n",
      "loss: 1.730014  [313664/467150]\n",
      "loss: 1.293306  [320064/467150]\n",
      "loss: 1.446339  [326464/467150]\n",
      "loss: 2.374651  [332864/467150]\n",
      "loss: 1.337581  [339264/467150]\n",
      "loss: 1.195999  [345664/467150]\n",
      "loss: 1.244845  [352064/467150]\n",
      "loss: 1.348093  [358464/467150]\n",
      "loss: 1.766319  [364864/467150]\n",
      "loss: 2.188123  [371264/467150]\n",
      "loss: 1.895483  [377664/467150]\n",
      "loss: 1.291536  [384064/467150]\n",
      "loss: 1.145770  [390464/467150]\n",
      "loss: 1.294631  [396864/467150]\n",
      "loss: 1.938099  [403264/467150]\n",
      "loss: 1.563407  [409664/467150]\n",
      "loss: 1.183640  [416064/467150]\n",
      "loss: 1.887509  [422464/467150]\n",
      "loss: 1.961723  [428864/467150]\n",
      "loss: 1.712945  [435264/467150]\n",
      "loss: 1.320162  [441664/467150]\n",
      "loss: 0.829122  [448064/467150]\n",
      "loss: 1.494916  [454464/467150]\n",
      "loss: 1.486854  [460864/467150]\n",
      "Training time: 658.567192\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 1.850645\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.5737e-04.\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.069699  [   64/467150]\n",
      "loss: 1.469048  [ 6464/467150]\n",
      "loss: 1.511262  [12864/467150]\n",
      "loss: 1.071579  [19264/467150]\n",
      "loss: 1.018469  [25664/467150]\n",
      "loss: 1.839256  [32064/467150]\n",
      "loss: 1.076282  [38464/467150]\n",
      "loss: 1.698527  [44864/467150]\n",
      "loss: 0.993729  [51264/467150]\n",
      "loss: 1.880977  [57664/467150]\n",
      "loss: 1.180330  [64064/467150]\n",
      "loss: 1.254595  [70464/467150]\n",
      "loss: 1.882583  [76864/467150]\n",
      "loss: 1.427345  [83264/467150]\n",
      "loss: 1.210560  [89664/467150]\n",
      "loss: 0.965190  [96064/467150]\n",
      "loss: 1.729741  [102464/467150]\n",
      "loss: 1.120497  [108864/467150]\n",
      "loss: 1.744840  [115264/467150]\n",
      "loss: 2.437539  [121664/467150]\n",
      "loss: 1.280921  [128064/467150]\n",
      "loss: 1.896825  [134464/467150]\n",
      "loss: 2.118714  [140864/467150]\n",
      "loss: 1.308889  [147264/467150]\n",
      "loss: 1.681167  [153664/467150]\n",
      "loss: 1.326085  [160064/467150]\n",
      "loss: 1.820622  [166464/467150]\n",
      "loss: 1.227872  [172864/467150]\n",
      "loss: 1.186719  [179264/467150]\n",
      "loss: 1.537733  [185664/467150]\n",
      "loss: 1.073871  [192064/467150]\n",
      "loss: 0.909577  [198464/467150]\n",
      "loss: 1.070786  [204864/467150]\n",
      "loss: 1.097647  [211264/467150]\n",
      "loss: 1.034277  [217664/467150]\n",
      "loss: 1.695706  [224064/467150]\n",
      "loss: 1.458770  [230464/467150]\n",
      "loss: 1.995159  [236864/467150]\n",
      "loss: 1.418154  [243264/467150]\n",
      "loss: 2.378708  [249664/467150]\n",
      "loss: 1.522522  [256064/467150]\n",
      "loss: 2.034878  [262464/467150]\n",
      "loss: 2.201525  [268864/467150]\n",
      "loss: 1.644717  [275264/467150]\n",
      "loss: 1.776507  [281664/467150]\n",
      "loss: 1.638772  [288064/467150]\n",
      "loss: 1.791827  [294464/467150]\n",
      "loss: 1.641215  [300864/467150]\n",
      "loss: 1.858758  [307264/467150]\n",
      "loss: 1.848063  [313664/467150]\n",
      "loss: 1.322255  [320064/467150]\n",
      "loss: 1.481808  [326464/467150]\n",
      "loss: 2.528686  [332864/467150]\n",
      "loss: 1.549965  [339264/467150]\n",
      "loss: 1.141905  [345664/467150]\n",
      "loss: 1.531736  [352064/467150]\n",
      "loss: 1.348547  [358464/467150]\n",
      "loss: 1.820967  [364864/467150]\n",
      "loss: 2.398794  [371264/467150]\n",
      "loss: 1.634243  [377664/467150]\n",
      "loss: 1.449021  [384064/467150]\n",
      "loss: 1.128644  [390464/467150]\n",
      "loss: 1.252426  [396864/467150]\n",
      "loss: 1.189394  [403264/467150]\n",
      "loss: 1.578491  [409664/467150]\n",
      "loss: 1.142095  [416064/467150]\n",
      "loss: 1.948583  [422464/467150]\n",
      "loss: 2.009183  [428864/467150]\n",
      "loss: 1.847177  [435264/467150]\n",
      "loss: 1.263085  [441664/467150]\n",
      "loss: 0.831607  [448064/467150]\n",
      "loss: 1.504294  [454464/467150]\n",
      "loss: 1.530985  [460864/467150]\n",
      "Training time: 658.878965\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 1.848939\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.1451e-04.\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.027365  [   64/467150]\n",
      "loss: 1.425725  [ 6464/467150]\n",
      "loss: 1.516807  [12864/467150]\n",
      "loss: 1.075709  [19264/467150]\n",
      "loss: 0.866069  [25664/467150]\n",
      "loss: 1.927148  [32064/467150]\n",
      "loss: 1.131421  [38464/467150]\n",
      "loss: 1.620570  [44864/467150]\n",
      "loss: 1.029838  [51264/467150]\n",
      "loss: 1.743920  [57664/467150]\n",
      "loss: 0.947374  [64064/467150]\n",
      "loss: 1.279193  [70464/467150]\n",
      "loss: 1.934831  [76864/467150]\n",
      "loss: 1.415008  [83264/467150]\n",
      "loss: 1.378461  [89664/467150]\n",
      "loss: 0.800087  [96064/467150]\n",
      "loss: 1.739617  [102464/467150]\n",
      "loss: 1.133964  [108864/467150]\n",
      "loss: 1.539553  [115264/467150]\n",
      "loss: 2.434870  [121664/467150]\n",
      "loss: 1.321031  [128064/467150]\n",
      "loss: 1.736361  [134464/467150]\n",
      "loss: 1.858458  [140864/467150]\n",
      "loss: 1.238788  [147264/467150]\n",
      "loss: 1.639256  [153664/467150]\n",
      "loss: 1.403029  [160064/467150]\n",
      "loss: 1.765103  [166464/467150]\n",
      "loss: 1.508188  [172864/467150]\n",
      "loss: 1.073454  [179264/467150]\n",
      "loss: 1.510381  [185664/467150]\n",
      "loss: 1.112013  [192064/467150]\n",
      "loss: 1.212212  [198464/467150]\n",
      "loss: 0.974047  [204864/467150]\n",
      "loss: 1.117661  [211264/467150]\n",
      "loss: 1.010923  [217664/467150]\n",
      "loss: 1.862118  [224064/467150]\n",
      "loss: 1.579116  [230464/467150]\n",
      "loss: 2.054465  [236864/467150]\n",
      "loss: 1.370372  [243264/467150]\n",
      "loss: 2.110067  [249664/467150]\n",
      "loss: 1.808622  [256064/467150]\n",
      "loss: 2.084345  [262464/467150]\n",
      "loss: 2.114193  [268864/467150]\n",
      "loss: 1.919407  [275264/467150]\n",
      "loss: 1.762026  [281664/467150]\n",
      "loss: 1.713214  [288064/467150]\n",
      "loss: 1.622817  [294464/467150]\n",
      "loss: 1.644240  [300864/467150]\n",
      "loss: 1.797418  [307264/467150]\n",
      "loss: 1.868350  [313664/467150]\n",
      "loss: 1.318075  [320064/467150]\n",
      "loss: 1.440282  [326464/467150]\n",
      "loss: 2.432988  [332864/467150]\n",
      "loss: 1.430666  [339264/467150]\n",
      "loss: 1.075905  [345664/467150]\n",
      "loss: 1.198420  [352064/467150]\n",
      "loss: 1.340943  [358464/467150]\n",
      "loss: 1.781542  [364864/467150]\n",
      "loss: 2.109839  [371264/467150]\n",
      "loss: 1.540632  [377664/467150]\n",
      "loss: 1.362919  [384064/467150]\n",
      "loss: 1.140588  [390464/467150]\n",
      "loss: 1.759244  [396864/467150]\n",
      "loss: 1.805629  [403264/467150]\n",
      "loss: 1.450345  [409664/467150]\n",
      "loss: 1.146296  [416064/467150]\n",
      "loss: 1.860037  [422464/467150]\n",
      "loss: 1.946121  [428864/467150]\n",
      "loss: 1.939911  [435264/467150]\n",
      "loss: 1.403352  [441664/467150]\n",
      "loss: 0.836828  [448064/467150]\n",
      "loss: 1.490193  [454464/467150]\n",
      "loss: 1.717099  [460864/467150]\n",
      "Training time: 658.444169\n",
      "Test Error: \n",
      " Accuracy: 39.0%, Avg loss: 1.850152\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.7378e-04.\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.047193  [   64/467150]\n",
      "loss: 1.676762  [ 6464/467150]\n",
      "loss: 1.295562  [12864/467150]\n",
      "loss: 1.060189  [19264/467150]\n",
      "loss: 0.972907  [25664/467150]\n",
      "loss: 1.955053  [32064/467150]\n",
      "loss: 1.051834  [38464/467150]\n",
      "loss: 1.625554  [44864/467150]\n",
      "loss: 1.012930  [51264/467150]\n",
      "loss: 1.703117  [57664/467150]\n",
      "loss: 1.111149  [64064/467150]\n",
      "loss: 1.236624  [70464/467150]\n",
      "loss: 2.108919  [76864/467150]\n",
      "loss: 1.466708  [83264/467150]\n",
      "loss: 1.017527  [89664/467150]\n",
      "loss: 0.916388  [96064/467150]\n",
      "loss: 1.930313  [102464/467150]\n",
      "loss: 1.099845  [108864/467150]\n",
      "loss: 1.627396  [115264/467150]\n",
      "loss: 2.199376  [121664/467150]\n",
      "loss: 1.470588  [128064/467150]\n",
      "loss: 1.942355  [134464/467150]\n",
      "loss: 2.042004  [140864/467150]\n",
      "loss: 1.246672  [147264/467150]\n",
      "loss: 1.813916  [153664/467150]\n",
      "loss: 1.419955  [160064/467150]\n",
      "loss: 1.903897  [166464/467150]\n",
      "loss: 1.496512  [172864/467150]\n",
      "loss: 1.168804  [179264/467150]\n",
      "loss: 1.563689  [185664/467150]\n",
      "loss: 1.042573  [192064/467150]\n",
      "loss: 0.928361  [198464/467150]\n",
      "loss: 0.913468  [204864/467150]\n",
      "loss: 1.195265  [211264/467150]\n",
      "loss: 1.076287  [217664/467150]\n",
      "loss: 1.899992  [224064/467150]\n",
      "loss: 1.929446  [230464/467150]\n",
      "loss: 1.914986  [236864/467150]\n",
      "loss: 1.338554  [243264/467150]\n",
      "loss: 2.260108  [249664/467150]\n",
      "loss: 1.815642  [256064/467150]\n",
      "loss: 1.906678  [262464/467150]\n",
      "loss: 2.289438  [268864/467150]\n",
      "loss: 2.085060  [275264/467150]\n",
      "loss: 1.539461  [281664/467150]\n",
      "loss: 1.726796  [288064/467150]\n",
      "loss: 1.814575  [294464/467150]\n",
      "loss: 1.465139  [300864/467150]\n",
      "loss: 1.890322  [307264/467150]\n",
      "loss: 1.823144  [313664/467150]\n",
      "loss: 1.329708  [320064/467150]\n",
      "loss: 1.452399  [326464/467150]\n",
      "loss: 1.730365  [332864/467150]\n",
      "loss: 1.537751  [339264/467150]\n",
      "loss: 1.238157  [345664/467150]\n",
      "loss: 1.232143  [352064/467150]\n",
      "loss: 1.314179  [358464/467150]\n",
      "loss: 1.821010  [364864/467150]\n",
      "loss: 2.165243  [371264/467150]\n",
      "loss: 1.195958  [377664/467150]\n",
      "loss: 0.838902  [384064/467150]\n",
      "loss: 1.174299  [390464/467150]\n",
      "loss: 1.508653  [396864/467150]\n",
      "loss: 1.184346  [403264/467150]\n",
      "loss: 1.625792  [409664/467150]\n",
      "loss: 1.088463  [416064/467150]\n",
      "loss: 1.836598  [422464/467150]\n",
      "loss: 1.987858  [428864/467150]\n",
      "loss: 1.680331  [435264/467150]\n",
      "loss: 1.210247  [441664/467150]\n",
      "loss: 0.839260  [448064/467150]\n",
      "loss: 1.486965  [454464/467150]\n",
      "loss: 1.833227  [460864/467150]\n",
      "Training time: 658.105806\n",
      "Test Error: \n",
      " Accuracy: 40.7%, Avg loss: 1.839696\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.3509e-04.\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.060683  [   64/467150]\n",
      "loss: 1.571302  [ 6464/467150]\n",
      "loss: 1.429903  [12864/467150]\n",
      "loss: 1.060054  [19264/467150]\n",
      "loss: 0.988876  [25664/467150]\n",
      "loss: 2.025547  [32064/467150]\n",
      "loss: 1.016785  [38464/467150]\n",
      "loss: 1.745637  [44864/467150]\n",
      "loss: 1.008795  [51264/467150]\n",
      "loss: 1.781029  [57664/467150]\n",
      "loss: 1.107125  [64064/467150]\n",
      "loss: 1.386937  [70464/467150]\n",
      "loss: 2.457608  [76864/467150]\n",
      "loss: 1.375333  [83264/467150]\n",
      "loss: 1.325624  [89664/467150]\n",
      "loss: 1.110626  [96064/467150]\n",
      "loss: 1.937919  [102464/467150]\n",
      "loss: 1.165679  [108864/467150]\n",
      "loss: 1.561911  [115264/467150]\n",
      "loss: 2.477859  [121664/467150]\n",
      "loss: 1.497395  [128064/467150]\n",
      "loss: 1.857572  [134464/467150]\n",
      "loss: 2.004498  [140864/467150]\n",
      "loss: 1.502924  [147264/467150]\n",
      "loss: 1.064410  [153664/467150]\n",
      "loss: 1.468604  [160064/467150]\n",
      "loss: 2.021541  [166464/467150]\n",
      "loss: 1.134150  [172864/467150]\n",
      "loss: 1.031232  [179264/467150]\n",
      "loss: 1.493573  [185664/467150]\n",
      "loss: 1.038959  [192064/467150]\n",
      "loss: 0.935008  [198464/467150]\n",
      "loss: 0.920143  [204864/467150]\n",
      "loss: 1.175185  [211264/467150]\n",
      "loss: 1.057311  [217664/467150]\n",
      "loss: 1.777027  [224064/467150]\n",
      "loss: 1.375227  [230464/467150]\n",
      "loss: 1.854227  [236864/467150]\n",
      "loss: 1.366023  [243264/467150]\n",
      "loss: 2.104375  [249664/467150]\n",
      "loss: 1.775080  [256064/467150]\n",
      "loss: 2.000662  [262464/467150]\n",
      "loss: 2.278089  [268864/467150]\n",
      "loss: 1.982143  [275264/467150]\n",
      "loss: 1.515723  [281664/467150]\n",
      "loss: 1.660401  [288064/467150]\n",
      "loss: 1.678978  [294464/467150]\n",
      "loss: 1.739589  [300864/467150]\n",
      "loss: 1.781668  [307264/467150]\n",
      "loss: 2.011795  [313664/467150]\n",
      "loss: 1.376806  [320064/467150]\n",
      "loss: 1.436039  [326464/467150]\n",
      "loss: 2.569421  [332864/467150]\n",
      "loss: 1.085472  [339264/467150]\n",
      "loss: 1.102824  [345664/467150]\n",
      "loss: 1.249994  [352064/467150]\n",
      "loss: 1.309443  [358464/467150]\n",
      "loss: 1.769295  [364864/467150]\n",
      "loss: 2.222458  [371264/467150]\n",
      "loss: 1.187000  [377664/467150]\n",
      "loss: 0.960322  [384064/467150]\n",
      "loss: 1.137064  [390464/467150]\n",
      "loss: 1.220523  [396864/467150]\n",
      "loss: 1.444168  [403264/467150]\n",
      "loss: 1.473174  [409664/467150]\n",
      "loss: 1.088453  [416064/467150]\n",
      "loss: 1.782175  [422464/467150]\n",
      "loss: 1.922392  [428864/467150]\n",
      "loss: 1.728023  [435264/467150]\n",
      "loss: 1.308177  [441664/467150]\n",
      "loss: 0.835514  [448064/467150]\n",
      "loss: 1.373184  [454464/467150]\n",
      "loss: 1.709236  [460864/467150]\n",
      "Training time: 658.933733\n",
      "Test Error: \n",
      " Accuracy: 37.0%, Avg loss: 1.854744\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.9834e-04.\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.061318  [   64/467150]\n",
      "loss: 1.664210  [ 6464/467150]\n",
      "loss: 1.469694  [12864/467150]\n",
      "loss: 1.090486  [19264/467150]\n",
      "loss: 0.992319  [25664/467150]\n",
      "loss: 2.131261  [32064/467150]\n",
      "loss: 0.989655  [38464/467150]\n",
      "loss: 1.715780  [44864/467150]\n",
      "loss: 1.000055  [51264/467150]\n",
      "loss: 1.732230  [57664/467150]\n",
      "loss: 1.115885  [64064/467150]\n",
      "loss: 1.341134  [70464/467150]\n",
      "loss: 2.214581  [76864/467150]\n",
      "loss: 1.354753  [83264/467150]\n",
      "loss: 1.351819  [89664/467150]\n",
      "loss: 1.052432  [96064/467150]\n",
      "loss: 1.809188  [102464/467150]\n",
      "loss: 1.160205  [108864/467150]\n",
      "loss: 1.376313  [115264/467150]\n",
      "loss: 2.456615  [121664/467150]\n",
      "loss: 1.291585  [128064/467150]\n",
      "loss: 1.685726  [134464/467150]\n",
      "loss: 2.094051  [140864/467150]\n",
      "loss: 1.199027  [147264/467150]\n",
      "loss: 1.269067  [153664/467150]\n",
      "loss: 1.404210  [160064/467150]\n",
      "loss: 2.215103  [166464/467150]\n",
      "loss: 1.242609  [172864/467150]\n",
      "loss: 1.397756  [179264/467150]\n",
      "loss: 1.699070  [185664/467150]\n",
      "loss: 0.999606  [192064/467150]\n",
      "loss: 1.398665  [198464/467150]\n",
      "loss: 0.968136  [204864/467150]\n",
      "loss: 1.098494  [211264/467150]\n",
      "loss: 1.038414  [217664/467150]\n",
      "loss: 1.567807  [224064/467150]\n",
      "loss: 1.140660  [230464/467150]\n",
      "loss: 2.066767  [236864/467150]\n",
      "loss: 1.477692  [243264/467150]\n",
      "loss: 2.141037  [249664/467150]\n",
      "loss: 1.769973  [256064/467150]\n",
      "loss: 1.834026  [262464/467150]\n",
      "loss: 2.286285  [268864/467150]\n",
      "loss: 1.866481  [275264/467150]\n",
      "loss: 1.276423  [281664/467150]\n",
      "loss: 1.711942  [288064/467150]\n",
      "loss: 1.602696  [294464/467150]\n",
      "loss: 1.809102  [300864/467150]\n",
      "loss: 1.749360  [307264/467150]\n",
      "loss: 2.122549  [313664/467150]\n",
      "loss: 1.331698  [320064/467150]\n",
      "loss: 1.494841  [326464/467150]\n",
      "loss: 2.607826  [332864/467150]\n",
      "loss: 1.170116  [339264/467150]\n",
      "loss: 1.197802  [345664/467150]\n",
      "loss: 1.235165  [352064/467150]\n",
      "loss: 1.245966  [358464/467150]\n",
      "loss: 2.089821  [364864/467150]\n",
      "loss: 2.323194  [371264/467150]\n",
      "loss: 1.176915  [377664/467150]\n",
      "loss: 0.940962  [384064/467150]\n",
      "loss: 1.145468  [390464/467150]\n",
      "loss: 0.904005  [396864/467150]\n",
      "loss: 1.178793  [403264/467150]\n",
      "loss: 1.714542  [409664/467150]\n",
      "loss: 1.083542  [416064/467150]\n",
      "loss: 1.901884  [422464/467150]\n",
      "loss: 1.833862  [428864/467150]\n",
      "loss: 1.669863  [435264/467150]\n",
      "loss: 1.177243  [441664/467150]\n",
      "loss: 0.824238  [448064/467150]\n",
      "loss: 1.456106  [454464/467150]\n",
      "loss: 1.724919  [460864/467150]\n",
      "Training time: 658.541477\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 1.842550\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.6342e-04.\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.033919  [   64/467150]\n",
      "loss: 1.572880  [ 6464/467150]\n",
      "loss: 1.606179  [12864/467150]\n",
      "loss: 1.077115  [19264/467150]\n",
      "loss: 0.794649  [25664/467150]\n",
      "loss: 1.886030  [32064/467150]\n",
      "loss: 1.043711  [38464/467150]\n",
      "loss: 1.732602  [44864/467150]\n",
      "loss: 1.086335  [51264/467150]\n",
      "loss: 1.832509  [57664/467150]\n",
      "loss: 1.082586  [64064/467150]\n",
      "loss: 1.325630  [70464/467150]\n",
      "loss: 2.233196  [76864/467150]\n",
      "loss: 1.390783  [83264/467150]\n",
      "loss: 1.182536  [89664/467150]\n",
      "loss: 0.918988  [96064/467150]\n",
      "loss: 2.149600  [102464/467150]\n",
      "loss: 1.102921  [108864/467150]\n",
      "loss: 1.461252  [115264/467150]\n",
      "loss: 2.464331  [121664/467150]\n",
      "loss: 1.546255  [128064/467150]\n",
      "loss: 1.706264  [134464/467150]\n",
      "loss: 1.930178  [140864/467150]\n",
      "loss: 1.430934  [147264/467150]\n",
      "loss: 1.164164  [153664/467150]\n",
      "loss: 1.352238  [160064/467150]\n",
      "loss: 2.413080  [166464/467150]\n",
      "loss: 2.572617  [172864/467150]\n",
      "loss: 1.476944  [179264/467150]\n",
      "loss: 1.651017  [185664/467150]\n",
      "loss: 1.118309  [192064/467150]\n",
      "loss: 1.168094  [198464/467150]\n",
      "loss: 0.971832  [204864/467150]\n",
      "loss: 1.082354  [211264/467150]\n",
      "loss: 1.027962  [217664/467150]\n",
      "loss: 1.505684  [224064/467150]\n",
      "loss: 1.712787  [230464/467150]\n",
      "loss: 2.359593  [236864/467150]\n",
      "loss: 1.365258  [243264/467150]\n",
      "loss: 2.232994  [249664/467150]\n",
      "loss: 1.910193  [256064/467150]\n",
      "loss: 1.776702  [262464/467150]\n",
      "loss: 2.121389  [268864/467150]\n",
      "loss: 2.203757  [275264/467150]\n",
      "loss: 1.649538  [281664/467150]\n",
      "loss: 1.497259  [288064/467150]\n",
      "loss: 1.909324  [294464/467150]\n",
      "loss: 1.784234  [300864/467150]\n",
      "loss: 1.826639  [307264/467150]\n",
      "loss: 1.950649  [313664/467150]\n",
      "loss: 1.346610  [320064/467150]\n",
      "loss: 1.457192  [326464/467150]\n",
      "loss: 2.603970  [332864/467150]\n",
      "loss: 1.417308  [339264/467150]\n",
      "loss: 1.288736  [345664/467150]\n",
      "loss: 1.263683  [352064/467150]\n",
      "loss: 1.229163  [358464/467150]\n",
      "loss: 2.184736  [364864/467150]\n",
      "loss: 2.395205  [371264/467150]\n",
      "loss: 1.175971  [377664/467150]\n",
      "loss: 0.794532  [384064/467150]\n",
      "loss: 1.158788  [390464/467150]\n",
      "loss: 0.959774  [396864/467150]\n",
      "loss: 0.807599  [403264/467150]\n",
      "loss: 1.539333  [409664/467150]\n",
      "loss: 1.085148  [416064/467150]\n",
      "loss: 1.811361  [422464/467150]\n",
      "loss: 2.015371  [428864/467150]\n",
      "loss: 1.563649  [435264/467150]\n",
      "loss: 1.317125  [441664/467150]\n",
      "loss: 0.827472  [448064/467150]\n",
      "loss: 1.313412  [454464/467150]\n",
      "loss: 1.506890  [460864/467150]\n",
      "Training time: 659.23616\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 1.841585\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.3025e-04.\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.054984  [   64/467150]\n",
      "loss: 1.636257  [ 6464/467150]\n",
      "loss: 1.242058  [12864/467150]\n",
      "loss: 1.120176  [19264/467150]\n",
      "loss: 0.973870  [25664/467150]\n",
      "loss: 2.145132  [32064/467150]\n",
      "loss: 1.012838  [38464/467150]\n",
      "loss: 1.632761  [44864/467150]\n",
      "loss: 0.997801  [51264/467150]\n",
      "loss: 1.747213  [57664/467150]\n",
      "loss: 1.166627  [64064/467150]\n",
      "loss: 1.289937  [70464/467150]\n",
      "loss: 2.182486  [76864/467150]\n",
      "loss: 1.578063  [83264/467150]\n",
      "loss: 1.189861  [89664/467150]\n",
      "loss: 0.867230  [96064/467150]\n",
      "loss: 2.041996  [102464/467150]\n",
      "loss: 1.103620  [108864/467150]\n",
      "loss: 1.308008  [115264/467150]\n",
      "loss: 2.444506  [121664/467150]\n",
      "loss: 1.450521  [128064/467150]\n",
      "loss: 1.696347  [134464/467150]\n",
      "loss: 1.802723  [140864/467150]\n",
      "loss: 1.790305  [147264/467150]\n",
      "loss: 1.035301  [153664/467150]\n",
      "loss: 1.316058  [160064/467150]\n",
      "loss: 2.327912  [166464/467150]\n",
      "loss: 1.479780  [172864/467150]\n",
      "loss: 1.298333  [179264/467150]\n",
      "loss: 1.641254  [185664/467150]\n",
      "loss: 1.117166  [192064/467150]\n",
      "loss: 0.963540  [198464/467150]\n",
      "loss: 0.936619  [204864/467150]\n",
      "loss: 1.845492  [211264/467150]\n",
      "loss: 1.021940  [217664/467150]\n",
      "loss: 1.242700  [224064/467150]\n",
      "loss: 1.775378  [230464/467150]\n",
      "loss: 2.176725  [236864/467150]\n",
      "loss: 1.417126  [243264/467150]\n",
      "loss: 2.090975  [249664/467150]\n",
      "loss: 1.459235  [256064/467150]\n",
      "loss: 1.487659  [262464/467150]\n",
      "loss: 1.912926  [268864/467150]\n",
      "loss: 1.648874  [275264/467150]\n",
      "loss: 1.428280  [281664/467150]\n",
      "loss: 1.455573  [288064/467150]\n",
      "loss: 1.685864  [294464/467150]\n",
      "loss: 1.958130  [300864/467150]\n",
      "loss: 1.925734  [307264/467150]\n",
      "loss: 1.776941  [313664/467150]\n",
      "loss: 1.297938  [320064/467150]\n",
      "loss: 1.432947  [326464/467150]\n",
      "loss: 2.374815  [332864/467150]\n",
      "loss: 1.438172  [339264/467150]\n",
      "loss: 1.251929  [345664/467150]\n",
      "loss: 1.329477  [352064/467150]\n",
      "loss: 1.282299  [358464/467150]\n",
      "loss: 2.124995  [364864/467150]\n",
      "loss: 1.849019  [371264/467150]\n",
      "loss: 1.320656  [377664/467150]\n",
      "loss: 0.954332  [384064/467150]\n",
      "loss: 1.213453  [390464/467150]\n",
      "loss: 0.814784  [396864/467150]\n",
      "loss: 1.285151  [403264/467150]\n",
      "loss: 1.693613  [409664/467150]\n",
      "loss: 1.053689  [416064/467150]\n",
      "loss: 1.974708  [422464/467150]\n",
      "loss: 1.988665  [428864/467150]\n",
      "loss: 1.897906  [435264/467150]\n",
      "loss: 1.214628  [441664/467150]\n",
      "loss: 0.837207  [448064/467150]\n",
      "loss: 1.526381  [454464/467150]\n",
      "loss: 1.591347  [460864/467150]\n",
      "Training time: 658.412295\n",
      "Test Error: \n",
      " Accuracy: 39.7%, Avg loss: 1.844234\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.9874e-04.\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.049991  [   64/467150]\n",
      "loss: 1.583261  [ 6464/467150]\n",
      "loss: 1.235687  [12864/467150]\n",
      "loss: 1.125749  [19264/467150]\n",
      "loss: 0.807919  [25664/467150]\n",
      "loss: 2.157256  [32064/467150]\n",
      "loss: 1.085173  [38464/467150]\n",
      "loss: 1.686871  [44864/467150]\n",
      "loss: 1.106879  [51264/467150]\n",
      "loss: 1.787899  [57664/467150]\n",
      "loss: 1.238864  [64064/467150]\n",
      "loss: 1.337244  [70464/467150]\n",
      "loss: 1.855835  [76864/467150]\n",
      "loss: 1.383323  [83264/467150]\n",
      "loss: 1.183655  [89664/467150]\n",
      "loss: 0.849579  [96064/467150]\n",
      "loss: 1.956000  [102464/467150]\n",
      "loss: 1.101295  [108864/467150]\n",
      "loss: 1.596323  [115264/467150]\n",
      "loss: 2.602176  [121664/467150]\n",
      "loss: 1.325966  [128064/467150]\n",
      "loss: 1.710580  [134464/467150]\n",
      "loss: 2.305416  [140864/467150]\n",
      "loss: 1.170820  [147264/467150]\n",
      "loss: 2.026873  [153664/467150]\n",
      "loss: 1.571037  [160064/467150]\n",
      "loss: 1.955417  [166464/467150]\n",
      "loss: 1.150234  [172864/467150]\n",
      "loss: 1.246048  [179264/467150]\n",
      "loss: 1.528940  [185664/467150]\n",
      "loss: 1.197876  [192064/467150]\n",
      "loss: 0.952908  [198464/467150]\n",
      "loss: 0.964054  [204864/467150]\n",
      "loss: 1.360367  [211264/467150]\n",
      "loss: 1.018948  [217664/467150]\n",
      "loss: 1.402609  [224064/467150]\n",
      "loss: 1.509390  [230464/467150]\n",
      "loss: 1.938112  [236864/467150]\n",
      "loss: 1.438533  [243264/467150]\n",
      "loss: 2.241498  [249664/467150]\n",
      "loss: 1.827379  [256064/467150]\n",
      "loss: 1.925225  [262464/467150]\n",
      "loss: 2.178702  [268864/467150]\n",
      "loss: 1.715219  [275264/467150]\n",
      "loss: 1.367178  [281664/467150]\n",
      "loss: 1.523173  [288064/467150]\n",
      "loss: 1.657927  [294464/467150]\n",
      "loss: 1.902801  [300864/467150]\n",
      "loss: 1.942945  [307264/467150]\n",
      "loss: 1.898774  [313664/467150]\n",
      "loss: 1.274804  [320064/467150]\n",
      "loss: 1.457812  [326464/467150]\n",
      "loss: 1.963346  [332864/467150]\n",
      "loss: 0.973179  [339264/467150]\n",
      "loss: 1.217991  [345664/467150]\n",
      "loss: 1.264710  [352064/467150]\n",
      "loss: 1.224706  [358464/467150]\n",
      "loss: 2.055325  [364864/467150]\n",
      "loss: 1.980001  [371264/467150]\n",
      "loss: 1.172991  [377664/467150]\n",
      "loss: 1.001729  [384064/467150]\n",
      "loss: 1.172148  [390464/467150]\n",
      "loss: 0.852042  [396864/467150]\n",
      "loss: 1.295291  [403264/467150]\n",
      "loss: 1.576694  [409664/467150]\n",
      "loss: 1.060997  [416064/467150]\n",
      "loss: 1.915769  [422464/467150]\n",
      "loss: 1.869088  [428864/467150]\n",
      "loss: 1.754854  [435264/467150]\n",
      "loss: 1.130905  [441664/467150]\n",
      "loss: 0.843313  [448064/467150]\n",
      "loss: 1.167658  [454464/467150]\n",
      "loss: 1.700904  [460864/467150]\n",
      "Training time: 658.534773\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 1.841541\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.6880e-04.\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.045708  [   64/467150]\n",
      "loss: 1.383083  [ 6464/467150]\n",
      "loss: 1.324856  [12864/467150]\n",
      "loss: 1.147987  [19264/467150]\n",
      "loss: 1.274366  [25664/467150]\n",
      "loss: 2.163183  [32064/467150]\n",
      "loss: 1.167088  [38464/467150]\n",
      "loss: 1.666068  [44864/467150]\n",
      "loss: 1.065427  [51264/467150]\n",
      "loss: 2.007351  [57664/467150]\n",
      "loss: 1.152975  [64064/467150]\n",
      "loss: 1.499580  [70464/467150]\n",
      "loss: 1.598309  [76864/467150]\n",
      "loss: 1.427725  [83264/467150]\n",
      "loss: 1.180169  [89664/467150]\n",
      "loss: 0.936456  [96064/467150]\n",
      "loss: 2.099599  [102464/467150]\n",
      "loss: 1.107087  [108864/467150]\n",
      "loss: 1.468575  [115264/467150]\n",
      "loss: 2.516216  [121664/467150]\n",
      "loss: 1.361240  [128064/467150]\n",
      "loss: 1.718718  [134464/467150]\n",
      "loss: 1.888754  [140864/467150]\n",
      "loss: 1.436095  [147264/467150]\n",
      "loss: 1.057288  [153664/467150]\n",
      "loss: 1.487744  [160064/467150]\n",
      "loss: 2.187362  [166464/467150]\n",
      "loss: 0.978300  [172864/467150]\n",
      "loss: 1.219054  [179264/467150]\n",
      "loss: 1.756848  [185664/467150]\n",
      "loss: 1.117040  [192064/467150]\n",
      "loss: 0.989011  [198464/467150]\n",
      "loss: 0.873326  [204864/467150]\n",
      "loss: 1.460263  [211264/467150]\n",
      "loss: 0.995973  [217664/467150]\n",
      "loss: 1.118398  [224064/467150]\n",
      "loss: 1.854401  [230464/467150]\n",
      "loss: 1.926072  [236864/467150]\n",
      "loss: 1.403612  [243264/467150]\n",
      "loss: 2.114728  [249664/467150]\n",
      "loss: 2.115629  [256064/467150]\n",
      "loss: 2.031888  [262464/467150]\n",
      "loss: 2.393020  [268864/467150]\n",
      "loss: 2.044482  [275264/467150]\n",
      "loss: 1.474495  [281664/467150]\n",
      "loss: 1.473685  [288064/467150]\n",
      "loss: 1.502504  [294464/467150]\n",
      "loss: 1.849263  [300864/467150]\n",
      "loss: 1.899215  [307264/467150]\n",
      "loss: 1.990878  [313664/467150]\n",
      "loss: 1.359277  [320064/467150]\n",
      "loss: 1.419455  [326464/467150]\n",
      "loss: 1.893413  [332864/467150]\n",
      "loss: 1.043015  [339264/467150]\n",
      "loss: 1.255913  [345664/467150]\n",
      "loss: 1.282745  [352064/467150]\n",
      "loss: 1.238842  [358464/467150]\n",
      "loss: 1.808042  [364864/467150]\n",
      "loss: 1.865296  [371264/467150]\n",
      "loss: 1.298863  [377664/467150]\n",
      "loss: 1.106624  [384064/467150]\n",
      "loss: 1.134738  [390464/467150]\n",
      "loss: 0.783495  [396864/467150]\n",
      "loss: 1.087966  [403264/467150]\n",
      "loss: 1.588073  [409664/467150]\n",
      "loss: 1.061520  [416064/467150]\n",
      "loss: 1.664225  [422464/467150]\n",
      "loss: 1.832030  [428864/467150]\n",
      "loss: 1.989653  [435264/467150]\n",
      "loss: 1.207067  [441664/467150]\n",
      "loss: 0.832915  [448064/467150]\n",
      "loss: 1.351230  [454464/467150]\n",
      "loss: 1.755119  [460864/467150]\n",
      "Training time: 657.88696\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.840662\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.4036e-04.\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.044677  [   64/467150]\n",
      "loss: 1.619819  [ 6464/467150]\n",
      "loss: 1.293733  [12864/467150]\n",
      "loss: 1.143514  [19264/467150]\n",
      "loss: 1.078835  [25664/467150]\n",
      "loss: 2.068219  [32064/467150]\n",
      "loss: 0.987928  [38464/467150]\n",
      "loss: 1.640132  [44864/467150]\n",
      "loss: 1.040391  [51264/467150]\n",
      "loss: 1.703385  [57664/467150]\n",
      "loss: 1.084103  [64064/467150]\n",
      "loss: 1.381474  [70464/467150]\n",
      "loss: 2.258228  [76864/467150]\n",
      "loss: 1.483876  [83264/467150]\n",
      "loss: 1.106841  [89664/467150]\n",
      "loss: 0.848513  [96064/467150]\n",
      "loss: 1.847386  [102464/467150]\n",
      "loss: 1.116133  [108864/467150]\n",
      "loss: 1.181823  [115264/467150]\n",
      "loss: 2.518406  [121664/467150]\n",
      "loss: 1.301681  [128064/467150]\n",
      "loss: 1.713992  [134464/467150]\n",
      "loss: 1.915104  [140864/467150]\n",
      "loss: 1.466549  [147264/467150]\n",
      "loss: 1.418258  [153664/467150]\n",
      "loss: 1.530931  [160064/467150]\n",
      "loss: 2.040907  [166464/467150]\n",
      "loss: 1.405832  [172864/467150]\n",
      "loss: 1.258564  [179264/467150]\n",
      "loss: 1.965653  [185664/467150]\n",
      "loss: 1.094166  [192064/467150]\n",
      "loss: 1.074778  [198464/467150]\n",
      "loss: 0.981000  [204864/467150]\n",
      "loss: 1.358531  [211264/467150]\n",
      "loss: 1.017611  [217664/467150]\n",
      "loss: 1.192077  [224064/467150]\n",
      "loss: 2.049802  [230464/467150]\n",
      "loss: 2.096134  [236864/467150]\n",
      "loss: 1.400729  [243264/467150]\n",
      "loss: 2.266304  [249664/467150]\n",
      "loss: 1.756930  [256064/467150]\n",
      "loss: 1.989816  [262464/467150]\n",
      "loss: 2.122115  [268864/467150]\n",
      "loss: 1.950719  [275264/467150]\n",
      "loss: 1.590080  [281664/467150]\n",
      "loss: 1.465786  [288064/467150]\n",
      "loss: 1.520134  [294464/467150]\n",
      "loss: 2.203966  [300864/467150]\n",
      "loss: 1.895760  [307264/467150]\n",
      "loss: 1.782892  [313664/467150]\n",
      "loss: 1.318490  [320064/467150]\n",
      "loss: 1.566693  [326464/467150]\n",
      "loss: 1.919626  [332864/467150]\n",
      "loss: 1.251224  [339264/467150]\n",
      "loss: 1.236826  [345664/467150]\n",
      "loss: 1.196419  [352064/467150]\n",
      "loss: 1.302969  [358464/467150]\n",
      "loss: 2.116003  [364864/467150]\n",
      "loss: 2.079383  [371264/467150]\n",
      "loss: 1.340725  [377664/467150]\n",
      "loss: 0.758895  [384064/467150]\n",
      "loss: 1.131902  [390464/467150]\n",
      "loss: 0.960160  [396864/467150]\n",
      "loss: 0.784833  [403264/467150]\n",
      "loss: 1.477023  [409664/467150]\n",
      "loss: 1.099115  [416064/467150]\n",
      "loss: 1.832616  [422464/467150]\n",
      "loss: 1.746674  [428864/467150]\n",
      "loss: 1.602848  [435264/467150]\n",
      "loss: 1.283751  [441664/467150]\n",
      "loss: 0.846453  [448064/467150]\n",
      "loss: 1.523693  [454464/467150]\n",
      "loss: 1.715937  [460864/467150]\n",
      "Training time: 658.537415\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 1.840406\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.1334e-04.\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.043956  [   64/467150]\n",
      "loss: 1.590253  [ 6464/467150]\n",
      "loss: 1.277760  [12864/467150]\n",
      "loss: 1.089975  [19264/467150]\n",
      "loss: 1.029338  [25664/467150]\n",
      "loss: 2.072513  [32064/467150]\n",
      "loss: 0.994758  [38464/467150]\n",
      "loss: 1.790583  [44864/467150]\n",
      "loss: 1.010311  [51264/467150]\n",
      "loss: 1.661233  [57664/467150]\n",
      "loss: 1.202050  [64064/467150]\n",
      "loss: 1.389493  [70464/467150]\n",
      "loss: 2.005387  [76864/467150]\n",
      "loss: 1.492826  [83264/467150]\n",
      "loss: 1.177960  [89664/467150]\n",
      "loss: 1.085209  [96064/467150]\n",
      "loss: 2.103793  [102464/467150]\n",
      "loss: 1.113749  [108864/467150]\n",
      "loss: 1.262002  [115264/467150]\n",
      "loss: 2.552859  [121664/467150]\n",
      "loss: 1.336451  [128064/467150]\n",
      "loss: 1.797700  [134464/467150]\n",
      "loss: 2.118989  [140864/467150]\n",
      "loss: 1.478661  [147264/467150]\n",
      "loss: 1.519377  [153664/467150]\n",
      "loss: 1.424030  [160064/467150]\n",
      "loss: 2.036676  [166464/467150]\n",
      "loss: 1.159385  [172864/467150]\n",
      "loss: 1.258755  [179264/467150]\n",
      "loss: 1.655680  [185664/467150]\n",
      "loss: 0.990358  [192064/467150]\n",
      "loss: 1.202079  [198464/467150]\n",
      "loss: 0.834957  [204864/467150]\n",
      "loss: 1.268977  [211264/467150]\n",
      "loss: 1.011932  [217664/467150]\n",
      "loss: 1.539710  [224064/467150]\n",
      "loss: 1.336224  [230464/467150]\n",
      "loss: 1.915755  [236864/467150]\n",
      "loss: 1.430869  [243264/467150]\n",
      "loss: 2.194660  [249664/467150]\n",
      "loss: 1.595221  [256064/467150]\n",
      "loss: 1.890749  [262464/467150]\n",
      "loss: 2.267272  [268864/467150]\n",
      "loss: 2.267667  [275264/467150]\n",
      "loss: 1.551774  [281664/467150]\n",
      "loss: 1.447199  [288064/467150]\n",
      "loss: 1.089999  [294464/467150]\n",
      "loss: 1.757833  [300864/467150]\n",
      "loss: 2.055380  [307264/467150]\n",
      "loss: 1.765699  [313664/467150]\n",
      "loss: 1.354591  [320064/467150]\n",
      "loss: 1.410875  [326464/467150]\n",
      "loss: 2.303809  [332864/467150]\n",
      "loss: 1.204525  [339264/467150]\n",
      "loss: 1.169392  [345664/467150]\n",
      "loss: 1.291069  [352064/467150]\n",
      "loss: 1.280593  [358464/467150]\n",
      "loss: 1.962073  [364864/467150]\n",
      "loss: 1.945366  [371264/467150]\n",
      "loss: 1.336147  [377664/467150]\n",
      "loss: 0.881079  [384064/467150]\n",
      "loss: 1.132796  [390464/467150]\n",
      "loss: 1.629705  [396864/467150]\n",
      "loss: 0.900506  [403264/467150]\n",
      "loss: 1.610861  [409664/467150]\n",
      "loss: 1.073034  [416064/467150]\n",
      "loss: 1.666451  [422464/467150]\n",
      "loss: 1.825130  [428864/467150]\n",
      "loss: 1.668222  [435264/467150]\n",
      "loss: 1.237640  [441664/467150]\n",
      "loss: 0.838796  [448064/467150]\n",
      "loss: 1.206686  [454464/467150]\n",
      "loss: 1.724154  [460864/467150]\n",
      "Training time: 658.608023\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 1.837237\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8767e-04.\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.059193  [   64/467150]\n",
      "loss: 1.536938  [ 6464/467150]\n",
      "loss: 1.238676  [12864/467150]\n",
      "loss: 1.084523  [19264/467150]\n",
      "loss: 0.807910  [25664/467150]\n",
      "loss: 2.226159  [32064/467150]\n",
      "loss: 0.981115  [38464/467150]\n",
      "loss: 1.836764  [44864/467150]\n",
      "loss: 1.004153  [51264/467150]\n",
      "loss: 1.688743  [57664/467150]\n",
      "loss: 1.020219  [64064/467150]\n",
      "loss: 1.511681  [70464/467150]\n",
      "loss: 2.039023  [76864/467150]\n",
      "loss: 1.382804  [83264/467150]\n",
      "loss: 1.134359  [89664/467150]\n",
      "loss: 1.033103  [96064/467150]\n",
      "loss: 1.895269  [102464/467150]\n",
      "loss: 1.123124  [108864/467150]\n",
      "loss: 1.286967  [115264/467150]\n",
      "loss: 2.477399  [121664/467150]\n",
      "loss: 1.348918  [128064/467150]\n",
      "loss: 2.376874  [134464/467150]\n",
      "loss: 2.225475  [140864/467150]\n",
      "loss: 1.550640  [147264/467150]\n",
      "loss: 0.964635  [153664/467150]\n",
      "loss: 1.403267  [160064/467150]\n",
      "loss: 2.313941  [166464/467150]\n",
      "loss: 1.197667  [172864/467150]\n",
      "loss: 1.388675  [179264/467150]\n",
      "loss: 1.981052  [185664/467150]\n",
      "loss: 1.136703  [192064/467150]\n",
      "loss: 1.017343  [198464/467150]\n",
      "loss: 0.769568  [204864/467150]\n",
      "loss: 1.391886  [211264/467150]\n",
      "loss: 1.016717  [217664/467150]\n",
      "loss: 1.420869  [224064/467150]\n",
      "loss: 1.358515  [230464/467150]\n",
      "loss: 2.054801  [236864/467150]\n",
      "loss: 1.362677  [243264/467150]\n",
      "loss: 2.285793  [249664/467150]\n",
      "loss: 1.914436  [256064/467150]\n",
      "loss: 1.848820  [262464/467150]\n",
      "loss: 1.894066  [268864/467150]\n",
      "loss: 2.234940  [275264/467150]\n",
      "loss: 1.764613  [281664/467150]\n",
      "loss: 1.462609  [288064/467150]\n",
      "loss: 1.462929  [294464/467150]\n",
      "loss: 1.952080  [300864/467150]\n",
      "loss: 2.071009  [307264/467150]\n",
      "loss: 1.956759  [313664/467150]\n",
      "loss: 1.328526  [320064/467150]\n",
      "loss: 1.674252  [326464/467150]\n",
      "loss: 1.782578  [332864/467150]\n",
      "loss: 1.288476  [339264/467150]\n",
      "loss: 1.238547  [345664/467150]\n",
      "loss: 1.234061  [352064/467150]\n",
      "loss: 1.269685  [358464/467150]\n",
      "loss: 1.849887  [364864/467150]\n",
      "loss: 1.752185  [371264/467150]\n",
      "loss: 1.119694  [377664/467150]\n",
      "loss: 1.285413  [384064/467150]\n",
      "loss: 1.163719  [390464/467150]\n",
      "loss: 1.718160  [396864/467150]\n",
      "loss: 0.852941  [403264/467150]\n",
      "loss: 1.568635  [409664/467150]\n",
      "loss: 1.110571  [416064/467150]\n",
      "loss: 1.664574  [422464/467150]\n",
      "loss: 1.788533  [428864/467150]\n",
      "loss: 1.561403  [435264/467150]\n",
      "loss: 1.219655  [441664/467150]\n",
      "loss: 0.845712  [448064/467150]\n",
      "loss: 1.603961  [454464/467150]\n",
      "loss: 1.717807  [460864/467150]\n",
      "Training time: 658.794657\n",
      "Test Error: \n",
      " Accuracy: 41.4%, Avg loss: 1.842777\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6329e-04.\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.043848  [   64/467150]\n",
      "loss: 1.494128  [ 6464/467150]\n",
      "loss: 1.760074  [12864/467150]\n",
      "loss: 1.086264  [19264/467150]\n",
      "loss: 0.891171  [25664/467150]\n",
      "loss: 2.041275  [32064/467150]\n",
      "loss: 0.971338  [38464/467150]\n",
      "loss: 1.704617  [44864/467150]\n",
      "loss: 0.987108  [51264/467150]\n",
      "loss: 1.735656  [57664/467150]\n",
      "loss: 1.015413  [64064/467150]\n",
      "loss: 1.399884  [70464/467150]\n",
      "loss: 2.014208  [76864/467150]\n",
      "loss: 1.326535  [83264/467150]\n",
      "loss: 1.183623  [89664/467150]\n",
      "loss: 0.833443  [96064/467150]\n",
      "loss: 1.731518  [102464/467150]\n",
      "loss: 1.104974  [108864/467150]\n",
      "loss: 1.271037  [115264/467150]\n",
      "loss: 2.515061  [121664/467150]\n",
      "loss: 1.397070  [128064/467150]\n",
      "loss: 1.593389  [134464/467150]\n",
      "loss: 2.109248  [140864/467150]\n",
      "loss: 1.502894  [147264/467150]\n",
      "loss: 1.757061  [153664/467150]\n",
      "loss: 1.356223  [160064/467150]\n",
      "loss: 2.153454  [166464/467150]\n",
      "loss: 1.060870  [172864/467150]\n",
      "loss: 1.353296  [179264/467150]\n",
      "loss: 1.694694  [185664/467150]\n",
      "loss: 1.050120  [192064/467150]\n",
      "loss: 1.108501  [198464/467150]\n",
      "loss: 0.917924  [204864/467150]\n",
      "loss: 1.194592  [211264/467150]\n",
      "loss: 1.062310  [217664/467150]\n",
      "loss: 1.380361  [224064/467150]\n",
      "loss: 1.823107  [230464/467150]\n",
      "loss: 2.234860  [236864/467150]\n",
      "loss: 1.380434  [243264/467150]\n",
      "loss: 2.261561  [249664/467150]\n",
      "loss: 2.099474  [256064/467150]\n",
      "loss: 1.805193  [262464/467150]\n",
      "loss: 1.631574  [268864/467150]\n",
      "loss: 2.115006  [275264/467150]\n",
      "loss: 1.388741  [281664/467150]\n",
      "loss: 1.472846  [288064/467150]\n",
      "loss: 2.052816  [294464/467150]\n",
      "loss: 1.929489  [300864/467150]\n",
      "loss: 1.773108  [307264/467150]\n",
      "loss: 1.933729  [313664/467150]\n",
      "loss: 1.376352  [320064/467150]\n",
      "loss: 1.423599  [326464/467150]\n",
      "loss: 1.708691  [332864/467150]\n",
      "loss: 1.122829  [339264/467150]\n",
      "loss: 1.206753  [345664/467150]\n",
      "loss: 1.191210  [352064/467150]\n",
      "loss: 1.249660  [358464/467150]\n",
      "loss: 1.904661  [364864/467150]\n",
      "loss: 1.631384  [371264/467150]\n",
      "loss: 1.164391  [377664/467150]\n",
      "loss: 0.761757  [384064/467150]\n",
      "loss: 1.176765  [390464/467150]\n",
      "loss: 1.221299  [396864/467150]\n",
      "loss: 0.933864  [403264/467150]\n",
      "loss: 1.487739  [409664/467150]\n",
      "loss: 1.144993  [416064/467150]\n",
      "loss: 2.012720  [422464/467150]\n",
      "loss: 1.687159  [428864/467150]\n",
      "loss: 1.561300  [435264/467150]\n",
      "loss: 1.377565  [441664/467150]\n",
      "loss: 0.836347  [448064/467150]\n",
      "loss: 1.190124  [454464/467150]\n",
      "loss: 1.687510  [460864/467150]\n",
      "Training time: 658.767996\n",
      "Test Error: \n",
      " Accuracy: 42.1%, Avg loss: 1.834880\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4013e-04.\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.041106  [   64/467150]\n",
      "loss: 1.620045  [ 6464/467150]\n",
      "loss: 1.183344  [12864/467150]\n",
      "loss: 1.088334  [19264/467150]\n",
      "loss: 1.027814  [25664/467150]\n",
      "loss: 2.167098  [32064/467150]\n",
      "loss: 1.010245  [38464/467150]\n",
      "loss: 1.586919  [44864/467150]\n",
      "loss: 1.149160  [51264/467150]\n",
      "loss: 1.824290  [57664/467150]\n",
      "loss: 1.204346  [64064/467150]\n",
      "loss: 1.366772  [70464/467150]\n",
      "loss: 1.925981  [76864/467150]\n",
      "loss: 1.312454  [83264/467150]\n",
      "loss: 1.134439  [89664/467150]\n",
      "loss: 0.838774  [96064/467150]\n",
      "loss: 1.983454  [102464/467150]\n",
      "loss: 1.107315  [108864/467150]\n",
      "loss: 1.280574  [115264/467150]\n",
      "loss: 2.509168  [121664/467150]\n",
      "loss: 1.415146  [128064/467150]\n",
      "loss: 1.876644  [134464/467150]\n",
      "loss: 1.900858  [140864/467150]\n",
      "loss: 1.542454  [147264/467150]\n",
      "loss: 1.325613  [153664/467150]\n",
      "loss: 1.595172  [160064/467150]\n",
      "loss: 2.009919  [166464/467150]\n",
      "loss: 1.025408  [172864/467150]\n",
      "loss: 1.308919  [179264/467150]\n",
      "loss: 1.913366  [185664/467150]\n",
      "loss: 1.077051  [192064/467150]\n",
      "loss: 1.202927  [198464/467150]\n",
      "loss: 0.969406  [204864/467150]\n",
      "loss: 1.374133  [211264/467150]\n",
      "loss: 1.036492  [217664/467150]\n",
      "loss: 1.233667  [224064/467150]\n",
      "loss: 1.326805  [230464/467150]\n",
      "loss: 2.119827  [236864/467150]\n",
      "loss: 1.418181  [243264/467150]\n",
      "loss: 2.238934  [249664/467150]\n",
      "loss: 1.692474  [256064/467150]\n",
      "loss: 1.745947  [262464/467150]\n",
      "loss: 2.266202  [268864/467150]\n",
      "loss: 2.389917  [275264/467150]\n",
      "loss: 1.198539  [281664/467150]\n",
      "loss: 1.675393  [288064/467150]\n",
      "loss: 1.158133  [294464/467150]\n",
      "loss: 2.135355  [300864/467150]\n",
      "loss: 1.767092  [307264/467150]\n",
      "loss: 1.756063  [313664/467150]\n",
      "loss: 1.284390  [320064/467150]\n",
      "loss: 1.451707  [326464/467150]\n",
      "loss: 2.042468  [332864/467150]\n",
      "loss: 0.845232  [339264/467150]\n",
      "loss: 1.380677  [345664/467150]\n",
      "loss: 1.218496  [352064/467150]\n",
      "loss: 1.281317  [358464/467150]\n",
      "loss: 2.141941  [364864/467150]\n",
      "loss: 1.660186  [371264/467150]\n",
      "loss: 1.199834  [377664/467150]\n",
      "loss: 0.800177  [384064/467150]\n",
      "loss: 1.146842  [390464/467150]\n",
      "loss: 0.780444  [396864/467150]\n",
      "loss: 0.869450  [403264/467150]\n",
      "loss: 1.435362  [409664/467150]\n",
      "loss: 1.144086  [416064/467150]\n",
      "loss: 1.994012  [422464/467150]\n",
      "loss: 1.816873  [428864/467150]\n",
      "loss: 1.731923  [435264/467150]\n",
      "loss: 1.045651  [441664/467150]\n",
      "loss: 0.831849  [448064/467150]\n",
      "loss: 1.173629  [454464/467150]\n",
      "loss: 1.130024  [460864/467150]\n",
      "Training time: 658.78955\n",
      "Test Error: \n",
      " Accuracy: 39.8%, Avg loss: 1.838611\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1812e-04.\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.038581  [   64/467150]\n",
      "loss: 1.627558  [ 6464/467150]\n",
      "loss: 1.744492  [12864/467150]\n",
      "loss: 1.092561  [19264/467150]\n",
      "loss: 0.994516  [25664/467150]\n",
      "loss: 2.317973  [32064/467150]\n",
      "loss: 1.037071  [38464/467150]\n",
      "loss: 1.633618  [44864/467150]\n",
      "loss: 1.025901  [51264/467150]\n",
      "loss: 2.011481  [57664/467150]\n",
      "loss: 1.254043  [64064/467150]\n",
      "loss: 1.332197  [70464/467150]\n",
      "loss: 1.740326  [76864/467150]\n",
      "loss: 1.324437  [83264/467150]\n",
      "loss: 1.239878  [89664/467150]\n",
      "loss: 0.789828  [96064/467150]\n",
      "loss: 1.858262  [102464/467150]\n",
      "loss: 1.188585  [108864/467150]\n",
      "loss: 1.291889  [115264/467150]\n",
      "loss: 2.612644  [121664/467150]\n",
      "loss: 1.660681  [128064/467150]\n",
      "loss: 1.710733  [134464/467150]\n",
      "loss: 2.424568  [140864/467150]\n",
      "loss: 1.249393  [147264/467150]\n",
      "loss: 1.766753  [153664/467150]\n",
      "loss: 1.443422  [160064/467150]\n",
      "loss: 2.222836  [166464/467150]\n",
      "loss: 1.306203  [172864/467150]\n",
      "loss: 1.239943  [179264/467150]\n",
      "loss: 1.993522  [185664/467150]\n",
      "loss: 1.106120  [192064/467150]\n",
      "loss: 1.109492  [198464/467150]\n",
      "loss: 0.962880  [204864/467150]\n",
      "loss: 1.142278  [211264/467150]\n",
      "loss: 1.017210  [217664/467150]\n",
      "loss: 1.602995  [224064/467150]\n",
      "loss: 1.870425  [230464/467150]\n",
      "loss: 2.232058  [236864/467150]\n",
      "loss: 1.484914  [243264/467150]\n",
      "loss: 2.227103  [249664/467150]\n",
      "loss: 1.530161  [256064/467150]\n",
      "loss: 2.046492  [262464/467150]\n",
      "loss: 1.998754  [268864/467150]\n",
      "loss: 2.283254  [275264/467150]\n",
      "loss: 1.452482  [281664/467150]\n",
      "loss: 1.413050  [288064/467150]\n",
      "loss: 1.646598  [294464/467150]\n",
      "loss: 2.049517  [300864/467150]\n",
      "loss: 1.936208  [307264/467150]\n",
      "loss: 1.689418  [313664/467150]\n",
      "loss: 1.341073  [320064/467150]\n",
      "loss: 1.428838  [326464/467150]\n",
      "loss: 2.155554  [332864/467150]\n",
      "loss: 1.260584  [339264/467150]\n",
      "loss: 1.334146  [345664/467150]\n",
      "loss: 1.208016  [352064/467150]\n",
      "loss: 1.219501  [358464/467150]\n",
      "loss: 2.069161  [364864/467150]\n",
      "loss: 1.987228  [371264/467150]\n",
      "loss: 1.301135  [377664/467150]\n",
      "loss: 0.830095  [384064/467150]\n",
      "loss: 1.155978  [390464/467150]\n",
      "loss: 0.743036  [396864/467150]\n",
      "loss: 0.968612  [403264/467150]\n",
      "loss: 1.428073  [409664/467150]\n",
      "loss: 1.175867  [416064/467150]\n",
      "loss: 2.022224  [422464/467150]\n",
      "loss: 1.768300  [428864/467150]\n",
      "loss: 1.848249  [435264/467150]\n",
      "loss: 1.424283  [441664/467150]\n",
      "loss: 0.835934  [448064/467150]\n",
      "loss: 1.949093  [454464/467150]\n",
      "loss: 1.618982  [460864/467150]\n",
      "Training time: 657.967015\n",
      "Test Error: \n",
      " Accuracy: 41.6%, Avg loss: 1.837422\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9721e-04.\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.044967  [   64/467150]\n",
      "loss: 1.443873  [ 6464/467150]\n",
      "loss: 0.875762  [12864/467150]\n",
      "loss: 1.087299  [19264/467150]\n",
      "loss: 0.976605  [25664/467150]\n",
      "loss: 1.987270  [32064/467150]\n",
      "loss: 1.024151  [38464/467150]\n",
      "loss: 1.669323  [44864/467150]\n",
      "loss: 1.006155  [51264/467150]\n",
      "loss: 1.955233  [57664/467150]\n",
      "loss: 0.928386  [64064/467150]\n",
      "loss: 1.453622  [70464/467150]\n",
      "loss: 1.634319  [76864/467150]\n",
      "loss: 1.391575  [83264/467150]\n",
      "loss: 1.168640  [89664/467150]\n",
      "loss: 0.808044  [96064/467150]\n",
      "loss: 1.787910  [102464/467150]\n",
      "loss: 1.075801  [108864/467150]\n",
      "loss: 1.210681  [115264/467150]\n",
      "loss: 2.349257  [121664/467150]\n",
      "loss: 1.442344  [128064/467150]\n",
      "loss: 1.953771  [134464/467150]\n",
      "loss: 2.230343  [140864/467150]\n",
      "loss: 1.355210  [147264/467150]\n",
      "loss: 1.495700  [153664/467150]\n",
      "loss: 1.556650  [160064/467150]\n",
      "loss: 2.129469  [166464/467150]\n",
      "loss: 1.245738  [172864/467150]\n",
      "loss: 1.588459  [179264/467150]\n",
      "loss: 1.843211  [185664/467150]\n",
      "loss: 1.212169  [192064/467150]\n",
      "loss: 1.409587  [198464/467150]\n",
      "loss: 0.953111  [204864/467150]\n",
      "loss: 1.365378  [211264/467150]\n",
      "loss: 1.076953  [217664/467150]\n",
      "loss: 1.486943  [224064/467150]\n",
      "loss: 1.791193  [230464/467150]\n",
      "loss: 1.492161  [236864/467150]\n",
      "loss: 1.420737  [243264/467150]\n",
      "loss: 2.198442  [249664/467150]\n",
      "loss: 1.557646  [256064/467150]\n",
      "loss: 1.840906  [262464/467150]\n",
      "loss: 2.048743  [268864/467150]\n",
      "loss: 2.309413  [275264/467150]\n",
      "loss: 1.068682  [281664/467150]\n",
      "loss: 1.761308  [288064/467150]\n",
      "loss: 2.357923  [294464/467150]\n",
      "loss: 2.330502  [300864/467150]\n",
      "loss: 1.767537  [307264/467150]\n",
      "loss: 1.659008  [313664/467150]\n",
      "loss: 1.320341  [320064/467150]\n",
      "loss: 1.832101  [326464/467150]\n",
      "loss: 1.473086  [332864/467150]\n",
      "loss: 1.454626  [339264/467150]\n",
      "loss: 1.220829  [345664/467150]\n",
      "loss: 1.204474  [352064/467150]\n",
      "loss: 1.276807  [358464/467150]\n",
      "loss: 2.125752  [364864/467150]\n",
      "loss: 1.688329  [371264/467150]\n",
      "loss: 1.205568  [377664/467150]\n",
      "loss: 0.680350  [384064/467150]\n",
      "loss: 1.124292  [390464/467150]\n",
      "loss: 0.809634  [396864/467150]\n",
      "loss: 0.971288  [403264/467150]\n",
      "loss: 1.466542  [409664/467150]\n",
      "loss: 1.187177  [416064/467150]\n",
      "loss: 1.627254  [422464/467150]\n",
      "loss: 1.698841  [428864/467150]\n",
      "loss: 1.728757  [435264/467150]\n",
      "loss: 1.153280  [441664/467150]\n",
      "loss: 0.838966  [448064/467150]\n",
      "loss: 1.738295  [454464/467150]\n",
      "loss: 1.530503  [460864/467150]\n",
      "Training time: 658.505666\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 1.841413\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7735e-04.\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.065602  [   64/467150]\n",
      "loss: 1.445715  [ 6464/467150]\n",
      "loss: 1.166846  [12864/467150]\n",
      "loss: 1.090483  [19264/467150]\n",
      "loss: 1.058892  [25664/467150]\n",
      "loss: 2.010051  [32064/467150]\n",
      "loss: 1.026058  [38464/467150]\n",
      "loss: 1.944318  [44864/467150]\n",
      "loss: 1.143996  [51264/467150]\n",
      "loss: 1.826419  [57664/467150]\n",
      "loss: 0.871819  [64064/467150]\n",
      "loss: 1.361886  [70464/467150]\n",
      "loss: 1.900049  [76864/467150]\n",
      "loss: 1.370473  [83264/467150]\n",
      "loss: 1.135185  [89664/467150]\n",
      "loss: 0.846484  [96064/467150]\n",
      "loss: 1.764115  [102464/467150]\n",
      "loss: 1.119362  [108864/467150]\n",
      "loss: 1.707271  [115264/467150]\n",
      "loss: 2.266682  [121664/467150]\n",
      "loss: 1.373276  [128064/467150]\n",
      "loss: 1.821357  [134464/467150]\n",
      "loss: 2.357595  [140864/467150]\n",
      "loss: 1.424142  [147264/467150]\n",
      "loss: 1.534722  [153664/467150]\n",
      "loss: 1.625913  [160064/467150]\n",
      "loss: 2.096082  [166464/467150]\n",
      "loss: 1.116486  [172864/467150]\n",
      "loss: 1.437651  [179264/467150]\n",
      "loss: 2.024346  [185664/467150]\n",
      "loss: 1.173842  [192064/467150]\n",
      "loss: 1.250156  [198464/467150]\n",
      "loss: 1.009968  [204864/467150]\n",
      "loss: 1.257518  [211264/467150]\n",
      "loss: 1.051990  [217664/467150]\n",
      "loss: 1.346845  [224064/467150]\n",
      "loss: 1.307635  [230464/467150]\n",
      "loss: 1.821097  [236864/467150]\n",
      "loss: 1.504032  [243264/467150]\n",
      "loss: 2.075918  [249664/467150]\n",
      "loss: 1.556045  [256064/467150]\n",
      "loss: 1.891342  [262464/467150]\n",
      "loss: 1.697299  [268864/467150]\n",
      "loss: 2.318304  [275264/467150]\n",
      "loss: 1.602826  [281664/467150]\n",
      "loss: 1.891877  [288064/467150]\n",
      "loss: 1.464211  [294464/467150]\n",
      "loss: 1.899580  [300864/467150]\n",
      "loss: 1.823797  [307264/467150]\n",
      "loss: 1.871618  [313664/467150]\n",
      "loss: 1.278623  [320064/467150]\n",
      "loss: 1.722115  [326464/467150]\n",
      "loss: 2.015369  [332864/467150]\n",
      "loss: 1.250593  [339264/467150]\n",
      "loss: 1.135278  [345664/467150]\n",
      "loss: 1.148745  [352064/467150]\n",
      "loss: 1.273806  [358464/467150]\n",
      "loss: 2.334793  [364864/467150]\n",
      "loss: 1.416376  [371264/467150]\n",
      "loss: 1.169419  [377664/467150]\n",
      "loss: 0.790586  [384064/467150]\n",
      "loss: 1.148720  [390464/467150]\n",
      "loss: 0.806294  [396864/467150]\n",
      "loss: 1.025945  [403264/467150]\n",
      "loss: 1.446556  [409664/467150]\n",
      "loss: 1.173150  [416064/467150]\n",
      "loss: 1.882012  [422464/467150]\n",
      "loss: 1.844621  [428864/467150]\n",
      "loss: 1.737693  [435264/467150]\n",
      "loss: 1.048078  [441664/467150]\n",
      "loss: 0.837360  [448064/467150]\n",
      "loss: 1.689403  [454464/467150]\n",
      "loss: 1.251131  [460864/467150]\n",
      "Training time: 659.040596\n",
      "Test Error: \n",
      " Accuracy: 41.8%, Avg loss: 1.833125\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5849e-04.\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.062978  [   64/467150]\n",
      "loss: 1.379359  [ 6464/467150]\n",
      "loss: 1.218804  [12864/467150]\n",
      "loss: 1.091584  [19264/467150]\n",
      "loss: 1.089610  [25664/467150]\n",
      "loss: 2.130349  [32064/467150]\n",
      "loss: 1.033877  [38464/467150]\n",
      "loss: 1.618126  [44864/467150]\n",
      "loss: 0.990497  [51264/467150]\n",
      "loss: 1.677105  [57664/467150]\n",
      "loss: 0.946363  [64064/467150]\n",
      "loss: 1.376409  [70464/467150]\n",
      "loss: 1.625915  [76864/467150]\n",
      "loss: 1.335736  [83264/467150]\n",
      "loss: 1.133163  [89664/467150]\n",
      "loss: 0.788374  [96064/467150]\n",
      "loss: 1.816376  [102464/467150]\n",
      "loss: 1.130147  [108864/467150]\n",
      "loss: 1.535108  [115264/467150]\n",
      "loss: 2.426866  [121664/467150]\n",
      "loss: 1.258626  [128064/467150]\n",
      "loss: 1.809132  [134464/467150]\n",
      "loss: 2.178537  [140864/467150]\n",
      "loss: 1.659519  [147264/467150]\n",
      "loss: 1.640424  [153664/467150]\n",
      "loss: 1.460459  [160064/467150]\n",
      "loss: 2.079087  [166464/467150]\n",
      "loss: 1.170839  [172864/467150]\n",
      "loss: 1.527585  [179264/467150]\n",
      "loss: 1.766035  [185664/467150]\n",
      "loss: 1.094290  [192064/467150]\n",
      "loss: 1.185801  [198464/467150]\n",
      "loss: 0.992496  [204864/467150]\n",
      "loss: 1.276774  [211264/467150]\n",
      "loss: 1.030943  [217664/467150]\n",
      "loss: 1.307943  [224064/467150]\n",
      "loss: 2.267858  [230464/467150]\n",
      "loss: 1.355025  [236864/467150]\n",
      "loss: 1.437222  [243264/467150]\n",
      "loss: 2.352812  [249664/467150]\n",
      "loss: 1.779304  [256064/467150]\n",
      "loss: 1.998478  [262464/467150]\n",
      "loss: 1.574634  [268864/467150]\n",
      "loss: 2.427272  [275264/467150]\n",
      "loss: 1.226038  [281664/467150]\n",
      "loss: 1.772503  [288064/467150]\n",
      "loss: 1.739854  [294464/467150]\n",
      "loss: 1.974286  [300864/467150]\n",
      "loss: 1.673270  [307264/467150]\n",
      "loss: 1.679823  [313664/467150]\n",
      "loss: 1.288633  [320064/467150]\n",
      "loss: 1.548141  [326464/467150]\n",
      "loss: 2.250844  [332864/467150]\n",
      "loss: 1.318199  [339264/467150]\n",
      "loss: 1.313893  [345664/467150]\n",
      "loss: 1.194026  [352064/467150]\n",
      "loss: 1.303679  [358464/467150]\n",
      "loss: 1.988091  [364864/467150]\n",
      "loss: 1.406967  [371264/467150]\n",
      "loss: 1.238758  [377664/467150]\n",
      "loss: 0.738845  [384064/467150]\n",
      "loss: 1.148573  [390464/467150]\n",
      "loss: 0.715595  [396864/467150]\n",
      "loss: 1.787054  [403264/467150]\n",
      "loss: 1.540846  [409664/467150]\n",
      "loss: 1.167653  [416064/467150]\n",
      "loss: 2.067071  [422464/467150]\n",
      "loss: 1.562732  [428864/467150]\n",
      "loss: 1.720885  [435264/467150]\n",
      "loss: 1.204607  [441664/467150]\n",
      "loss: 0.833110  [448064/467150]\n",
      "loss: 1.812676  [454464/467150]\n",
      "loss: 1.340891  [460864/467150]\n",
      "Training time: 658.093711\n",
      "Test Error: \n",
      " Accuracy: 41.0%, Avg loss: 1.835366\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4056e-04.\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.050584  [   64/467150]\n",
      "loss: 1.431913  [ 6464/467150]\n",
      "loss: 1.203973  [12864/467150]\n",
      "loss: 1.080000  [19264/467150]\n",
      "loss: 0.981183  [25664/467150]\n",
      "loss: 2.020557  [32064/467150]\n",
      "loss: 1.029666  [38464/467150]\n",
      "loss: 1.904592  [44864/467150]\n",
      "loss: 1.142562  [51264/467150]\n",
      "loss: 2.083702  [57664/467150]\n",
      "loss: 0.927147  [64064/467150]\n",
      "loss: 1.417759  [70464/467150]\n",
      "loss: 1.567450  [76864/467150]\n",
      "loss: 1.340828  [83264/467150]\n",
      "loss: 1.200884  [89664/467150]\n",
      "loss: 0.830779  [96064/467150]\n",
      "loss: 1.848191  [102464/467150]\n",
      "loss: 1.105808  [108864/467150]\n",
      "loss: 1.242682  [115264/467150]\n",
      "loss: 2.463083  [121664/467150]\n",
      "loss: 1.295888  [128064/467150]\n",
      "loss: 1.977367  [134464/467150]\n",
      "loss: 2.473085  [140864/467150]\n",
      "loss: 1.155562  [147264/467150]\n",
      "loss: 1.479545  [153664/467150]\n",
      "loss: 1.413435  [160064/467150]\n",
      "loss: 1.731259  [166464/467150]\n",
      "loss: 1.076165  [172864/467150]\n",
      "loss: 1.363985  [179264/467150]\n",
      "loss: 1.703964  [185664/467150]\n",
      "loss: 1.084221  [192064/467150]\n",
      "loss: 1.330270  [198464/467150]\n",
      "loss: 0.951131  [204864/467150]\n",
      "loss: 1.761984  [211264/467150]\n",
      "loss: 1.002660  [217664/467150]\n",
      "loss: 1.783729  [224064/467150]\n",
      "loss: 1.863448  [230464/467150]\n",
      "loss: 1.647103  [236864/467150]\n",
      "loss: 1.513395  [243264/467150]\n",
      "loss: 2.315753  [249664/467150]\n",
      "loss: 1.713654  [256064/467150]\n",
      "loss: 2.035192  [262464/467150]\n",
      "loss: 1.930442  [268864/467150]\n",
      "loss: 2.189752  [275264/467150]\n",
      "loss: 1.700458  [281664/467150]\n",
      "loss: 1.666942  [288064/467150]\n",
      "loss: 1.595928  [294464/467150]\n",
      "loss: 2.097800  [300864/467150]\n",
      "loss: 1.975054  [307264/467150]\n",
      "loss: 1.773557  [313664/467150]\n",
      "loss: 1.277897  [320064/467150]\n",
      "loss: 1.775695  [326464/467150]\n",
      "loss: 2.076588  [332864/467150]\n",
      "loss: 0.956067  [339264/467150]\n",
      "loss: 1.303916  [345664/467150]\n",
      "loss: 1.181227  [352064/467150]\n",
      "loss: 1.299076  [358464/467150]\n",
      "loss: 1.989465  [364864/467150]\n",
      "loss: 1.491938  [371264/467150]\n",
      "loss: 1.237673  [377664/467150]\n",
      "loss: 0.725814  [384064/467150]\n",
      "loss: 1.150573  [390464/467150]\n",
      "loss: 2.109000  [396864/467150]\n",
      "loss: 0.875453  [403264/467150]\n",
      "loss: 1.530487  [409664/467150]\n",
      "loss: 1.105028  [416064/467150]\n",
      "loss: 1.824292  [422464/467150]\n",
      "loss: 1.660787  [428864/467150]\n",
      "loss: 1.738393  [435264/467150]\n",
      "loss: 1.086592  [441664/467150]\n",
      "loss: 0.849854  [448064/467150]\n",
      "loss: 1.145502  [454464/467150]\n",
      "loss: 1.203985  [460864/467150]\n",
      "Training time: 658.386518\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 1.832095\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2353e-04.\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.045971  [   64/467150]\n",
      "loss: 1.421965  [ 6464/467150]\n",
      "loss: 1.336336  [12864/467150]\n",
      "loss: 1.104905  [19264/467150]\n",
      "loss: 0.977212  [25664/467150]\n",
      "loss: 2.058424  [32064/467150]\n",
      "loss: 1.000763  [38464/467150]\n",
      "loss: 1.616128  [44864/467150]\n",
      "loss: 1.038918  [51264/467150]\n",
      "loss: 1.689278  [57664/467150]\n",
      "loss: 0.928697  [64064/467150]\n",
      "loss: 1.400609  [70464/467150]\n",
      "loss: 1.843511  [76864/467150]\n",
      "loss: 1.431143  [83264/467150]\n",
      "loss: 1.250378  [89664/467150]\n",
      "loss: 0.761848  [96064/467150]\n",
      "loss: 1.703005  [102464/467150]\n",
      "loss: 1.166642  [108864/467150]\n",
      "loss: 1.222658  [115264/467150]\n",
      "loss: 2.363768  [121664/467150]\n",
      "loss: 1.475548  [128064/467150]\n",
      "loss: 1.807695  [134464/467150]\n",
      "loss: 2.435136  [140864/467150]\n",
      "loss: 1.300067  [147264/467150]\n",
      "loss: 1.467142  [153664/467150]\n",
      "loss: 1.415686  [160064/467150]\n",
      "loss: 2.219845  [166464/467150]\n",
      "loss: 1.197948  [172864/467150]\n",
      "loss: 1.393311  [179264/467150]\n",
      "loss: 1.933201  [185664/467150]\n",
      "loss: 1.007905  [192064/467150]\n",
      "loss: 1.119174  [198464/467150]\n",
      "loss: 1.081554  [204864/467150]\n",
      "loss: 1.137275  [211264/467150]\n",
      "loss: 1.022219  [217664/467150]\n",
      "loss: 1.265905  [224064/467150]\n",
      "loss: 1.180392  [230464/467150]\n",
      "loss: 2.051242  [236864/467150]\n",
      "loss: 1.421344  [243264/467150]\n",
      "loss: 2.270784  [249664/467150]\n",
      "loss: 1.684682  [256064/467150]\n",
      "loss: 1.829685  [262464/467150]\n",
      "loss: 1.584754  [268864/467150]\n",
      "loss: 2.351960  [275264/467150]\n",
      "loss: 1.374802  [281664/467150]\n",
      "loss: 1.670292  [288064/467150]\n",
      "loss: 2.019258  [294464/467150]\n",
      "loss: 2.008221  [300864/467150]\n",
      "loss: 1.944436  [307264/467150]\n",
      "loss: 1.865002  [313664/467150]\n",
      "loss: 1.274205  [320064/467150]\n",
      "loss: 1.738563  [326464/467150]\n",
      "loss: 1.545560  [332864/467150]\n",
      "loss: 1.140578  [339264/467150]\n",
      "loss: 1.225032  [345664/467150]\n",
      "loss: 1.154157  [352064/467150]\n",
      "loss: 1.267143  [358464/467150]\n",
      "loss: 2.288438  [364864/467150]\n",
      "loss: 1.531499  [371264/467150]\n",
      "loss: 1.196278  [377664/467150]\n",
      "loss: 0.919612  [384064/467150]\n",
      "loss: 1.190529  [390464/467150]\n",
      "loss: 0.912219  [396864/467150]\n",
      "loss: 1.286061  [403264/467150]\n",
      "loss: 1.629355  [409664/467150]\n",
      "loss: 1.087891  [416064/467150]\n",
      "loss: 2.009000  [422464/467150]\n",
      "loss: 1.309826  [428864/467150]\n",
      "loss: 1.766058  [435264/467150]\n",
      "loss: 1.077207  [441664/467150]\n",
      "loss: 0.853259  [448064/467150]\n",
      "loss: 1.201250  [454464/467150]\n",
      "loss: 1.222721  [460864/467150]\n",
      "Training time: 658.743052\n",
      "Test Error: \n",
      " Accuracy: 41.9%, Avg loss: 1.835610\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0736e-04.\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.033771  [   64/467150]\n",
      "loss: 1.633448  [ 6464/467150]\n",
      "loss: 1.702818  [12864/467150]\n",
      "loss: 1.105547  [19264/467150]\n",
      "loss: 0.888146  [25664/467150]\n",
      "loss: 1.891971  [32064/467150]\n",
      "loss: 1.024970  [38464/467150]\n",
      "loss: 1.787800  [44864/467150]\n",
      "loss: 0.992508  [51264/467150]\n",
      "loss: 1.684222  [57664/467150]\n",
      "loss: 1.198017  [64064/467150]\n",
      "loss: 1.540042  [70464/467150]\n",
      "loss: 2.118695  [76864/467150]\n",
      "loss: 1.344372  [83264/467150]\n",
      "loss: 1.288205  [89664/467150]\n",
      "loss: 0.868498  [96064/467150]\n",
      "loss: 1.751655  [102464/467150]\n",
      "loss: 1.102394  [108864/467150]\n",
      "loss: 1.368209  [115264/467150]\n",
      "loss: 2.373620  [121664/467150]\n",
      "loss: 1.394371  [128064/467150]\n",
      "loss: 1.783261  [134464/467150]\n",
      "loss: 2.283725  [140864/467150]\n",
      "loss: 1.665622  [147264/467150]\n",
      "loss: 1.087540  [153664/467150]\n",
      "loss: 1.352855  [160064/467150]\n",
      "loss: 2.055238  [166464/467150]\n",
      "loss: 1.087991  [172864/467150]\n",
      "loss: 1.443650  [179264/467150]\n",
      "loss: 1.906792  [185664/467150]\n",
      "loss: 0.998505  [192064/467150]\n",
      "loss: 0.998631  [198464/467150]\n",
      "loss: 1.187943  [204864/467150]\n",
      "loss: 1.137945  [211264/467150]\n",
      "loss: 1.017382  [217664/467150]\n",
      "loss: 1.274333  [224064/467150]\n",
      "loss: 1.195638  [230464/467150]\n",
      "loss: 1.942623  [236864/467150]\n",
      "loss: 1.380703  [243264/467150]\n",
      "loss: 2.413109  [249664/467150]\n",
      "loss: 1.772765  [256064/467150]\n",
      "loss: 1.840082  [262464/467150]\n",
      "loss: 2.017039  [268864/467150]\n",
      "loss: 2.469113  [275264/467150]\n",
      "loss: 1.366144  [281664/467150]\n",
      "loss: 1.602278  [288064/467150]\n",
      "loss: 1.803981  [294464/467150]\n",
      "loss: 1.888904  [300864/467150]\n",
      "loss: 2.039205  [307264/467150]\n",
      "loss: 2.042719  [313664/467150]\n",
      "loss: 1.264213  [320064/467150]\n",
      "loss: 1.680801  [326464/467150]\n",
      "loss: 2.077067  [332864/467150]\n",
      "loss: 1.220118  [339264/467150]\n",
      "loss: 1.040373  [345664/467150]\n",
      "loss: 1.557648  [352064/467150]\n",
      "loss: 1.251371  [358464/467150]\n",
      "loss: 1.946867  [364864/467150]\n",
      "loss: 1.414537  [371264/467150]\n",
      "loss: 1.417152  [377664/467150]\n",
      "loss: 0.704421  [384064/467150]\n",
      "loss: 1.179189  [390464/467150]\n",
      "loss: 0.747933  [396864/467150]\n",
      "loss: 0.904033  [403264/467150]\n",
      "loss: 1.472838  [409664/467150]\n",
      "loss: 1.109426  [416064/467150]\n",
      "loss: 2.006401  [422464/467150]\n",
      "loss: 1.949980  [428864/467150]\n",
      "loss: 1.812065  [435264/467150]\n",
      "loss: 1.032462  [441664/467150]\n",
      "loss: 0.902123  [448064/467150]\n",
      "loss: 1.347612  [454464/467150]\n",
      "loss: 1.060497  [460864/467150]\n",
      "Training time: 658.544565\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.831325\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9199e-04.\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.032633  [   64/467150]\n",
      "loss: 1.816124  [ 6464/467150]\n",
      "loss: 1.638634  [12864/467150]\n",
      "loss: 1.098008  [19264/467150]\n",
      "loss: 0.906673  [25664/467150]\n",
      "loss: 1.965089  [32064/467150]\n",
      "loss: 1.048044  [38464/467150]\n",
      "loss: 1.626136  [44864/467150]\n",
      "loss: 0.992023  [51264/467150]\n",
      "loss: 1.915782  [57664/467150]\n",
      "loss: 0.993113  [64064/467150]\n",
      "loss: 1.649933  [70464/467150]\n",
      "loss: 1.773277  [76864/467150]\n",
      "loss: 1.364115  [83264/467150]\n",
      "loss: 1.267948  [89664/467150]\n",
      "loss: 1.066840  [96064/467150]\n",
      "loss: 1.721852  [102464/467150]\n",
      "loss: 1.108115  [108864/467150]\n",
      "loss: 1.373459  [115264/467150]\n",
      "loss: 2.448990  [121664/467150]\n",
      "loss: 1.302203  [128064/467150]\n",
      "loss: 1.586836  [134464/467150]\n",
      "loss: 2.308637  [140864/467150]\n",
      "loss: 1.769802  [147264/467150]\n",
      "loss: 0.929267  [153664/467150]\n",
      "loss: 1.268846  [160064/467150]\n",
      "loss: 2.091720  [166464/467150]\n",
      "loss: 1.223901  [172864/467150]\n",
      "loss: 1.452553  [179264/467150]\n",
      "loss: 1.779945  [185664/467150]\n",
      "loss: 1.030876  [192064/467150]\n",
      "loss: 1.037549  [198464/467150]\n",
      "loss: 1.128451  [204864/467150]\n",
      "loss: 1.259063  [211264/467150]\n",
      "loss: 0.996880  [217664/467150]\n",
      "loss: 1.129906  [224064/467150]\n",
      "loss: 1.281535  [230464/467150]\n",
      "loss: 2.086835  [236864/467150]\n",
      "loss: 1.419550  [243264/467150]\n",
      "loss: 2.538998  [249664/467150]\n",
      "loss: 1.692144  [256064/467150]\n",
      "loss: 1.893114  [262464/467150]\n",
      "loss: 1.905293  [268864/467150]\n",
      "loss: 2.119341  [275264/467150]\n",
      "loss: 1.481425  [281664/467150]\n",
      "loss: 1.661568  [288064/467150]\n",
      "loss: 1.826426  [294464/467150]\n",
      "loss: 1.525385  [300864/467150]\n",
      "loss: 1.720217  [307264/467150]\n",
      "loss: 1.925137  [313664/467150]\n",
      "loss: 1.302939  [320064/467150]\n",
      "loss: 1.582455  [326464/467150]\n",
      "loss: 2.037362  [332864/467150]\n",
      "loss: 1.044610  [339264/467150]\n",
      "loss: 1.043712  [345664/467150]\n",
      "loss: 1.144437  [352064/467150]\n",
      "loss: 1.233212  [358464/467150]\n",
      "loss: 1.878709  [364864/467150]\n",
      "loss: 1.399866  [371264/467150]\n",
      "loss: 1.231427  [377664/467150]\n",
      "loss: 0.724462  [384064/467150]\n",
      "loss: 1.171865  [390464/467150]\n",
      "loss: 0.671068  [396864/467150]\n",
      "loss: 0.895622  [403264/467150]\n",
      "loss: 1.697053  [409664/467150]\n",
      "loss: 1.109201  [416064/467150]\n",
      "loss: 1.825176  [422464/467150]\n",
      "loss: 1.671934  [428864/467150]\n",
      "loss: 1.722982  [435264/467150]\n",
      "loss: 1.320363  [441664/467150]\n",
      "loss: 0.841249  [448064/467150]\n",
      "loss: 1.327207  [454464/467150]\n",
      "loss: 1.349385  [460864/467150]\n",
      "Training time: 658.206485\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 1.828414\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7739e-04.\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.040290  [   64/467150]\n",
      "loss: 1.620798  [ 6464/467150]\n",
      "loss: 1.017502  [12864/467150]\n",
      "loss: 1.088670  [19264/467150]\n",
      "loss: 0.859755  [25664/467150]\n",
      "loss: 2.142434  [32064/467150]\n",
      "loss: 1.038287  [38464/467150]\n",
      "loss: 2.065841  [44864/467150]\n",
      "loss: 0.977975  [51264/467150]\n",
      "loss: 1.597575  [57664/467150]\n",
      "loss: 0.994334  [64064/467150]\n",
      "loss: 1.733337  [70464/467150]\n",
      "loss: 1.990709  [76864/467150]\n",
      "loss: 1.489051  [83264/467150]\n",
      "loss: 1.305323  [89664/467150]\n",
      "loss: 0.786891  [96064/467150]\n",
      "loss: 1.781884  [102464/467150]\n",
      "loss: 1.106148  [108864/467150]\n",
      "loss: 1.342103  [115264/467150]\n",
      "loss: 2.458903  [121664/467150]\n",
      "loss: 1.333733  [128064/467150]\n",
      "loss: 1.468914  [134464/467150]\n",
      "loss: 2.390964  [140864/467150]\n",
      "loss: 1.676878  [147264/467150]\n",
      "loss: 0.901069  [153664/467150]\n",
      "loss: 1.419949  [160064/467150]\n",
      "loss: 2.205794  [166464/467150]\n",
      "loss: 1.314177  [172864/467150]\n",
      "loss: 1.551926  [179264/467150]\n",
      "loss: 1.926268  [185664/467150]\n",
      "loss: 1.053854  [192064/467150]\n",
      "loss: 1.250011  [198464/467150]\n",
      "loss: 0.973989  [204864/467150]\n",
      "loss: 1.450889  [211264/467150]\n",
      "loss: 1.029126  [217664/467150]\n",
      "loss: 1.147576  [224064/467150]\n",
      "loss: 2.112309  [230464/467150]\n",
      "loss: 1.868949  [236864/467150]\n",
      "loss: 1.436439  [243264/467150]\n",
      "loss: 2.298027  [249664/467150]\n",
      "loss: 1.915508  [256064/467150]\n",
      "loss: 1.945317  [262464/467150]\n",
      "loss: 1.800894  [268864/467150]\n",
      "loss: 2.306707  [275264/467150]\n",
      "loss: 1.603580  [281664/467150]\n",
      "loss: 1.583439  [288064/467150]\n",
      "loss: 1.654889  [294464/467150]\n",
      "loss: 1.777361  [300864/467150]\n",
      "loss: 1.916013  [307264/467150]\n",
      "loss: 1.960453  [313664/467150]\n",
      "loss: 1.286732  [320064/467150]\n",
      "loss: 1.640661  [326464/467150]\n",
      "loss: 2.285173  [332864/467150]\n",
      "loss: 1.017057  [339264/467150]\n",
      "loss: 1.077730  [345664/467150]\n",
      "loss: 1.166139  [352064/467150]\n",
      "loss: 1.234309  [358464/467150]\n",
      "loss: 2.290328  [364864/467150]\n",
      "loss: 1.381268  [371264/467150]\n",
      "loss: 1.213045  [377664/467150]\n",
      "loss: 0.708512  [384064/467150]\n",
      "loss: 1.153060  [390464/467150]\n",
      "loss: 0.699758  [396864/467150]\n",
      "loss: 1.068468  [403264/467150]\n",
      "loss: 1.513666  [409664/467150]\n",
      "loss: 1.214663  [416064/467150]\n",
      "loss: 1.793600  [422464/467150]\n",
      "loss: 1.629717  [428864/467150]\n",
      "loss: 1.878008  [435264/467150]\n",
      "loss: 1.249488  [441664/467150]\n",
      "loss: 0.850547  [448064/467150]\n",
      "loss: 1.397500  [454464/467150]\n",
      "loss: 1.045005  [460864/467150]\n",
      "Training time: 657.630646\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 1.829179\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6352e-04.\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.039035  [   64/467150]\n",
      "loss: 1.396952  [ 6464/467150]\n",
      "loss: 1.060152  [12864/467150]\n",
      "loss: 1.082774  [19264/467150]\n",
      "loss: 0.933579  [25664/467150]\n",
      "loss: 2.252964  [32064/467150]\n",
      "loss: 1.125218  [38464/467150]\n",
      "loss: 1.804659  [44864/467150]\n",
      "loss: 0.996210  [51264/467150]\n",
      "loss: 1.540035  [57664/467150]\n",
      "loss: 0.835451  [64064/467150]\n",
      "loss: 1.673806  [70464/467150]\n",
      "loss: 2.034408  [76864/467150]\n",
      "loss: 1.473023  [83264/467150]\n",
      "loss: 1.177292  [89664/467150]\n",
      "loss: 0.792145  [96064/467150]\n",
      "loss: 2.021170  [102464/467150]\n",
      "loss: 1.136354  [108864/467150]\n",
      "loss: 1.290919  [115264/467150]\n",
      "loss: 2.413485  [121664/467150]\n",
      "loss: 1.362506  [128064/467150]\n",
      "loss: 1.513109  [134464/467150]\n",
      "loss: 2.288137  [140864/467150]\n",
      "loss: 1.909644  [147264/467150]\n",
      "loss: 0.893195  [153664/467150]\n",
      "loss: 1.314303  [160064/467150]\n",
      "loss: 2.093729  [166464/467150]\n",
      "loss: 1.242250  [172864/467150]\n",
      "loss: 1.492793  [179264/467150]\n",
      "loss: 1.859300  [185664/467150]\n",
      "loss: 1.125500  [192064/467150]\n",
      "loss: 1.189318  [198464/467150]\n",
      "loss: 0.902996  [204864/467150]\n",
      "loss: 1.065835  [211264/467150]\n",
      "loss: 1.039688  [217664/467150]\n",
      "loss: 1.218892  [224064/467150]\n",
      "loss: 1.987763  [230464/467150]\n",
      "loss: 1.743041  [236864/467150]\n",
      "loss: 1.463566  [243264/467150]\n",
      "loss: 2.129994  [249664/467150]\n",
      "loss: 1.652157  [256064/467150]\n",
      "loss: 1.798638  [262464/467150]\n",
      "loss: 1.900976  [268864/467150]\n",
      "loss: 2.250611  [275264/467150]\n",
      "loss: 1.468862  [281664/467150]\n",
      "loss: 1.663127  [288064/467150]\n",
      "loss: 1.756129  [294464/467150]\n",
      "loss: 1.914300  [300864/467150]\n",
      "loss: 1.741821  [307264/467150]\n",
      "loss: 1.994772  [313664/467150]\n",
      "loss: 1.262147  [320064/467150]\n",
      "loss: 1.730611  [326464/467150]\n",
      "loss: 1.913718  [332864/467150]\n",
      "loss: 0.923762  [339264/467150]\n",
      "loss: 1.229177  [345664/467150]\n",
      "loss: 1.164453  [352064/467150]\n",
      "loss: 1.212723  [358464/467150]\n",
      "loss: 2.041957  [364864/467150]\n",
      "loss: 1.347793  [371264/467150]\n",
      "loss: 1.316584  [377664/467150]\n",
      "loss: 0.961399  [384064/467150]\n",
      "loss: 1.167127  [390464/467150]\n",
      "loss: 0.767762  [396864/467150]\n",
      "loss: 0.844780  [403264/467150]\n",
      "loss: 1.505871  [409664/467150]\n",
      "loss: 1.200127  [416064/467150]\n",
      "loss: 1.693793  [422464/467150]\n",
      "loss: 1.612224  [428864/467150]\n",
      "loss: 1.720067  [435264/467150]\n",
      "loss: 1.170692  [441664/467150]\n",
      "loss: 0.889639  [448064/467150]\n",
      "loss: 1.267080  [454464/467150]\n",
      "loss: 1.067513  [460864/467150]\n",
      "Training time: 659.443196\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.832979\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5034e-04.\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.038741  [   64/467150]\n",
      "loss: 1.712469  [ 6464/467150]\n",
      "loss: 1.598436  [12864/467150]\n",
      "loss: 1.080116  [19264/467150]\n",
      "loss: 0.837138  [25664/467150]\n",
      "loss: 1.982835  [32064/467150]\n",
      "loss: 1.098252  [38464/467150]\n",
      "loss: 2.113137  [44864/467150]\n",
      "loss: 1.010992  [51264/467150]\n",
      "loss: 1.405363  [57664/467150]\n",
      "loss: 1.085110  [64064/467150]\n",
      "loss: 1.651087  [70464/467150]\n",
      "loss: 2.067050  [76864/467150]\n",
      "loss: 1.455426  [83264/467150]\n",
      "loss: 1.210366  [89664/467150]\n",
      "loss: 0.796564  [96064/467150]\n",
      "loss: 1.827258  [102464/467150]\n",
      "loss: 1.118371  [108864/467150]\n",
      "loss: 1.254287  [115264/467150]\n",
      "loss: 2.517565  [121664/467150]\n",
      "loss: 1.276425  [128064/467150]\n",
      "loss: 1.469776  [134464/467150]\n",
      "loss: 2.363351  [140864/467150]\n",
      "loss: 2.041275  [147264/467150]\n",
      "loss: 0.928484  [153664/467150]\n",
      "loss: 1.344069  [160064/467150]\n",
      "loss: 2.112842  [166464/467150]\n",
      "loss: 1.049090  [172864/467150]\n",
      "loss: 1.247445  [179264/467150]\n",
      "loss: 2.008130  [185664/467150]\n",
      "loss: 1.385838  [192064/467150]\n",
      "loss: 1.105691  [198464/467150]\n",
      "loss: 0.991330  [204864/467150]\n",
      "loss: 1.193460  [211264/467150]\n",
      "loss: 1.050806  [217664/467150]\n",
      "loss: 0.891748  [224064/467150]\n",
      "loss: 2.146610  [230464/467150]\n",
      "loss: 1.885353  [236864/467150]\n",
      "loss: 1.438318  [243264/467150]\n",
      "loss: 2.339867  [249664/467150]\n",
      "loss: 1.972430  [256064/467150]\n",
      "loss: 1.807105  [262464/467150]\n",
      "loss: 2.003869  [268864/467150]\n",
      "loss: 2.020732  [275264/467150]\n",
      "loss: 1.507113  [281664/467150]\n",
      "loss: 1.665197  [288064/467150]\n",
      "loss: 1.653336  [294464/467150]\n",
      "loss: 1.869146  [300864/467150]\n",
      "loss: 2.007346  [307264/467150]\n",
      "loss: 2.073505  [313664/467150]\n",
      "loss: 1.306081  [320064/467150]\n",
      "loss: 1.710346  [326464/467150]\n",
      "loss: 1.602939  [332864/467150]\n",
      "loss: 1.079916  [339264/467150]\n",
      "loss: 1.152278  [345664/467150]\n",
      "loss: 1.129013  [352064/467150]\n",
      "loss: 1.214687  [358464/467150]\n",
      "loss: 2.003080  [364864/467150]\n",
      "loss: 1.616409  [371264/467150]\n",
      "loss: 1.298896  [377664/467150]\n",
      "loss: 0.826666  [384064/467150]\n",
      "loss: 1.165259  [390464/467150]\n",
      "loss: 0.971144  [396864/467150]\n",
      "loss: 0.864860  [403264/467150]\n",
      "loss: 1.534247  [409664/467150]\n",
      "loss: 1.096299  [416064/467150]\n",
      "loss: 1.683341  [422464/467150]\n",
      "loss: 1.594449  [428864/467150]\n",
      "loss: 1.708728  [435264/467150]\n",
      "loss: 1.222871  [441664/467150]\n",
      "loss: 0.895170  [448064/467150]\n",
      "loss: 1.691634  [454464/467150]\n",
      "loss: 1.061914  [460864/467150]\n",
      "Training time: 658.571772\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 1.826261\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3783e-04.\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.035132  [   64/467150]\n",
      "loss: 1.741255  [ 6464/467150]\n",
      "loss: 0.897557  [12864/467150]\n",
      "loss: 1.070311  [19264/467150]\n",
      "loss: 0.957076  [25664/467150]\n",
      "loss: 2.164254  [32064/467150]\n",
      "loss: 1.067078  [38464/467150]\n",
      "loss: 1.961917  [44864/467150]\n",
      "loss: 0.993258  [51264/467150]\n",
      "loss: 1.692237  [57664/467150]\n",
      "loss: 0.911087  [64064/467150]\n",
      "loss: 1.610646  [70464/467150]\n",
      "loss: 1.918290  [76864/467150]\n",
      "loss: 1.437446  [83264/467150]\n",
      "loss: 1.190463  [89664/467150]\n",
      "loss: 0.756472  [96064/467150]\n",
      "loss: 1.845726  [102464/467150]\n",
      "loss: 1.104321  [108864/467150]\n",
      "loss: 1.234383  [115264/467150]\n",
      "loss: 2.574795  [121664/467150]\n",
      "loss: 1.251400  [128064/467150]\n",
      "loss: 2.338279  [134464/467150]\n",
      "loss: 2.077423  [140864/467150]\n",
      "loss: 1.811000  [147264/467150]\n",
      "loss: 0.893558  [153664/467150]\n",
      "loss: 1.571472  [160064/467150]\n",
      "loss: 2.119612  [166464/467150]\n",
      "loss: 1.154002  [172864/467150]\n",
      "loss: 1.232028  [179264/467150]\n",
      "loss: 2.044581  [185664/467150]\n",
      "loss: 1.335163  [192064/467150]\n",
      "loss: 0.992164  [198464/467150]\n",
      "loss: 1.110650  [204864/467150]\n",
      "loss: 1.202915  [211264/467150]\n",
      "loss: 1.080373  [217664/467150]\n",
      "loss: 1.454047  [224064/467150]\n",
      "loss: 1.668656  [230464/467150]\n",
      "loss: 1.795285  [236864/467150]\n",
      "loss: 1.430258  [243264/467150]\n",
      "loss: 1.951008  [249664/467150]\n",
      "loss: 1.295786  [256064/467150]\n",
      "loss: 1.824976  [262464/467150]\n",
      "loss: 2.062227  [268864/467150]\n",
      "loss: 2.161131  [275264/467150]\n",
      "loss: 1.417488  [281664/467150]\n",
      "loss: 1.686074  [288064/467150]\n",
      "loss: 1.789319  [294464/467150]\n",
      "loss: 1.925542  [300864/467150]\n",
      "loss: 2.071973  [307264/467150]\n",
      "loss: 2.223857  [313664/467150]\n",
      "loss: 1.270344  [320064/467150]\n",
      "loss: 1.728662  [326464/467150]\n",
      "loss: 1.569620  [332864/467150]\n",
      "loss: 0.958801  [339264/467150]\n",
      "loss: 1.143769  [345664/467150]\n",
      "loss: 1.116463  [352064/467150]\n",
      "loss: 1.200614  [358464/467150]\n",
      "loss: 2.112986  [364864/467150]\n",
      "loss: 1.507860  [371264/467150]\n",
      "loss: 1.329751  [377664/467150]\n",
      "loss: 0.752691  [384064/467150]\n",
      "loss: 1.163038  [390464/467150]\n",
      "loss: 0.829199  [396864/467150]\n",
      "loss: 0.814216  [403264/467150]\n",
      "loss: 1.539654  [409664/467150]\n",
      "loss: 1.090248  [416064/467150]\n",
      "loss: 1.741716  [422464/467150]\n",
      "loss: 1.580141  [428864/467150]\n",
      "loss: 1.714652  [435264/467150]\n",
      "loss: 1.116816  [441664/467150]\n",
      "loss: 0.867859  [448064/467150]\n",
      "loss: 1.265790  [454464/467150]\n",
      "loss: 1.076640  [460864/467150]\n",
      "Training time: 658.663905\n",
      "Test Error: \n",
      " Accuracy: 42.3%, Avg loss: 1.827561\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2594e-04.\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.040932  [   64/467150]\n",
      "loss: 1.785274  [ 6464/467150]\n",
      "loss: 1.097691  [12864/467150]\n",
      "loss: 1.077467  [19264/467150]\n",
      "loss: 0.877384  [25664/467150]\n",
      "loss: 2.252759  [32064/467150]\n",
      "loss: 1.002663  [38464/467150]\n",
      "loss: 1.616843  [44864/467150]\n",
      "loss: 0.986171  [51264/467150]\n",
      "loss: 1.814507  [57664/467150]\n",
      "loss: 0.986511  [64064/467150]\n",
      "loss: 1.450309  [70464/467150]\n",
      "loss: 1.843047  [76864/467150]\n",
      "loss: 1.464555  [83264/467150]\n",
      "loss: 1.133479  [89664/467150]\n",
      "loss: 0.890477  [96064/467150]\n",
      "loss: 1.802683  [102464/467150]\n",
      "loss: 1.112094  [108864/467150]\n",
      "loss: 1.260158  [115264/467150]\n",
      "loss: 2.580649  [121664/467150]\n",
      "loss: 1.248787  [128064/467150]\n",
      "loss: 1.496367  [134464/467150]\n",
      "loss: 2.307771  [140864/467150]\n",
      "loss: 1.910046  [147264/467150]\n",
      "loss: 0.950219  [153664/467150]\n",
      "loss: 1.521656  [160064/467150]\n",
      "loss: 2.355648  [166464/467150]\n",
      "loss: 1.075349  [172864/467150]\n",
      "loss: 1.517762  [179264/467150]\n",
      "loss: 1.679261  [185664/467150]\n",
      "loss: 1.083050  [192064/467150]\n",
      "loss: 1.230056  [198464/467150]\n",
      "loss: 1.089324  [204864/467150]\n",
      "loss: 1.250856  [211264/467150]\n",
      "loss: 1.040856  [217664/467150]\n",
      "loss: 1.439797  [224064/467150]\n",
      "loss: 1.918614  [230464/467150]\n",
      "loss: 1.897701  [236864/467150]\n",
      "loss: 1.416639  [243264/467150]\n",
      "loss: 1.986932  [249664/467150]\n",
      "loss: 1.566397  [256064/467150]\n",
      "loss: 1.945350  [262464/467150]\n",
      "loss: 2.067969  [268864/467150]\n",
      "loss: 2.235827  [275264/467150]\n",
      "loss: 1.412974  [281664/467150]\n",
      "loss: 1.692680  [288064/467150]\n",
      "loss: 2.444117  [294464/467150]\n",
      "loss: 1.991924  [300864/467150]\n",
      "loss: 2.051499  [307264/467150]\n",
      "loss: 2.074823  [313664/467150]\n",
      "loss: 1.308233  [320064/467150]\n",
      "loss: 1.714446  [326464/467150]\n",
      "loss: 1.672797  [332864/467150]\n",
      "loss: 0.967833  [339264/467150]\n",
      "loss: 1.244681  [345664/467150]\n",
      "loss: 1.102262  [352064/467150]\n",
      "loss: 1.203883  [358464/467150]\n",
      "loss: 1.709346  [364864/467150]\n",
      "loss: 1.327776  [371264/467150]\n",
      "loss: 1.190902  [377664/467150]\n",
      "loss: 0.677449  [384064/467150]\n",
      "loss: 1.154278  [390464/467150]\n",
      "loss: 0.726346  [396864/467150]\n",
      "loss: 0.787483  [403264/467150]\n",
      "loss: 1.472378  [409664/467150]\n",
      "loss: 1.096582  [416064/467150]\n",
      "loss: 1.724079  [422464/467150]\n",
      "loss: 1.631283  [428864/467150]\n",
      "loss: 1.742253  [435264/467150]\n",
      "loss: 1.134470  [441664/467150]\n",
      "loss: 0.846761  [448064/467150]\n",
      "loss: 1.676462  [454464/467150]\n",
      "loss: 1.088041  [460864/467150]\n",
      "Training time: 658.16306\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 1.826846\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1464e-04.\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.038432  [   64/467150]\n",
      "loss: 1.655144  [ 6464/467150]\n",
      "loss: 0.868518  [12864/467150]\n",
      "loss: 1.069437  [19264/467150]\n",
      "loss: 0.812936  [25664/467150]\n",
      "loss: 2.269168  [32064/467150]\n",
      "loss: 1.023377  [38464/467150]\n",
      "loss: 1.812827  [44864/467150]\n",
      "loss: 0.995150  [51264/467150]\n",
      "loss: 1.569559  [57664/467150]\n",
      "loss: 0.996510  [64064/467150]\n",
      "loss: 1.615288  [70464/467150]\n",
      "loss: 1.952981  [76864/467150]\n",
      "loss: 1.418866  [83264/467150]\n",
      "loss: 1.154426  [89664/467150]\n",
      "loss: 0.838492  [96064/467150]\n",
      "loss: 1.783333  [102464/467150]\n",
      "loss: 1.103688  [108864/467150]\n",
      "loss: 1.202441  [115264/467150]\n",
      "loss: 2.532696  [121664/467150]\n",
      "loss: 1.248926  [128064/467150]\n",
      "loss: 1.322528  [134464/467150]\n",
      "loss: 2.365629  [140864/467150]\n",
      "loss: 1.631069  [147264/467150]\n",
      "loss: 1.074076  [153664/467150]\n",
      "loss: 1.356948  [160064/467150]\n",
      "loss: 2.213480  [166464/467150]\n",
      "loss: 1.248266  [172864/467150]\n",
      "loss: 1.361134  [179264/467150]\n",
      "loss: 1.804933  [185664/467150]\n",
      "loss: 1.302355  [192064/467150]\n",
      "loss: 1.184562  [198464/467150]\n",
      "loss: 0.940420  [204864/467150]\n",
      "loss: 1.299764  [211264/467150]\n",
      "loss: 1.016157  [217664/467150]\n",
      "loss: 1.245847  [224064/467150]\n",
      "loss: 2.055662  [230464/467150]\n",
      "loss: 1.954951  [236864/467150]\n",
      "loss: 1.433446  [243264/467150]\n",
      "loss: 1.926115  [249664/467150]\n",
      "loss: 1.456124  [256064/467150]\n",
      "loss: 1.917285  [262464/467150]\n",
      "loss: 1.999703  [268864/467150]\n",
      "loss: 2.131250  [275264/467150]\n",
      "loss: 1.415423  [281664/467150]\n",
      "loss: 1.660182  [288064/467150]\n",
      "loss: 2.249074  [294464/467150]\n",
      "loss: 1.965948  [300864/467150]\n",
      "loss: 2.034384  [307264/467150]\n",
      "loss: 2.441558  [313664/467150]\n",
      "loss: 1.246693  [320064/467150]\n",
      "loss: 1.637853  [326464/467150]\n",
      "loss: 1.676190  [332864/467150]\n",
      "loss: 1.017752  [339264/467150]\n",
      "loss: 1.354256  [345664/467150]\n",
      "loss: 1.128271  [352064/467150]\n",
      "loss: 1.218899  [358464/467150]\n",
      "loss: 1.750477  [364864/467150]\n",
      "loss: 1.312136  [371264/467150]\n",
      "loss: 1.383740  [377664/467150]\n",
      "loss: 0.820254  [384064/467150]\n",
      "loss: 1.150433  [390464/467150]\n",
      "loss: 0.650579  [396864/467150]\n",
      "loss: 0.724347  [403264/467150]\n",
      "loss: 1.721960  [409664/467150]\n",
      "loss: 1.116776  [416064/467150]\n",
      "loss: 1.821958  [422464/467150]\n",
      "loss: 1.528244  [428864/467150]\n",
      "loss: 1.739679  [435264/467150]\n",
      "loss: 1.170630  [441664/467150]\n",
      "loss: 0.850020  [448064/467150]\n",
      "loss: 1.647681  [454464/467150]\n",
      "loss: 1.103866  [460864/467150]\n",
      "Training time: 660.084814\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.826384\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0391e-04.\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.040314  [   64/467150]\n",
      "loss: 1.690866  [ 6464/467150]\n",
      "loss: 1.156507  [12864/467150]\n",
      "loss: 1.066194  [19264/467150]\n",
      "loss: 0.923515  [25664/467150]\n",
      "loss: 2.016071  [32064/467150]\n",
      "loss: 1.022185  [38464/467150]\n",
      "loss: 1.701516  [44864/467150]\n",
      "loss: 1.014840  [51264/467150]\n",
      "loss: 1.742249  [57664/467150]\n",
      "loss: 1.196325  [64064/467150]\n",
      "loss: 1.694907  [70464/467150]\n",
      "loss: 1.839939  [76864/467150]\n",
      "loss: 1.347576  [83264/467150]\n",
      "loss: 1.151900  [89664/467150]\n",
      "loss: 0.817364  [96064/467150]\n",
      "loss: 1.900443  [102464/467150]\n",
      "loss: 1.101915  [108864/467150]\n",
      "loss: 1.175267  [115264/467150]\n",
      "loss: 2.518637  [121664/467150]\n",
      "loss: 1.327843  [128064/467150]\n",
      "loss: 1.354958  [134464/467150]\n",
      "loss: 2.279541  [140864/467150]\n",
      "loss: 1.689478  [147264/467150]\n",
      "loss: 0.953673  [153664/467150]\n",
      "loss: 1.405965  [160064/467150]\n",
      "loss: 2.162561  [166464/467150]\n",
      "loss: 1.199201  [172864/467150]\n",
      "loss: 1.411039  [179264/467150]\n",
      "loss: 2.041116  [185664/467150]\n",
      "loss: 1.111022  [192064/467150]\n",
      "loss: 1.131025  [198464/467150]\n",
      "loss: 0.891217  [204864/467150]\n",
      "loss: 1.330635  [211264/467150]\n",
      "loss: 1.018816  [217664/467150]\n",
      "loss: 1.166729  [224064/467150]\n",
      "loss: 0.777203  [230464/467150]\n",
      "loss: 1.796257  [236864/467150]\n",
      "loss: 1.428691  [243264/467150]\n",
      "loss: 1.983143  [249664/467150]\n",
      "loss: 1.359197  [256064/467150]\n",
      "loss: 1.727082  [262464/467150]\n",
      "loss: 1.562582  [268864/467150]\n",
      "loss: 2.168059  [275264/467150]\n",
      "loss: 1.433033  [281664/467150]\n",
      "loss: 1.839373  [288064/467150]\n",
      "loss: 2.502590  [294464/467150]\n",
      "loss: 1.873992  [300864/467150]\n",
      "loss: 1.781463  [307264/467150]\n",
      "loss: 2.557199  [313664/467150]\n",
      "loss: 1.261913  [320064/467150]\n",
      "loss: 1.607035  [326464/467150]\n",
      "loss: 1.799045  [332864/467150]\n",
      "loss: 1.150862  [339264/467150]\n",
      "loss: 1.393661  [345664/467150]\n",
      "loss: 1.137371  [352064/467150]\n",
      "loss: 1.215279  [358464/467150]\n",
      "loss: 1.711324  [364864/467150]\n",
      "loss: 1.532150  [371264/467150]\n",
      "loss: 1.345855  [377664/467150]\n",
      "loss: 0.726284  [384064/467150]\n",
      "loss: 1.148817  [390464/467150]\n",
      "loss: 0.633038  [396864/467150]\n",
      "loss: 0.776268  [403264/467150]\n",
      "loss: 1.425574  [409664/467150]\n",
      "loss: 1.101188  [416064/467150]\n",
      "loss: 1.665952  [422464/467150]\n",
      "loss: 1.593521  [428864/467150]\n",
      "loss: 1.829852  [435264/467150]\n",
      "loss: 1.088922  [441664/467150]\n",
      "loss: 0.846675  [448064/467150]\n",
      "loss: 1.103513  [454464/467150]\n",
      "loss: 1.097481  [460864/467150]\n",
      "Training time: 658.739209\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.825354\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9371e-04.\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.043725  [   64/467150]\n",
      "loss: 1.671874  [ 6464/467150]\n",
      "loss: 1.141170  [12864/467150]\n",
      "loss: 1.069011  [19264/467150]\n",
      "loss: 0.865321  [25664/467150]\n",
      "loss: 1.981394  [32064/467150]\n",
      "loss: 1.018191  [38464/467150]\n",
      "loss: 1.624402  [44864/467150]\n",
      "loss: 1.039208  [51264/467150]\n",
      "loss: 1.662973  [57664/467150]\n",
      "loss: 0.864634  [64064/467150]\n",
      "loss: 1.721156  [70464/467150]\n",
      "loss: 2.225617  [76864/467150]\n",
      "loss: 1.343717  [83264/467150]\n",
      "loss: 1.169473  [89664/467150]\n",
      "loss: 0.809070  [96064/467150]\n",
      "loss: 1.721490  [102464/467150]\n",
      "loss: 1.103361  [108864/467150]\n",
      "loss: 1.141634  [115264/467150]\n",
      "loss: 2.407914  [121664/467150]\n",
      "loss: 1.249979  [128064/467150]\n",
      "loss: 1.557226  [134464/467150]\n",
      "loss: 2.221002  [140864/467150]\n",
      "loss: 1.740435  [147264/467150]\n",
      "loss: 0.978998  [153664/467150]\n",
      "loss: 1.529468  [160064/467150]\n",
      "loss: 2.252507  [166464/467150]\n",
      "loss: 1.127990  [172864/467150]\n",
      "loss: 1.389108  [179264/467150]\n",
      "loss: 1.796922  [185664/467150]\n",
      "loss: 1.134616  [192064/467150]\n",
      "loss: 1.221157  [198464/467150]\n",
      "loss: 0.852166  [204864/467150]\n",
      "loss: 1.284572  [211264/467150]\n",
      "loss: 1.019361  [217664/467150]\n",
      "loss: 1.503930  [224064/467150]\n",
      "loss: 2.517069  [230464/467150]\n",
      "loss: 1.813276  [236864/467150]\n",
      "loss: 1.420116  [243264/467150]\n",
      "loss: 1.942590  [249664/467150]\n",
      "loss: 1.577886  [256064/467150]\n",
      "loss: 1.821569  [262464/467150]\n",
      "loss: 2.201002  [268864/467150]\n",
      "loss: 2.161674  [275264/467150]\n",
      "loss: 1.340355  [281664/467150]\n",
      "loss: 1.874934  [288064/467150]\n",
      "loss: 1.277884  [294464/467150]\n",
      "loss: 1.567207  [300864/467150]\n",
      "loss: 1.984162  [307264/467150]\n",
      "loss: 2.509139  [313664/467150]\n",
      "loss: 1.266228  [320064/467150]\n",
      "loss: 1.509623  [326464/467150]\n",
      "loss: 2.235204  [332864/467150]\n",
      "loss: 1.027865  [339264/467150]\n",
      "loss: 1.175232  [345664/467150]\n",
      "loss: 1.402933  [352064/467150]\n",
      "loss: 1.208143  [358464/467150]\n",
      "loss: 1.754533  [364864/467150]\n",
      "loss: 1.382850  [371264/467150]\n",
      "loss: 1.333753  [377664/467150]\n",
      "loss: 0.703350  [384064/467150]\n",
      "loss: 1.156933  [390464/467150]\n",
      "loss: 0.630673  [396864/467150]\n",
      "loss: 0.776308  [403264/467150]\n",
      "loss: 1.486623  [409664/467150]\n",
      "loss: 1.106047  [416064/467150]\n",
      "loss: 1.750233  [422464/467150]\n",
      "loss: 1.583747  [428864/467150]\n",
      "loss: 1.737457  [435264/467150]\n",
      "loss: 1.261097  [441664/467150]\n",
      "loss: 0.833080  [448064/467150]\n",
      "loss: 1.845998  [454464/467150]\n",
      "loss: 1.204577  [460864/467150]\n",
      "Training time: 658.617122\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.826764\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8403e-04.\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.046855  [   64/467150]\n",
      "loss: 1.632691  [ 6464/467150]\n",
      "loss: 1.588868  [12864/467150]\n",
      "loss: 1.062389  [19264/467150]\n",
      "loss: 0.960757  [25664/467150]\n",
      "loss: 1.986452  [32064/467150]\n",
      "loss: 1.028118  [38464/467150]\n",
      "loss: 1.673810  [44864/467150]\n",
      "loss: 1.036059  [51264/467150]\n",
      "loss: 1.656746  [57664/467150]\n",
      "loss: 0.908437  [64064/467150]\n",
      "loss: 1.659459  [70464/467150]\n",
      "loss: 2.055819  [76864/467150]\n",
      "loss: 1.336507  [83264/467150]\n",
      "loss: 1.174260  [89664/467150]\n",
      "loss: 0.832879  [96064/467150]\n",
      "loss: 1.733127  [102464/467150]\n",
      "loss: 1.097309  [108864/467150]\n",
      "loss: 1.150421  [115264/467150]\n",
      "loss: 2.465325  [121664/467150]\n",
      "loss: 1.238251  [128064/467150]\n",
      "loss: 1.429212  [134464/467150]\n",
      "loss: 2.318647  [140864/467150]\n",
      "loss: 1.767845  [147264/467150]\n",
      "loss: 0.887765  [153664/467150]\n",
      "loss: 1.708665  [160064/467150]\n",
      "loss: 2.319141  [166464/467150]\n",
      "loss: 1.046920  [172864/467150]\n",
      "loss: 1.415752  [179264/467150]\n",
      "loss: 2.065602  [185664/467150]\n",
      "loss: 1.136308  [192064/467150]\n",
      "loss: 1.202943  [198464/467150]\n",
      "loss: 0.956329  [204864/467150]\n",
      "loss: 1.090673  [211264/467150]\n",
      "loss: 1.023423  [217664/467150]\n",
      "loss: 1.657616  [224064/467150]\n",
      "loss: 1.951036  [230464/467150]\n",
      "loss: 1.833033  [236864/467150]\n",
      "loss: 1.414444  [243264/467150]\n",
      "loss: 1.954112  [249664/467150]\n",
      "loss: 1.407536  [256064/467150]\n",
      "loss: 2.091743  [262464/467150]\n",
      "loss: 1.732220  [268864/467150]\n",
      "loss: 2.207903  [275264/467150]\n",
      "loss: 1.301072  [281664/467150]\n",
      "loss: 1.824354  [288064/467150]\n",
      "loss: 2.176534  [294464/467150]\n",
      "loss: 1.755605  [300864/467150]\n",
      "loss: 2.063760  [307264/467150]\n",
      "loss: 2.507753  [313664/467150]\n",
      "loss: 1.258134  [320064/467150]\n",
      "loss: 1.485915  [326464/467150]\n",
      "loss: 2.384021  [332864/467150]\n",
      "loss: 0.912388  [339264/467150]\n",
      "loss: 1.195984  [345664/467150]\n",
      "loss: 1.118989  [352064/467150]\n",
      "loss: 1.223492  [358464/467150]\n",
      "loss: 1.903655  [364864/467150]\n",
      "loss: 1.370561  [371264/467150]\n",
      "loss: 1.314730  [377664/467150]\n",
      "loss: 0.710519  [384064/467150]\n",
      "loss: 1.158429  [390464/467150]\n",
      "loss: 0.633937  [396864/467150]\n",
      "loss: 0.753315  [403264/467150]\n",
      "loss: 1.451938  [409664/467150]\n",
      "loss: 1.088291  [416064/467150]\n",
      "loss: 1.928127  [422464/467150]\n",
      "loss: 1.491317  [428864/467150]\n",
      "loss: 1.783387  [435264/467150]\n",
      "loss: 1.117288  [441664/467150]\n",
      "loss: 0.831330  [448064/467150]\n",
      "loss: 1.823239  [454464/467150]\n",
      "loss: 1.589815  [460864/467150]\n",
      "Training time: 658.642432\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.825165\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7482e-04.\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.051553  [   64/467150]\n",
      "loss: 1.641308  [ 6464/467150]\n",
      "loss: 1.021421  [12864/467150]\n",
      "loss: 1.062517  [19264/467150]\n",
      "loss: 0.959900  [25664/467150]\n",
      "loss: 2.046978  [32064/467150]\n",
      "loss: 1.020709  [38464/467150]\n",
      "loss: 1.580091  [44864/467150]\n",
      "loss: 0.997076  [51264/467150]\n",
      "loss: 1.535485  [57664/467150]\n",
      "loss: 1.035797  [64064/467150]\n",
      "loss: 1.611096  [70464/467150]\n",
      "loss: 1.980222  [76864/467150]\n",
      "loss: 1.344824  [83264/467150]\n",
      "loss: 1.090865  [89664/467150]\n",
      "loss: 0.797149  [96064/467150]\n",
      "loss: 1.851544  [102464/467150]\n",
      "loss: 1.097829  [108864/467150]\n",
      "loss: 1.143362  [115264/467150]\n",
      "loss: 2.549886  [121664/467150]\n",
      "loss: 1.209977  [128064/467150]\n",
      "loss: 1.378445  [134464/467150]\n",
      "loss: 2.281730  [140864/467150]\n",
      "loss: 1.839363  [147264/467150]\n",
      "loss: 1.371279  [153664/467150]\n",
      "loss: 1.621984  [160064/467150]\n",
      "loss: 2.430012  [166464/467150]\n",
      "loss: 0.996550  [172864/467150]\n",
      "loss: 1.491147  [179264/467150]\n",
      "loss: 2.036208  [185664/467150]\n",
      "loss: 1.166597  [192064/467150]\n",
      "loss: 1.156176  [198464/467150]\n",
      "loss: 0.968527  [204864/467150]\n",
      "loss: 1.244843  [211264/467150]\n",
      "loss: 1.024235  [217664/467150]\n",
      "loss: 1.221876  [224064/467150]\n",
      "loss: 1.504200  [230464/467150]\n",
      "loss: 1.793124  [236864/467150]\n",
      "loss: 1.423011  [243264/467150]\n",
      "loss: 2.140329  [249664/467150]\n",
      "loss: 1.525040  [256064/467150]\n",
      "loss: 2.173949  [262464/467150]\n",
      "loss: 2.066895  [268864/467150]\n",
      "loss: 2.226262  [275264/467150]\n",
      "loss: 1.292928  [281664/467150]\n",
      "loss: 1.718131  [288064/467150]\n",
      "loss: 1.712222  [294464/467150]\n",
      "loss: 1.829205  [300864/467150]\n",
      "loss: 1.908743  [307264/467150]\n",
      "loss: 2.726937  [313664/467150]\n",
      "loss: 1.257003  [320064/467150]\n",
      "loss: 1.563140  [326464/467150]\n",
      "loss: 2.309489  [332864/467150]\n",
      "loss: 0.966004  [339264/467150]\n",
      "loss: 1.257517  [345664/467150]\n",
      "loss: 1.164921  [352064/467150]\n",
      "loss: 1.216047  [358464/467150]\n",
      "loss: 1.899104  [364864/467150]\n",
      "loss: 1.392495  [371264/467150]\n",
      "loss: 1.467319  [377664/467150]\n",
      "loss: 0.704130  [384064/467150]\n",
      "loss: 1.158969  [390464/467150]\n",
      "loss: 0.627220  [396864/467150]\n",
      "loss: 0.736318  [403264/467150]\n",
      "loss: 1.533129  [409664/467150]\n",
      "loss: 1.084515  [416064/467150]\n",
      "loss: 1.847827  [422464/467150]\n",
      "loss: 1.615852  [428864/467150]\n",
      "loss: 1.828880  [435264/467150]\n",
      "loss: 1.170683  [441664/467150]\n",
      "loss: 0.836199  [448064/467150]\n",
      "loss: 1.319422  [454464/467150]\n",
      "loss: 1.257635  [460864/467150]\n",
      "Training time: 658.519115\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 1.822247\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6608e-04.\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.057170  [   64/467150]\n",
      "loss: 1.647561  [ 6464/467150]\n",
      "loss: 0.888102  [12864/467150]\n",
      "loss: 1.068582  [19264/467150]\n",
      "loss: 0.902417  [25664/467150]\n",
      "loss: 2.367040  [32064/467150]\n",
      "loss: 1.013829  [38464/467150]\n",
      "loss: 1.577783  [44864/467150]\n",
      "loss: 1.010540  [51264/467150]\n",
      "loss: 1.453507  [57664/467150]\n",
      "loss: 0.829328  [64064/467150]\n",
      "loss: 1.648476  [70464/467150]\n",
      "loss: 2.284838  [76864/467150]\n",
      "loss: 1.338413  [83264/467150]\n",
      "loss: 1.127928  [89664/467150]\n",
      "loss: 0.805706  [96064/467150]\n",
      "loss: 1.723694  [102464/467150]\n",
      "loss: 1.115083  [108864/467150]\n",
      "loss: 1.152413  [115264/467150]\n",
      "loss: 2.598551  [121664/467150]\n",
      "loss: 1.232838  [128064/467150]\n",
      "loss: 1.387309  [134464/467150]\n",
      "loss: 2.181998  [140864/467150]\n",
      "loss: 1.830651  [147264/467150]\n",
      "loss: 0.784142  [153664/467150]\n",
      "loss: 1.515879  [160064/467150]\n",
      "loss: 2.404356  [166464/467150]\n",
      "loss: 1.042561  [172864/467150]\n",
      "loss: 1.379924  [179264/467150]\n",
      "loss: 1.865061  [185664/467150]\n",
      "loss: 1.119027  [192064/467150]\n",
      "loss: 1.204325  [198464/467150]\n",
      "loss: 0.973652  [204864/467150]\n",
      "loss: 1.242986  [211264/467150]\n",
      "loss: 1.021791  [217664/467150]\n",
      "loss: 1.409814  [224064/467150]\n",
      "loss: 1.474039  [230464/467150]\n",
      "loss: 1.827085  [236864/467150]\n",
      "loss: 1.418280  [243264/467150]\n",
      "loss: 2.428680  [249664/467150]\n",
      "loss: 1.375522  [256064/467150]\n",
      "loss: 1.965350  [262464/467150]\n",
      "loss: 1.720862  [268864/467150]\n",
      "loss: 2.249679  [275264/467150]\n",
      "loss: 1.249599  [281664/467150]\n",
      "loss: 1.853427  [288064/467150]\n",
      "loss: 2.275019  [294464/467150]\n",
      "loss: 1.911316  [300864/467150]\n",
      "loss: 1.949802  [307264/467150]\n",
      "loss: 2.622306  [313664/467150]\n",
      "loss: 1.281470  [320064/467150]\n",
      "loss: 1.741062  [326464/467150]\n",
      "loss: 1.811582  [332864/467150]\n",
      "loss: 0.927773  [339264/467150]\n",
      "loss: 1.308874  [345664/467150]\n",
      "loss: 1.140673  [352064/467150]\n",
      "loss: 1.222339  [358464/467150]\n",
      "loss: 2.266870  [364864/467150]\n",
      "loss: 1.646938  [371264/467150]\n",
      "loss: 1.456894  [377664/467150]\n",
      "loss: 0.690264  [384064/467150]\n",
      "loss: 1.181644  [390464/467150]\n",
      "loss: 0.644029  [396864/467150]\n",
      "loss: 0.764942  [403264/467150]\n",
      "loss: 1.382259  [409664/467150]\n",
      "loss: 1.073650  [416064/467150]\n",
      "loss: 1.715290  [422464/467150]\n",
      "loss: 1.597074  [428864/467150]\n",
      "loss: 1.780567  [435264/467150]\n",
      "loss: 1.225700  [441664/467150]\n",
      "loss: 0.836215  [448064/467150]\n",
      "loss: 1.402584  [454464/467150]\n",
      "loss: 1.128439  [460864/467150]\n",
      "Training time: 658.357024\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.824850\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5778e-04.\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.055191  [   64/467150]\n",
      "loss: 1.622857  [ 6464/467150]\n",
      "loss: 1.127944  [12864/467150]\n",
      "loss: 1.066712  [19264/467150]\n",
      "loss: 0.865834  [25664/467150]\n",
      "loss: 2.286068  [32064/467150]\n",
      "loss: 1.009627  [38464/467150]\n",
      "loss: 1.546840  [44864/467150]\n",
      "loss: 1.016952  [51264/467150]\n",
      "loss: 1.557203  [57664/467150]\n",
      "loss: 0.975077  [64064/467150]\n",
      "loss: 1.625152  [70464/467150]\n",
      "loss: 1.953775  [76864/467150]\n",
      "loss: 1.377013  [83264/467150]\n",
      "loss: 1.135176  [89664/467150]\n",
      "loss: 0.850254  [96064/467150]\n",
      "loss: 1.721924  [102464/467150]\n",
      "loss: 1.103610  [108864/467150]\n",
      "loss: 1.200401  [115264/467150]\n",
      "loss: 2.540751  [121664/467150]\n",
      "loss: 1.156993  [128064/467150]\n",
      "loss: 1.442680  [134464/467150]\n",
      "loss: 2.128398  [140864/467150]\n",
      "loss: 1.814784  [147264/467150]\n",
      "loss: 0.819074  [153664/467150]\n",
      "loss: 1.573355  [160064/467150]\n",
      "loss: 2.261205  [166464/467150]\n",
      "loss: 1.003398  [172864/467150]\n",
      "loss: 1.449693  [179264/467150]\n",
      "loss: 1.856210  [185664/467150]\n",
      "loss: 1.130421  [192064/467150]\n",
      "loss: 1.223632  [198464/467150]\n",
      "loss: 0.956958  [204864/467150]\n",
      "loss: 1.275242  [211264/467150]\n",
      "loss: 1.014224  [217664/467150]\n",
      "loss: 1.434367  [224064/467150]\n",
      "loss: 1.529564  [230464/467150]\n",
      "loss: 1.784371  [236864/467150]\n",
      "loss: 1.410951  [243264/467150]\n",
      "loss: 2.434361  [249664/467150]\n",
      "loss: 1.427773  [256064/467150]\n",
      "loss: 2.020298  [262464/467150]\n",
      "loss: 1.621584  [268864/467150]\n",
      "loss: 2.177309  [275264/467150]\n",
      "loss: 1.278720  [281664/467150]\n",
      "loss: 1.848415  [288064/467150]\n",
      "loss: 1.791117  [294464/467150]\n",
      "loss: 1.761942  [300864/467150]\n",
      "loss: 1.922067  [307264/467150]\n",
      "loss: 2.499783  [313664/467150]\n",
      "loss: 1.259997  [320064/467150]\n",
      "loss: 1.749657  [326464/467150]\n",
      "loss: 1.827834  [332864/467150]\n",
      "loss: 1.024289  [339264/467150]\n",
      "loss: 1.256436  [345664/467150]\n",
      "loss: 1.144037  [352064/467150]\n",
      "loss: 1.223058  [358464/467150]\n",
      "loss: 2.279673  [364864/467150]\n",
      "loss: 1.404673  [371264/467150]\n",
      "loss: 1.624747  [377664/467150]\n",
      "loss: 0.694197  [384064/467150]\n",
      "loss: 1.192655  [390464/467150]\n",
      "loss: 0.655707  [396864/467150]\n",
      "loss: 0.771595  [403264/467150]\n",
      "loss: 1.659296  [409664/467150]\n",
      "loss: 1.075873  [416064/467150]\n",
      "loss: 1.776581  [422464/467150]\n",
      "loss: 1.502426  [428864/467150]\n",
      "loss: 1.778347  [435264/467150]\n",
      "loss: 1.208579  [441664/467150]\n",
      "loss: 0.833573  [448064/467150]\n",
      "loss: 1.655921  [454464/467150]\n",
      "loss: 0.992566  [460864/467150]\n",
      "Training time: 658.295067\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 1.822150\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4989e-04.\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.056960  [   64/467150]\n",
      "loss: 1.558812  [ 6464/467150]\n",
      "loss: 0.845469  [12864/467150]\n",
      "loss: 1.072323  [19264/467150]\n",
      "loss: 0.837470  [25664/467150]\n",
      "loss: 2.321896  [32064/467150]\n",
      "loss: 1.036212  [38464/467150]\n",
      "loss: 1.610061  [44864/467150]\n",
      "loss: 1.007109  [51264/467150]\n",
      "loss: 1.538642  [57664/467150]\n",
      "loss: 0.898164  [64064/467150]\n",
      "loss: 1.651327  [70464/467150]\n",
      "loss: 2.005086  [76864/467150]\n",
      "loss: 1.383102  [83264/467150]\n",
      "loss: 1.228852  [89664/467150]\n",
      "loss: 0.804809  [96064/467150]\n",
      "loss: 1.838062  [102464/467150]\n",
      "loss: 1.107702  [108864/467150]\n",
      "loss: 1.209364  [115264/467150]\n",
      "loss: 2.634604  [121664/467150]\n",
      "loss: 1.214609  [128064/467150]\n",
      "loss: 1.494393  [134464/467150]\n",
      "loss: 1.967941  [140864/467150]\n",
      "loss: 1.931797  [147264/467150]\n",
      "loss: 0.834918  [153664/467150]\n",
      "loss: 1.574941  [160064/467150]\n",
      "loss: 2.221566  [166464/467150]\n",
      "loss: 1.023946  [172864/467150]\n",
      "loss: 1.483535  [179264/467150]\n",
      "loss: 1.885699  [185664/467150]\n",
      "loss: 1.187723  [192064/467150]\n",
      "loss: 0.893190  [198464/467150]\n",
      "loss: 0.916986  [204864/467150]\n",
      "loss: 1.267951  [211264/467150]\n",
      "loss: 1.031337  [217664/467150]\n",
      "loss: 1.436934  [224064/467150]\n",
      "loss: 1.573826  [230464/467150]\n",
      "loss: 1.845348  [236864/467150]\n",
      "loss: 1.406675  [243264/467150]\n",
      "loss: 2.600454  [249664/467150]\n",
      "loss: 1.526726  [256064/467150]\n",
      "loss: 1.701439  [262464/467150]\n",
      "loss: 1.638508  [268864/467150]\n",
      "loss: 2.158912  [275264/467150]\n",
      "loss: 1.368161  [281664/467150]\n",
      "loss: 1.733353  [288064/467150]\n",
      "loss: 1.673739  [294464/467150]\n",
      "loss: 1.657821  [300864/467150]\n",
      "loss: 1.854010  [307264/467150]\n",
      "loss: 2.364485  [313664/467150]\n",
      "loss: 1.248925  [320064/467150]\n",
      "loss: 1.584454  [326464/467150]\n",
      "loss: 1.870960  [332864/467150]\n",
      "loss: 0.867196  [339264/467150]\n",
      "loss: 1.314523  [345664/467150]\n",
      "loss: 1.140710  [352064/467150]\n",
      "loss: 1.214988  [358464/467150]\n",
      "loss: 2.228200  [364864/467150]\n",
      "loss: 1.218117  [371264/467150]\n",
      "loss: 1.307372  [377664/467150]\n",
      "loss: 0.724592  [384064/467150]\n",
      "loss: 1.187580  [390464/467150]\n",
      "loss: 0.633914  [396864/467150]\n",
      "loss: 0.797024  [403264/467150]\n",
      "loss: 1.489417  [409664/467150]\n",
      "loss: 1.074414  [416064/467150]\n",
      "loss: 1.825564  [422464/467150]\n",
      "loss: 1.504654  [428864/467150]\n",
      "loss: 1.784023  [435264/467150]\n",
      "loss: 1.086025  [441664/467150]\n",
      "loss: 0.835128  [448064/467150]\n",
      "loss: 1.306635  [454464/467150]\n",
      "loss: 0.975237  [460864/467150]\n",
      "Training time: 658.473804\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.823337\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4240e-04.\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.057224  [   64/467150]\n",
      "loss: 1.523354  [ 6464/467150]\n",
      "loss: 1.021647  [12864/467150]\n",
      "loss: 1.065808  [19264/467150]\n",
      "loss: 0.785479  [25664/467150]\n",
      "loss: 2.282636  [32064/467150]\n",
      "loss: 1.032331  [38464/467150]\n",
      "loss: 1.521142  [44864/467150]\n",
      "loss: 1.048245  [51264/467150]\n",
      "loss: 1.577436  [57664/467150]\n",
      "loss: 0.921336  [64064/467150]\n",
      "loss: 1.635427  [70464/467150]\n",
      "loss: 2.013742  [76864/467150]\n",
      "loss: 1.459560  [83264/467150]\n",
      "loss: 1.125489  [89664/467150]\n",
      "loss: 0.806141  [96064/467150]\n",
      "loss: 1.762821  [102464/467150]\n",
      "loss: 1.117972  [108864/467150]\n",
      "loss: 1.165158  [115264/467150]\n",
      "loss: 2.638116  [121664/467150]\n",
      "loss: 1.209803  [128064/467150]\n",
      "loss: 1.440197  [134464/467150]\n",
      "loss: 1.958536  [140864/467150]\n",
      "loss: 1.959876  [147264/467150]\n",
      "loss: 0.803905  [153664/467150]\n",
      "loss: 1.534513  [160064/467150]\n",
      "loss: 2.234325  [166464/467150]\n",
      "loss: 0.973707  [172864/467150]\n",
      "loss: 1.491422  [179264/467150]\n",
      "loss: 1.887659  [185664/467150]\n",
      "loss: 1.171588  [192064/467150]\n",
      "loss: 1.136471  [198464/467150]\n",
      "loss: 1.013936  [204864/467150]\n",
      "loss: 1.291205  [211264/467150]\n",
      "loss: 1.027697  [217664/467150]\n",
      "loss: 1.383084  [224064/467150]\n",
      "loss: 1.555307  [230464/467150]\n",
      "loss: 1.778153  [236864/467150]\n",
      "loss: 1.422007  [243264/467150]\n",
      "loss: 2.586036  [249664/467150]\n",
      "loss: 1.454746  [256064/467150]\n",
      "loss: 1.742114  [262464/467150]\n",
      "loss: 1.726141  [268864/467150]\n",
      "loss: 2.154166  [275264/467150]\n",
      "loss: 1.436142  [281664/467150]\n",
      "loss: 1.605845  [288064/467150]\n",
      "loss: 2.336475  [294464/467150]\n",
      "loss: 1.178648  [300864/467150]\n",
      "loss: 2.088377  [307264/467150]\n",
      "loss: 2.344698  [313664/467150]\n",
      "loss: 1.203640  [320064/467150]\n",
      "loss: 1.547071  [326464/467150]\n",
      "loss: 1.838757  [332864/467150]\n",
      "loss: 0.884426  [339264/467150]\n",
      "loss: 1.311200  [345664/467150]\n",
      "loss: 1.128775  [352064/467150]\n",
      "loss: 1.214574  [358464/467150]\n",
      "loss: 2.191983  [364864/467150]\n",
      "loss: 1.051371  [371264/467150]\n",
      "loss: 1.309563  [377664/467150]\n",
      "loss: 0.729512  [384064/467150]\n",
      "loss: 1.170319  [390464/467150]\n",
      "loss: 0.637605  [396864/467150]\n",
      "loss: 0.772986  [403264/467150]\n",
      "loss: 1.537060  [409664/467150]\n",
      "loss: 1.133386  [416064/467150]\n",
      "loss: 1.811212  [422464/467150]\n",
      "loss: 1.427606  [428864/467150]\n",
      "loss: 1.751143  [435264/467150]\n",
      "loss: 1.000249  [441664/467150]\n",
      "loss: 0.839109  [448064/467150]\n",
      "loss: 1.849315  [454464/467150]\n",
      "loss: 1.082985  [460864/467150]\n",
      "Training time: 658.139774\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.823496\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3528e-04.\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.054224  [   64/467150]\n",
      "loss: 1.509484  [ 6464/467150]\n",
      "loss: 0.868908  [12864/467150]\n",
      "loss: 1.075077  [19264/467150]\n",
      "loss: 0.846752  [25664/467150]\n",
      "loss: 2.300065  [32064/467150]\n",
      "loss: 1.060607  [38464/467150]\n",
      "loss: 1.644793  [44864/467150]\n",
      "loss: 1.081856  [51264/467150]\n",
      "loss: 1.629462  [57664/467150]\n",
      "loss: 0.925700  [64064/467150]\n",
      "loss: 1.620850  [70464/467150]\n",
      "loss: 2.149208  [76864/467150]\n",
      "loss: 1.445128  [83264/467150]\n",
      "loss: 1.275867  [89664/467150]\n",
      "loss: 0.797362  [96064/467150]\n",
      "loss: 1.846963  [102464/467150]\n",
      "loss: 1.115553  [108864/467150]\n",
      "loss: 1.168384  [115264/467150]\n",
      "loss: 2.410197  [121664/467150]\n",
      "loss: 1.247607  [128064/467150]\n",
      "loss: 1.518301  [134464/467150]\n",
      "loss: 2.186475  [140864/467150]\n",
      "loss: 1.987441  [147264/467150]\n",
      "loss: 0.858422  [153664/467150]\n",
      "loss: 1.470347  [160064/467150]\n",
      "loss: 2.263852  [166464/467150]\n",
      "loss: 0.954642  [172864/467150]\n",
      "loss: 1.434981  [179264/467150]\n",
      "loss: 1.848653  [185664/467150]\n",
      "loss: 1.082126  [192064/467150]\n",
      "loss: 1.062943  [198464/467150]\n",
      "loss: 1.002263  [204864/467150]\n",
      "loss: 1.340941  [211264/467150]\n",
      "loss: 1.022903  [217664/467150]\n",
      "loss: 1.068918  [224064/467150]\n",
      "loss: 2.137065  [230464/467150]\n",
      "loss: 1.853826  [236864/467150]\n",
      "loss: 1.426152  [243264/467150]\n",
      "loss: 2.142857  [249664/467150]\n",
      "loss: 1.510271  [256064/467150]\n",
      "loss: 1.768006  [262464/467150]\n",
      "loss: 1.696607  [268864/467150]\n",
      "loss: 2.293081  [275264/467150]\n",
      "loss: 1.420453  [281664/467150]\n",
      "loss: 1.569943  [288064/467150]\n",
      "loss: 2.320858  [294464/467150]\n",
      "loss: 0.905257  [300864/467150]\n",
      "loss: 1.930697  [307264/467150]\n",
      "loss: 2.271422  [313664/467150]\n",
      "loss: 1.200089  [320064/467150]\n",
      "loss: 1.543038  [326464/467150]\n",
      "loss: 1.812290  [332864/467150]\n",
      "loss: 0.805416  [339264/467150]\n",
      "loss: 1.321319  [345664/467150]\n",
      "loss: 1.165081  [352064/467150]\n",
      "loss: 1.215870  [358464/467150]\n",
      "loss: 2.180020  [364864/467150]\n",
      "loss: 1.257908  [371264/467150]\n",
      "loss: 1.350584  [377664/467150]\n",
      "loss: 0.685032  [384064/467150]\n",
      "loss: 1.158329  [390464/467150]\n",
      "loss: 0.652902  [396864/467150]\n",
      "loss: 0.839281  [403264/467150]\n",
      "loss: 1.569054  [409664/467150]\n",
      "loss: 1.153082  [416064/467150]\n",
      "loss: 1.870911  [422464/467150]\n",
      "loss: 1.588959  [428864/467150]\n",
      "loss: 1.752949  [435264/467150]\n",
      "loss: 1.005538  [441664/467150]\n",
      "loss: 0.838872  [448064/467150]\n",
      "loss: 1.944452  [454464/467150]\n",
      "loss: 0.997219  [460864/467150]\n",
      "Training time: 657.661802\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.824005\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2851e-04.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss, train_acc = train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loss, test_acc = test_loop(validation_loader, model, loss_fn)\n",
    "    lr_scheduler.step()\n",
    "    epoch = {'val': {'loss': test_loss, 'acc': test_acc}, 'train': {'loss': train_loss, 'acc': train_acc}}\n",
    "    history.append(epoch)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'val': {'loss': 1.8707616064940926, 'acc': 0.3593954047659068}, 'train': {'loss': 1.7265987349039953, 'acc': 0.3152798886867173}}, {'val': {'loss': 1.8557786336114723, 'acc': 0.37831163289846265}, 'train': {'loss': 1.639627386436248, 'acc': 0.3654993042919833}}, {'val': {'loss': 1.8506451017901955, 'acc': 0.3948229270374058}, 'train': {'loss': 1.6119926360098038, 'acc': 0.3826180027828321}}, {'val': {'loss': 1.848939051008895, 'acc': 0.40228339431866666}, 'train': {'loss': 1.597396140213551, 'acc': 0.39328909343893825}}, {'val': {'loss': 1.850152028800043, 'acc': 0.39010356731875717}, 'train': {'loss': 1.5781379085580753, 'acc': 0.4028406293481751}}, {'val': {'loss': 1.8396963532844588, 'acc': 0.40745529538019937}, 'train': {'loss': 1.5760218946390534, 'acc': 0.40111527346676656}}, {'val': {'loss': 1.854744085898766, 'acc': 0.36950647134120324}, 'train': {'loss': 1.5689050092127474, 'acc': 0.4057326340575832}}, {'val': {'loss': 1.8425499501555689, 'acc': 0.40210237778151303}, 'train': {'loss': 1.5714565413523118, 'acc': 0.405959541903029}}, {'val': {'loss': 1.8415847705157953, 'acc': 0.3946806997582136}, 'train': {'loss': 1.5648772907201551, 'acc': 0.4121203039708873}}, {'val': {'loss': 1.844234230007585, 'acc': 0.3966718816669037}, 'train': {'loss': 1.5693714610680045, 'acc': 0.4088258589318206}}, {'val': {'loss': 1.8415412993545468, 'acc': 0.40486934484943304}, 'train': {'loss': 1.5630348490548307, 'acc': 0.4114652681151664}}, {'val': {'loss': 1.8406618125582648, 'acc': 0.407713890433276}, 'train': {'loss': 1.5668388297826006, 'acc': 0.41321845231724286}}, {'val': {'loss': 1.8404059110346465, 'acc': 0.39632277834525026}, 'train': {'loss': 1.5574086013191741, 'acc': 0.41799850155196405}}, {'val': {'loss': 1.8372368283070641, 'acc': 0.41309266753727003}, 'train': {'loss': 1.554369190944876, 'acc': 0.41706090120946165}}, {'val': {'loss': 1.8427771419607184, 'acc': 0.41399775022303825}, 'train': {'loss': 1.5571170897332915, 'acc': 0.41803061115273465}}, {'val': {'loss': 1.8348797308304174, 'acc': 0.4205014158079156}, 'train': {'loss': 1.544578443750778, 'acc': 0.4217531842020764}}, {'val': {'loss': 1.8386107784741372, 'acc': 0.39839153876986333}, 'train': {'loss': 1.542418845492955, 'acc': 0.4219137322059296}}, {'val': {'loss': 1.837422468033184, 'acc': 0.4156398288100749}, 'train': {'loss': 1.5527254265699506, 'acc': 0.41821256555710157}}, {'val': {'loss': 1.8414131383249048, 'acc': 0.40455903078574107}, 'train': {'loss': 1.540422203916771, 'acc': 0.4224403296585679}}, {'val': {'loss': 1.8331252839370047, 'acc': 0.41832921736207185}, 'train': {'loss': 1.5418685823617724, 'acc': 0.4248057369153377}}, {'val': {'loss': 1.835365715058408, 'acc': 0.410403278985273}, 'train': {'loss': 1.5405749615079198, 'acc': 0.427505084020122}}, {'val': {'loss': 1.832095062762277, 'acc': 0.42699215164013915}, 'train': {'loss': 1.5458931276399415, 'acc': 0.42329444503906666}}, {'val': {'loss': 1.8356096887509619, 'acc': 0.4191179322739556}, 'train': {'loss': 1.532191146463707, 'acc': 0.4304142138499411}}, {'val': {'loss': 1.8313246236742775, 'acc': 0.4365601686039746}, 'train': {'loss': 1.5306291478286786, 'acc': 0.4326533233436798}}, {'val': {'loss': 1.8284137251950967, 'acc': 0.4286342302271757}, 'train': {'loss': 1.5240629199988744, 'acc': 0.43688750936530024}}, {'val': {'loss': 1.8291789159191059, 'acc': 0.42850493270063744}, 'train': {'loss': 1.520519726471405, 'acc': 0.44}}, {'val': {'loss': 1.8329788396139595, 'acc': 0.4321123336910565}, 'train': {'loss': 1.520708493924105, 'acc': 0.4400877662421064}}, {'val': {'loss': 1.8262605753883634, 'acc': 0.42827219715286846}, 'train': {'loss': 1.5116580602469094, 'acc': 0.4454479289307503}}, {'val': {'loss': 1.827561466431598, 'acc': 0.42300978782275894}, 'train': {'loss': 1.5089955839870368, 'acc': 0.4467558600021406}}, {'val': {'loss': 1.826846120769668, 'acc': 0.43123311051059593}, 'train': {'loss': 1.506444941793244, 'acc': 0.44655463983731136}}, {'val': {'loss': 1.8263840747333144, 'acc': 0.4372066562366662}, 'train': {'loss': 1.5035931420483022, 'acc': 0.44675371936208924}}, {'val': {'loss': 1.8253539484132904, 'acc': 0.4370256396995125}, 'train': {'loss': 1.5212755750378348, 'acc': 0.4375125762603018}}, {'val': {'loss': 1.8267642193534732, 'acc': 0.4426630118565832}, 'train': {'loss': 1.5040458198654634, 'acc': 0.44763138178315315}}, {'val': {'loss': 1.8251653392025022, 'acc': 0.4439689168746202}, 'train': {'loss': 1.4955883072425051, 'acc': 0.45318420207642085}}, {'val': {'loss': 1.8222467732685868, 'acc': 0.44545583842981085}, 'train': {'loss': 1.492337677761012, 'acc': 0.4559862999036712}}, {'val': {'loss': 1.8248498218921319, 'acc': 0.43746525128974284}, 'train': {'loss': 1.4885469860843736, 'acc': 0.4587070534089693}}, {'val': {'loss': 1.8221504242583875, 'acc': 0.43915904888739477}, 'train': {'loss': 1.4880025260725125, 'acc': 0.45975596703414323}}, {'val': {'loss': 1.8233366044125743, 'acc': 0.4441240739064662}, 'train': {'loss': 1.4875593487000298, 'acc': 0.45742481001819546}}, {'val': {'loss': 1.8234961357266573, 'acc': 0.43809880916978056}, 'train': {'loss': 1.4808671101509243, 'acc': 0.46351493096435836}}, {'val': {'loss': 1.8240046253669746, 'acc': 0.434685354469169}, 'train': {'loss': 1.4751435239636126, 'acc': 0.46611794926683076}}]\n"
     ]
    }
   ],
   "source": [
    "print(history)\n",
    "\n",
    "import json\n",
    "\n",
    "train_log = {\n",
    "    'decay_rate': decay_rate,\n",
    "    'inputs': model.liquid.input_size,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': learning_rate,\n",
    "    'units': model_units,\n",
    "    'num_epochs': epochs,\n",
    "    'epochs': history,\n",
    "    'train_samples': len(df),\n",
    "}\n",
    "\n",
    "log_name = f'../log/pytorch/history_{datetime.datetime.timestamp(datetime.datetime.now())}.json'\n",
    "\n",
    "with open(log_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_log, f, ensure_ascii=False, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction, _ = model(torch.tensor(features.values).type(torch.LongTensor).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f84752918d0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_pred = []\n",
    "for one_hot in prediction:\n",
    "    idx = torch.argmax(one_hot)\n",
    "    class_pred.append(idx.cpu())\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 18))\n",
    "plt.plot(range(len(class_pred)), class_pred)\n",
    "plt.plot(range(len(df['Marker'])), df['Marker'], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48983410039601843\n"
     ]
    }
   ],
   "source": [
    "acc = sum(df['Marker'].values == class_pred) / len(df['Marker'])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f84752935e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_data = train_log.get('epochs', [])\n",
    "\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "\n",
    "for epoch_log in epoch_data:\n",
    "    val_loss.append(epoch_log['val']['loss'])\n",
    "    val_acc.append(epoch_log['val']['acc'])\n",
    "    train_loss.append(epoch_log['train']['loss'])\n",
    "    train_acc.append(epoch_log['train']['acc'])\n",
    "\n",
    "num_epochs = range(len(epoch_data))\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(num_epochs, train_loss, label='train_loss')\n",
    "plt.plot(num_epochs, val_loss, label='val_loss')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.plot(num_epochs, train_acc, label='train_acc')\n",
    "plt.plot(num_epochs, val_acc, label='val_acc')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
