{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.10/site-packages (0.13.0)\n",
      "Requirement already satisfied: ncps in ./.venv/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: pytorch-lightning in ./.venv/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.10/site-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.10/site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in ./.venv/lib/python3.10/site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: future in ./.venv/lib/python3.10/site-packages (from ncps) (0.18.3)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from ncps) (23.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.venv/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./.venv/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in ./.venv/lib/python3.10/site-packages (from pytorch-lightning) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./.venv/lib/python3.10/site-packages (from pytorch-lightning) (6.0.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in ./.venv/lib/python3.10/site-packages (from pytorch-lightning) (1.2.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in ./.venv/lib/python3.10/site-packages (from pytorch-lightning) (0.10.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.9.1)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (69.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn ncps torch pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fp1</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>...</th>\n",
       "      <th>F8</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "      <th>Pz</th>\n",
       "      <th>X5</th>\n",
       "      <th>Marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27232</th>\n",
       "      <td>-4.16</td>\n",
       "      <td>12.80</td>\n",
       "      <td>-6.16</td>\n",
       "      <td>1.66</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>...</td>\n",
       "      <td>6.29</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-2.62</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22201</th>\n",
       "      <td>-6.68</td>\n",
       "      <td>14.11</td>\n",
       "      <td>-6.04</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-4.14</td>\n",
       "      <td>1.42</td>\n",
       "      <td>-2.06</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.26</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>-8.79</td>\n",
       "      <td>13.64</td>\n",
       "      <td>-8.61</td>\n",
       "      <td>2.38</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.17</td>\n",
       "      <td>...</td>\n",
       "      <td>4.95</td>\n",
       "      <td>-2.66</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.12</td>\n",
       "      <td>5.75</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>-2.25</td>\n",
       "      <td>14.96</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-3.18</td>\n",
       "      <td>2.41</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>5.34</td>\n",
       "      <td>-3.09</td>\n",
       "      <td>2.54</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>1.15</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17313</th>\n",
       "      <td>-0.09</td>\n",
       "      <td>13.47</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>2.81</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Fp1    Fp2    F3    F4    C3    C4    P3    P4    O1    O2  ...    F8  \\\n",
       "27232 -4.16  12.80 -6.16  1.66 -0.86  1.46 -1.43 -1.92 -0.02 -1.42  ...  6.29   \n",
       "22201 -6.68  14.11 -6.04  1.44 -2.30  0.87 -0.53 -0.08  0.10 -0.22  ...  5.06   \n",
       "3773  -8.79  13.64 -8.61  2.38 -3.34  2.10  0.04  3.84  2.44  3.17  ...  4.95   \n",
       "5995  -2.25  14.96 -4.80  0.86 -3.18  2.41 -3.71  0.72 -2.23  1.93  ...  5.34   \n",
       "17313 -0.09  13.47  3.72  0.12  0.00  0.06  1.20  3.26  3.48  3.11  ...  0.07   \n",
       "\n",
       "         T3    T4    T5    T6    Fz    Cz    Pz    X5  Marker  \n",
       "27232 -3.82  0.99 -1.31 -2.62  1.07  2.60 -0.96 -0.11       0  \n",
       "22201 -4.14  1.42 -2.06 -1.17  1.68  2.26 -0.92  0.19       0  \n",
       "3773  -2.66  3.54  1.12  5.75 -0.53  0.52  2.09  0.26       0  \n",
       "5995  -3.09  2.54 -3.26  1.15 -1.01  0.08 -0.02 -0.31       0  \n",
       "17313 -1.03 -1.43 -0.48  2.81  3.98  2.81  1.99  0.33       0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/treated/HaLT-SubjectA-160223.csv')\n",
    "df = df.sort_values(by=df.columns[0])\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.torch import CfC\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "\n",
    "# LightningModule for training a RNNSequence module\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class LiquidBlock(pl.LightningModule):\n",
    "    def __init__(self, units=20, in_features=22, out_features=10, lr=0.005, weights=None):\n",
    "        super().__init__()\n",
    "        if weights:\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=weights, reduction='sum')\n",
    "        else:\n",
    "            self.criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "        self.wiring = AutoNCP(units, out_features)\n",
    "        self.cfc = CfC(in_features, self.wiring, batch_first=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task='multiclass', num_classes=out_features)\n",
    "        self.valid_acc = torchmetrics.Accuracy(task='multiclass', num_classes=out_features)\n",
    "        \n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, inputs, hiddens=None) -> Any:\n",
    "        x, hidden = self.cfc.forward(input=inputs, hx=hiddens)\n",
    "        return self.softmax(x), hidden\n",
    "\n",
    "    def training_step(self, batch, batch_idx, hiddens=None):\n",
    "        x, y = batch\n",
    "        y_hat, hidden = self.forward(x, hiddens)\n",
    "        y_hat = y_hat.view_as(y)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "                \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "\n",
    "        self.train_acc(y_hat, y)\n",
    "        self.log('train_acc', self.train_acc, on_step=True, on_epoch=False)\n",
    "\n",
    "        return {\"loss\": loss, \"hiddens\": hidden}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat, _ = self.forward(x)\n",
    "        y_hat = y_hat.view_as(y)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "        self.valid_acc(y_hat, y)\n",
    "        self.log('valid_acc', self.valid_acc, on_step=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Here we just reuse the validation_step for testing\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.cfc.parameters(), lr=self.lr)\n",
    "    \n",
    "    def draw_graph(self, **kwargs):\n",
    "        return self.wiring.draw_graph(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 500, 10])\n",
      "torch.Size([64, 1, 5000])\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(64, 500, 10)\n",
    "print(test.shape)\n",
    "print(test.reshape(64, 1, -1).shape)\n",
    "print(test.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode target classes as One Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "[0 1 2 3 4 5 6]\n",
      "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 1]])\n",
      "torch.Size([218106, 7])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Lookup features\n",
    "print(np.unique(df['Marker']))\n",
    "\n",
    "_tensor = torch.Tensor(df['Marker'].values).int()\n",
    "\n",
    "classes = np.unique(_tensor)\n",
    "print(classes)\n",
    "\n",
    "\n",
    "_tensor_one_hot = torch.nn.functional.one_hot(_tensor.long())\n",
    "print(_tensor_one_hot)\n",
    "print(_tensor_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model(model):\n",
    "    sns.set_style(\"white\")\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    legend_handles = model.draw_graph(draw_labels=True, neuron_colors={\"command\": \"tab:cyan\"})\n",
    "    plt.legend(handles=legend_handles, loc=\"upper center\", bbox_to_anchor=(1, 1))\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data \n",
    "\n",
    "# Train the model\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# features = df_copy[['Cz', 'C3', 'A1', 'F3', 'P3']]\n",
    "features = df.loc[:, df.columns != 'Marker']\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "# One hot encoding Marker\n",
    "_tensor = torch.Tensor(df['Marker'].values).int()\n",
    "\n",
    "target_one_hot = torch.nn.functional.one_hot(_tensor.long(), len(classes)).float()\n",
    "# use 20% of training data for validation\n",
    "train_set_size = int(len(df) * 0.8)\n",
    "valid_set_size = len(df) - train_set_size\n",
    "\n",
    "train_set = features[:][:train_set_size]\n",
    "valid_set = features[:][train_set_size:]\n",
    "\n",
    "train_data_y = target_one_hot.clone().detach()[:train_set_size]\n",
    "validation_data_y = target_one_hot.clone().detach()[train_set_size:]\n",
    "\n",
    "train_data_x = torch.tensor(train_set.values).float()\n",
    "validation_data_x = torch.tensor(valid_set.values).float()\n",
    "\n",
    "train_tensor = data.TensorDataset(train_data_x, train_data_y)\n",
    "validation_tensor = data.TensorDataset(validation_data_x, validation_data_y)\n",
    "\n",
    "train_loader = data.DataLoader(train_tensor, batch_size=BATCH_SIZE, num_workers=8)\n",
    "validation_loader = data.DataLoader(validation_tensor, batch_size=BATCH_SIZE, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Definition of the model:\n",
    "out_features = len(classes)\n",
    "in_features = len(features.columns)\n",
    "learn_rate = 1e-5\n",
    "\n",
    "EPOCHS = 15\n",
    "\n",
    "model = LiquidBlock(units=100, in_features=in_features, out_features=out_features, lr=learn_rate)\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    logger=pl.loggers.CSVLogger(\"log\"),\n",
    "    max_epochs=EPOCHS,\n",
    "    gradient_clip_val=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss   | 0     \n",
      "1 | cfc       | CfC                | 41.0 K\n",
      "2 | softmax   | Softmax            | 0     \n",
      "3 | train_acc | MulticlassAccuracy | 0     \n",
      "4 | valid_acc | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "32.9 K    Trainable params\n",
      "8.1 K     Non-trainable params\n",
      "41.0 K    Total params\n",
      "0.164     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 4/3490 [00:00<05:25, 10.71it/s, v_num=65, train_loss=96.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.fit(model, train_loader, validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to() received an invalid combination of arguments - got (device=list, ), but expected one of:\n * (torch.device device, torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (Tensor tensor, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(class_pred)), class_pred)\n\u001b[1;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarker\u001b[39m\u001b[38;5;124m'\u001b[39m])), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarker\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m \u001b[43mevaluate_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m, in \u001b[0;36mevaluate_prediction\u001b[0;34m(model, df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_prediction\u001b[39m(model, df):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 3\u001b[0m         prediction, _ \u001b[38;5;241m=\u001b[39m model(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMarker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m     class_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m one_hot \u001b[38;5;129;01min\u001b[39;00m prediction:\n",
      "\u001b[0;31mTypeError\u001b[0m: to() received an invalid combination of arguments - got (device=list, ), but expected one of:\n * (torch.device device, torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (Tensor tensor, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_prediction(model, df):\n",
    "    with torch.no_grad():\n",
    "        prediction, _ = model(torch.tensor(df.loc[:, df.columns != 'Marker'].values).float().to(device=[0]))\n",
    "    class_pred = []\n",
    "    for one_hot in prediction:\n",
    "        idx = torch.argmax(one_hot)\n",
    "        class_pred.append(idx)\n",
    "\n",
    "    plt.plot(range(len(class_pred)), class_pred)\n",
    "    plt.plot(range(len(df['Marker'])), df['Marker'])\n",
    "\n",
    "evaluate_prediction(model, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
