{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torcheeg in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.21.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.3.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (1.5.3)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (1.3.2)\n",
      "Requirement already satisfied: lmdb>=1.3.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (1.4.1)\n",
      "Requirement already satisfied: einops>=0.4.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (0.7.0)\n",
      "Requirement already satisfied: mne>=1.0.3 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (1.6.0)\n",
      "Requirement already satisfied: xmltodict>=0.13.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (0.13.0)\n",
      "Requirement already satisfied: networkx>=2.6.3 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (3.2.1)\n",
      "Requirement already satisfied: PyWavelets>=1.3.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (1.5.0)\n",
      "Requirement already satisfied: spectrum>=0.8.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (0.8.1)\n",
      "Requirement already satisfied: torchmetrics>=0.10.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (1.2.0)\n",
      "Requirement already satisfied: mne-connectivity>=0.4.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (0.6.0)\n",
      "Requirement already satisfied: pytorch-lightning>=1.9.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torcheeg) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne>=1.0.3->torcheeg) (3.8.2)\n",
      "Requirement already satisfied: pooch>=1.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne>=1.0.3->torcheeg) (1.8.0)\n",
      "Requirement already satisfied: decorator in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne>=1.0.3->torcheeg) (5.1.1)\n",
      "Requirement already satisfied: packaging in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne>=1.0.3->torcheeg) (23.2)\n",
      "Requirement already satisfied: jinja2 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne>=1.0.3->torcheeg) (3.1.2)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne>=1.0.3->torcheeg) (0.3)\n",
      "Requirement already satisfied: defusedxml in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne>=1.0.3->torcheeg) (0.7.1)\n",
      "Requirement already satisfied: netCDF4>=1.6.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne-connectivity>=0.4.0->torcheeg) (1.6.5)\n",
      "Requirement already satisfied: xarray>=2023.11.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne-connectivity>=0.4.0->torcheeg) (2024.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from pandas>=1.3.5->torcheeg) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from pandas>=1.3.5->torcheeg) (2023.3.post1)\n",
      "Requirement already satisfied: torch>=1.12.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from pytorch-lightning>=1.9.5->torcheeg) (2.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from pytorch-lightning>=1.9.5->torcheeg) (6.0.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from pytorch-lightning>=1.9.5->torcheeg) (4.8.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from pytorch-lightning>=1.9.5->torcheeg) (0.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from scikit-learn>=1.0.2->torcheeg) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from scikit-learn>=1.0.2->torcheeg) (3.2.0)\n",
      "Requirement already satisfied: easydev in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from spectrum>=0.8.1->torcheeg) (0.12.1)\n",
      "Requirement already satisfied: requests in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (3.9.1)\n",
      "Requirement already satisfied: setuptools in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=1.9.5->torcheeg) (69.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib>=3.5.0->mne>=1.0.3->torcheeg) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib>=3.5.0->mne>=1.0.3->torcheeg) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib>=3.5.0->mne>=1.0.3->torcheeg) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib>=3.5.0->mne>=1.0.3->torcheeg) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib>=3.5.0->mne>=1.0.3->torcheeg) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib>=3.5.0->mne>=1.0.3->torcheeg) (3.1.1)\n",
      "Requirement already satisfied: cftime in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from netCDF4>=1.6.5->mne-connectivity>=0.4.0->torcheeg) (1.6.3)\n",
      "Requirement already satisfied: certifi in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from netCDF4>=1.6.5->mne-connectivity>=0.4.0->torcheeg) (2023.11.17)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from pooch>=1.5->mne>=1.0.3->torcheeg) (4.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->torcheeg) (1.16.0)\n",
      "Requirement already satisfied: filelock in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (12.3.101)\n",
      "Requirement already satisfied: colorama in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from easydev->spectrum>=0.8.1->torcheeg) (0.4.6)\n",
      "Requirement already satisfied: pexpect in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from easydev->spectrum>=0.8.1->torcheeg) (4.9.0)\n",
      "Requirement already satisfied: colorlog in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from easydev->spectrum>=0.8.1->torcheeg) (6.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from jinja2->mne>=1.0.3->torcheeg) (2.1.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning>=1.9.5->torcheeg) (1.26.18)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from pexpect->easydev->spectrum>=0.8.1->torcheeg) (0.7.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from sympy->torch>=1.12.0->pytorch-lightning>=1.9.5->torcheeg) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: moabb==0.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: PyYAML<7.0,>=6.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (6.0.1)\n",
      "Requirement already satisfied: coverage<8.0.0,>=7.0.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (7.4.0)\n",
      "Requirement already satisfied: h5py<4.0.0,>=3.7.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (3.8.0)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.6.2 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (3.8.2)\n",
      "Requirement already satisfied: memory-profiler<0.62.0,>=0.61.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (0.61.0)\n",
      "Requirement already satisfied: mne<2.0.0,>=1.3.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (1.6.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.22 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (1.26.2)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.5.2 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (1.5.3)\n",
      "Requirement already satisfied: pooch<2.0.0,>=1.6.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (1.8.0)\n",
      "Requirement already satisfied: pyriemann<0.4,>=0.3 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (1.3.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.9.3 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (1.11.4)\n",
      "Requirement already satisfied: seaborn<0.13.0,>=0.12.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (0.12.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from moabb==0.5) (4.66.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb==0.5) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb==0.5) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb==0.5) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb==0.5) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb==0.5) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb==0.5) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb==0.5) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.6.2->moabb==0.5) (2.8.2)\n",
      "Requirement already satisfied: psutil in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from memory-profiler<0.62.0,>=0.61.0->moabb==0.5) (5.9.6)\n",
      "Requirement already satisfied: decorator in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne<2.0.0,>=1.3.0->moabb==0.5) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne<2.0.0,>=1.3.0->moabb==0.5) (3.1.2)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne<2.0.0,>=1.3.0->moabb==0.5) (0.3)\n",
      "Requirement already satisfied: defusedxml in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from mne<2.0.0,>=1.3.0->moabb==0.5) (0.7.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.2->moabb==0.5) (2023.3.post1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from pooch<2.0.0,>=1.6.0->moabb==0.5) (4.0.0)\n",
      "Requirement already satisfied: joblib in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from pyriemann<0.4,>=0.3->moabb==0.5) (1.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb==0.5) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb==0.5) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb==0.5) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->moabb==0.5) (2023.11.17)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.2.0->moabb==0.5) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.6.2->moabb==0.5) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/chema/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages (from jinja2->mne<2.0.0,>=1.3.0->moabb==0.5) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torcheeg\n",
    "%pip install moabb==0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.datasets import BCICIV2aDataset\n",
    "from torcheeg import transforms\n",
    "from typing import Dict, Union\n",
    "import numpy as np\n",
    "from torcheeg.transforms import EEGTransform\n",
    "\n",
    "# Custom transform to traspose matrix\n",
    "\n",
    "class TrasposeEEG(EEGTransform):\n",
    "    def __init__(self, apply_to_baseline: bool = False):\n",
    "        super(TrasposeEEG, self).__init__(apply_to_baseline=apply_to_baseline)\n",
    "\n",
    "    def __call__(self,\n",
    "                 *args,\n",
    "                 eeg: np.ndarray,\n",
    "                 baseline: Union[np.ndarray, None] = None,\n",
    "                 **kwargs) -> Dict[str, np.ndarray]:\n",
    "        return super().__call__(*args, eeg=eeg, baseline=baseline, **kwargs)\n",
    "    \n",
    "    def apply(self, eeg: np.ndarray, **kwargs) -> np.ndarray:\n",
    "        return np.moveaxis(eeg, -1, -2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-29 22:39:16] INFO (torcheeg/MainThread) 🔍 | Detected cached processing results, reading cache from .torcheeg/datasets_1706557112340_X93HI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[13.1348, 13.8672, 17.0898,  ...,  9.0820,  7.2266,  3.3691],\n",
      "         [14.5996, 18.7988, 17.9199,  ..., 14.8926, 12.6465, 10.8398],\n",
      "         [16.1621, 18.1641, 19.2871,  ..., 15.2832, 14.0625, 11.4746],\n",
      "         ...,\n",
      "         [-3.4180, -8.9355, -7.8613,  ..., -2.7832,  0.5371, -4.3945],\n",
      "         [ 1.0254, -3.0273, -1.8555,  ...,  1.6602,  3.8086, -0.4395],\n",
      "         [ 1.5625, -0.2930,  0.4395,  ...,  4.2969,  6.2500,  2.3438]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "# dataset = moabb_dataset.MOABBDataset(\n",
    "#     dataset=moabb,\n",
    "#     paradigm=paradigm,\n",
    "#     io_path='./io/moabb',\n",
    "#     # offline_transform=transforms.Compose([transforms.BandDifferentialEntropy()]),\n",
    "#     online_transform=transforms.ToTensor(),\n",
    "#     label_transform=transforms.Compose([\n",
    "#         transforms.Select('label'),\n",
    "#         transforms.Mapping({'left_hand': 0, 'right_hand': 1,}),\n",
    "#     ])\n",
    "# )\n",
    "\n",
    "# Load BCI-Competition IV-2a dataset\n",
    "\n",
    "SEQ_LENGTH = 500\n",
    " \n",
    "dataset = BCICIV2aDataset(root_path='../datasets/bci_c',\n",
    "                          io_path='.torcheeg/datasets_1706557112340_X93HI',\n",
    "                          chunk_size=SEQ_LENGTH,\n",
    "                          online_transform=transforms.Compose([\n",
    "                              transforms.To2d(),\n",
    "                              TrasposeEEG(),\n",
    "                              transforms.ToTensor()\n",
    "                          ]),\n",
    "                          label_transform=transforms.Compose([\n",
    "                              transforms.Select('label'),\n",
    "                              transforms.Lambda(lambda x: x - 1)\n",
    "                          ]))\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 500, 22])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.torch import CfC\n",
    "\n",
    "class OnlyLiquidEEG(nn.Module):\n",
    "    def __init__(self, liquid_units=50, num_classes=2, channels=4):\n",
    "        super().__init__()\n",
    "        self.liquid_block = LiquidBlock(units=liquid_units, out_features=num_classes, in_features=channels)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        x, _ = self.liquid_block.forward(torch.squeeze(x, dim=1), state)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class LiquidBlock(nn.Module):\n",
    "    def __init__(self, units=20, out_features=10, in_features=5):\n",
    "        super().__init__()\n",
    "        wiring = AutoNCP(units, out_features)\n",
    "        self.units = units\n",
    "        self.liquid = CfC(in_features, wiring, return_sequences=False, batch_first=True)\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        x, hx = self.liquid.forward(input=x, hx=state)\n",
    "        return x, hx\n",
    "    \n",
    "class ConvolutionalBlock(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=2, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=(1, 2)),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=3, stride=(1, 2)),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=1, kernel_size=5, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=dropout),\n",
    "            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 2))\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "    \n",
    "class ConvLiquidEEG(nn.Module):\n",
    "    # TODO: Prepare model for ablation tests\n",
    "    def __init__(self, liquid_units=20, num_classes=10, dropout=0):\n",
    "        super().__init__()\n",
    "        self.conv_block = ConvolutionalBlock(dropout=dropout)\n",
    "        # TODO Parametrize in features\n",
    "        self.liquid_block = LiquidBlock(units=liquid_units, out_features=num_classes, in_features=4)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        # print(f'>>>>>>> INPUT: {x.shape}')\n",
    "        # x = self.preprocessing(x)\n",
    "        # print(f'>>>>>>>>> PRE OUTPUT: {x.shape}')\n",
    "        x = self.conv_block(x)\n",
    "        # print(f'>>>>>>>>>> CONV OUTPUT SHAPE: {x.shape}')\n",
    "        x, _ = self.liquid_block.forward(torch.squeeze(x, dim=1))\n",
    "        # print(f'>>>>>>>>> LIQUID OUT: {x.shape}')\n",
    "        return self.softmax(x)\n",
    "    \n",
    "class ConvLSTMEEG(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout=0):\n",
    "        self.conv_block = ConvolutionalBlock(dropout=dropout)\n",
    "        self.lstm = nn.LSTM(4, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x, _ = self.liquid_block.forward(torch.squeeze(x, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "os.makedirs('./examples_vanilla_torch/log', exist_ok=True)\n",
    "logger = logging.getLogger('Training models with vanilla PyTorch')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "console_handler = logging.StreamHandler()\n",
    "timeticks = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "file_handler = logging.FileHandler(\n",
    "    os.path.join('./examples_vanilla_torch/log', f'{timeticks}.log'))\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.model_selection import KFoldPerSubject, train_test_split\n",
    "\n",
    "k_fold = KFoldPerSubject(n_splits=10,\n",
    "                         split_path='./examples_vanilla_torch/split',\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # training process\n",
    "# def train(dataloader, model, loss_fn, optimizer):\n",
    "#     # Set the model to training mode - important for batch normalization and dropout layers\n",
    "#     # Unnecessary in this situation but added for best practices\n",
    "#     model.train()\n",
    "#     total_start = datetime.datetime.now()\n",
    "#     size = len(dataloader.dataset)\n",
    "\n",
    "#     last_batch = 0\n",
    "#     start_batch_loading = datetime.datetime.now()\n",
    "#     for batch_idx, (X, y) in enumerate(dataloader):\n",
    "#         start_batch_training = datetime.datetime.now()\n",
    "#         batch_loading_time = (start_batch_training - start_batch_loading).total_seconds()\n",
    "  \n",
    "#         X, y = X.to(device), y.to(device)\n",
    "\n",
    "#         # Compute prediction and loss\n",
    "#         pred = model(X)\n",
    "#         loss = loss_fn(pred, y)\n",
    "\n",
    "#         # Backpropagation\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         batch_training_time = (datetime.datetime.now() - start_batch_training).total_seconds()\n",
    "#         start_batch_loading = datetime.datetime.now()\n",
    "#         if batch_idx % 50 == 0:\n",
    "#             loss, current = loss.item(), batch_idx * len(X)\n",
    "#             logger.info(f\"Train loss: {loss:>7f}  [{current:>5d}/{size:>5d}] training time ratio: {batch_training_time / (batch_training_time + batch_loading_time)}\")\n",
    "#     last_batch += 1\n",
    "#     print(f'Training time: {(datetime.datetime.now() - total_start).total_seconds()}')\n",
    "    \n",
    "#     return loss\n",
    "\n",
    "\n",
    "# def valid(dataloader, model, loss_fn):\n",
    "#     size = len(dataloader.dataset)\n",
    "#     num_batches = len(dataloader)\n",
    "#     model.eval()\n",
    "#     loss, correct = 0, 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch, (X, y) in enumerate(dataloader):\n",
    "#             X, y = X.to(device), y.to(device)\n",
    "\n",
    "#             pred = model(X)\n",
    "#             loss += loss_fn(pred, y).item()\n",
    "#             correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "#     loss /= num_batches\n",
    "#     correct /= size\n",
    "#     logger.info(f\"Valid Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {loss:>8f}\\n\")\n",
    "\n",
    "#     return correct, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# from torcheeg.model_selection import train_test_split\n",
    "# from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# batch_size = 64\n",
    "# NUM_CLASSES = 4\n",
    "\n",
    "# test_accs = []\n",
    "# test_losses = []\n",
    "\n",
    "# for i, (train_dataset, test_dataset) in enumerate(k_fold.split(dataset)):\n",
    "#     # initialize model\n",
    "#     model = ConvLiquidEEG(liquid_units=250, eeg_channels=22, num_classes=NUM_CLASSES, dropout=0).to(device)\n",
    "#     # initialize optimizer\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # official: weight_decay=5e-1\n",
    "#     # split train and val\n",
    "#     train_dataset, val_dataset = train_test_split(\n",
    "#         train_dataset,\n",
    "#         test_size=0.2,\n",
    "#         split_path=f'./examples_vanilla_torch/split{i}',\n",
    "#         shuffle=True)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "#     epochs = 5\n",
    "#     best_val_acc = 0.0\n",
    "#     for t in range(epochs):\n",
    "#         train_loss = train(train_loader, model, loss_fn, optimizer)\n",
    "#         val_acc, val_loss = valid(val_loader, model, loss_fn)\n",
    "#         # save the best model based on val_acc\n",
    "#         if val_acc > best_val_acc:\n",
    "#             best_val_acc = val_acc\n",
    "#             torch.save(model.state_dict(),\n",
    "#                        f'./examples_vanilla_torch/model{i}.pt')\n",
    "\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     # load the best model to test on test set\n",
    "#     model.load_state_dict(torch.load(f'./examples_vanilla_torch/model{i}.pt'))\n",
    "#     test_acc, test_loss = valid(test_loader, model, loss_fn)\n",
    "\n",
    "#     # log the test result\n",
    "#     logger.info(\n",
    "#         f\"Test Error {i}: \\n Accuracy: {(100*test_acc):>0.1f}%, Avg loss: {test_loss:>8f}\"\n",
    "#     )\n",
    "\n",
    "#     test_accs.append(test_acc)\n",
    "#     test_losses.append(test_loss)\n",
    "\n",
    "# # log the average test result on cross-validation datasets\n",
    "# logger.info(\n",
    "#     f\"Test Error: \\n Accuracy: {100*np.mean(test_accs):>0.1f}%, Avg loss: {np.mean(test_losses):>8f}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-01-29 22:39:16] INFO (torcheeg/MainThread) 📊 | Detected existing split of train and test set, use existing split from ./examples_vanilla_torch/split.\n",
      "[2024-01-29 22:39:16] INFO (torcheeg/MainThread) 💡 | If the dataset is re-generated, you need to re-generate the split of the dataset instead of using the previous split.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2024-01-29 22:39:16.963485: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-29 22:39:17.093285: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-29 22:39:17.098496: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-01-29 22:39:17.098510: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-01-29 22:39:17.120315: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-29 22:39:17.591590: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-29 22:39:17.591950: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-29 22:39:17.591958: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | ConvLiquidEEG    | 40.6 K\n",
      "1 | ce_fn         | CrossEntropyLoss | 0     \n",
      "2 | train_loss    | MeanMetric       | 0     \n",
      "3 | val_loss      | MeanMetric       | 0     \n",
      "4 | test_loss     | MeanMetric       | 0     \n",
      "5 | train_metrics | MetricCollection | 0     \n",
      "6 | val_metrics   | MetricCollection | 0     \n",
      "7 | test_metrics  | MetricCollection | 0     \n",
      "---------------------------------------------------\n",
      "40.3 K    Trainable params\n",
      "276       Non-trainable params\n",
      "40.6 K    Total params\n",
      "0.162     Total estimated model params size (MB)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1035\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:194\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip:\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:250\u001b[0m, in \u001b[0;36m_FitLoop.setup_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dl \u001b[38;5;129;01min\u001b[39;00m combined_loader\u001b[38;5;241m.\u001b[39mflattened:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# determine number of batches\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dl) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_len_all_ranks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_zero_length\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m     num_batches \u001b[38;5;241m=\u001b[39m _parse_num_batches(stage, length, trainer\u001b[38;5;241m.\u001b[39mlimit_train_batches)\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:103\u001b[0m, in \u001b[0;36mhas_len_all_ranks\u001b[0;34m(dataloader, strategy, allow_zero_length_dataloader_with_multiple_devices)\u001b[0m\n\u001b[1;32m    102\u001b[0m total_length \u001b[38;5;241m=\u001b[39m strategy\u001b[38;5;241m.\u001b[39mreduce(torch\u001b[38;5;241m.\u001b[39mtensor(local_length, device\u001b[38;5;241m=\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mroot_device), reduce_op\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtotal_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m    104\u001b[0m     rank_zero_warn(\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal length of `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dataloader)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` across ranks is zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please make sure this was your intention.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m ConvLiquidEEG(num_classes\u001b[38;5;241m=\u001b[39mNUM_CLASSES)\n\u001b[1;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ClassifierTrainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     17\u001b[0m                             num_classes\u001b[38;5;241m=\u001b[39mNUM_CLASSES,\n\u001b[1;32m     18\u001b[0m                             lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m,\n\u001b[1;32m     19\u001b[0m                             weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m,\n\u001b[1;32m     20\u001b[0m                             accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdefault_root_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./examples_pipeline/model/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43menable_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43menable_model_summary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlimit_val_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m score \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtest(val_loader,\n\u001b[1;32m     30\u001b[0m                      enable_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     31\u001b[0m                      enable_model_summary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/torcheeg/trainers/classifier.py:129\u001b[0m, in \u001b[0;36mClassifierTrainer.fit\u001b[0;34m(self, train_loader, val_loader, max_epochs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    train_loader (DataLoader): Iterable DataLoader for traversing the training data batch (:obj:`torch.utils.data.dataloader.DataLoader`, :obj:`torch_geometric.loader.DataLoader`, etc).\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    val_loader (DataLoader): Iterable DataLoader for traversing the validation data batch (:obj:`torch.utils.data.dataloader.DataLoader`, :obj:`torch_geometric.loader.DataLoader`, etc).\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    max_epochs (int): Maximum number of epochs to train the model. (default: :obj:`300`)\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    124\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices,\n\u001b[1;32m    125\u001b[0m                      accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator,\n\u001b[1;32m    126\u001b[0m                      max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[1;32m    127\u001b[0m                      \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    128\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:68\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mloggers:\n\u001b[1;32m     67\u001b[0m     logger\u001b[38;5;241m.\u001b[39mfinalize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[1;32m     70\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_teardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m    those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m     loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active_loop\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:528\u001b[0m, in \u001b[0;36mStrategy.teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: moving model to CPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 528\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/lightning_fabric/utilities/device_dtype_mixin.py:79\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See :meth:`torch.nn.Module.cpu`.\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__update_properties(device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:967\u001b[0m, in \u001b[0;36mModule.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcpu\u001b[39m(\u001b[38;5;28mself\u001b[39m: T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \n\u001b[1;32m    961\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MasterIA/TFM/code/liquid-eeg/.venv/lib/python3.10/site-packages/torchmetrics/metric.py:808\u001b[0m, in \u001b[0;36mMetric._apply\u001b[0;34m(self, fn, exclude_state)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    803\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metric state to be either a Tensor or a list of Tensor, but encountered \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    804\u001b[0m         )\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# make sure to update the device attribute\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# if the dummy tensor moves device by fn function we should also update the attribute\u001b[39;00m\n\u001b[0;32m--> 808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device \u001b[38;5;241m=\u001b[39m fn(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    810\u001b[0m \u001b[38;5;66;03m# Additional apply to forward cache and computed attributes (may be nested)\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m this\u001b[38;5;241m.\u001b[39m_computed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torcheeg.trainers import ClassifierTrainer\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "for i, (train_dataset, val_dataset) in enumerate(k_fold.split(dataset)):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=7)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # model = ConvLiquidEEG(liquid_units=250, num_classes=NUM_CLASSES)\n",
    "    model = ConvLiquidEEG(num_classes=NUM_CLASSES)\n",
    "\n",
    "\n",
    "    trainer = ClassifierTrainer(model=model,\n",
    "                                num_classes=NUM_CLASSES,\n",
    "                                lr=1e-3,\n",
    "                                weight_decay=1e-5,\n",
    "                                accelerator=\"gpu\")\n",
    "    trainer.fit(train_loader,\n",
    "                val_loader,\n",
    "                max_epochs=3,\n",
    "                default_root_dir=f'./examples_pipeline/model/{i}',\n",
    "                callbacks=[pl.callbacks.ModelCheckpoint(save_last=True)],\n",
    "                enable_progress_bar=True,\n",
    "                enable_model_summary=True,\n",
    "                limit_val_batches=0.0)\n",
    "    score = trainer.test(val_loader,\n",
    "                         enable_progress_bar=True,\n",
    "                         enable_model_summary=True)[0]\n",
    "    print(f'Fold {i} test accuracy: {score[\"test_accuracy\"]:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
